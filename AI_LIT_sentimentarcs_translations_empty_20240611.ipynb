{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* lix and rix stylo metrics\n",
        "* rollover for sentiment and readibility\n",
        "* KDE distribution plot\n",
        "* summary statistics before ascore norm\n"
      ],
      "metadata": {
        "id": "LtJIcwIFsHT7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53z5Wf6hfYs-"
      },
      "source": [
        "# **DIRECTIONS:** Please Read First\n",
        "\n",
        "Browser:\n",
        "* Must use **Chrome** browser (esp not Safari)\n",
        "\n",
        "Colab:\n",
        "* Use **GPU Runtime (e.g. T4 high memory)** for Ollama LLMs and Transformer Models\n",
        "\n",
        "Input Raw Text File:\n",
        "* Filename Format **(TitleInCamelCase)_(FnameLnameInCamelCase).txt**\n",
        "* Use only **plain text** files (no *.rtf, *.doc, etc)\n",
        "* ***Headers/Footers deleted***, only first line to last line of novel text\n",
        "* ***Paragraphs*** separarted by at least **two blank lines**\n",
        "* ***Chapters/Sections*** separated by line starting with **'CHAPTER...'** and preceeded/suceeded by at least two blank lines\n",
        "* Encode in **'utf-8'**\n",
        "\n",
        "Novels (Get plain text if possible):\n",
        "* https://gutenberg.net.au/ (AUS)\n",
        "* https://gutenberg.org/ (US)\n",
        "\n",
        "Notebook Notation:\n",
        "* **OPTION (n)** means execute only **ONE** of the OPTIONS provided\n",
        "* **STEP (n)** means execute **ALL** of the STEPS that follow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwxnxnOXF4TB"
      },
      "source": [
        "# SentimentArcs Simplified Notebook\n",
        "\n",
        "Created:\n",
        "\n",
        "* 1 June 2024\n",
        "* Jon Chun\n",
        "\n",
        "A simplified version of SentimentArcs Notebooks for use with diachronic sentiment and stylometric analysis and time series plot.\n",
        "\n",
        "* https://github.com/jon-chun/sentimentarcs_notebooks\n",
        "\n",
        "* https://arxiv.org/pdf/2110.09454.pdfol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84IZ26RpiS7f"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy"
      ],
      "metadata": {
        "id": "UnJX71s1P5-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5rwPrKbMjok"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy English Models (RESTART REQUIRED)"
      ],
      "metadata": {
        "id": "-o9oVth6PdtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SpaCy English Model\n",
        "\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "1itMiPNh0mTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy French Models (RESTART REQUIRED)"
      ],
      "metadata": {
        "id": "ZkEtvx9ZAI-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SpaCy French Model\n",
        "\n",
        "!python -m spacy download fr_core_news_lg"
      ],
      "metadata": {
        "id": "WZxg453zAInw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy German Models (RESTART REQUIRED)"
      ],
      "metadata": {
        "id": "DrTPBn52L_4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SpaCy German Model\n",
        "\n",
        "!python -m spacy download de_core_news_lg"
      ],
      "metadata": {
        "id": "fHesqStgz883"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **[RESTART RUNTIME]**"
      ],
      "metadata": {
        "id": "BjnhqaBDQR-W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQF84De_I4cw"
      },
      "source": [
        "## Ollama LLM Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVSBLFKpFeme"
      },
      "outputs": [],
      "source": [
        "#Install package and load the extension\n",
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1ex7y3Czz-"
      },
      "source": [
        "### mistral7bsenti.modelfile\n",
        "\n",
        "```\n",
        "PARAMETER temperature 0.0\n",
        "PARAMETER top_p 0.5\n",
        "PARAMETER seed 42\n",
        "PARAMETER num_predict 5\n",
        "SYSTEM \"\"\"You are a text sentiment analysis engine that responds with only one float number for the sentiment polarity of the input text. You only reply with one float number between -1.0 and 1.0 which represent the most negative to most positive sentiment polarity. Use 0.0 for perfectly neutral sentiment. Do not respond with any other text. Do not give an greeting, explaination, definition, introduction, overview or conclusion. Only reply with the float number representing the sentiment polarity of the input text.\"\"\"\n",
        "\n",
        "NOTE: .modelfile is very sensitive to cut-and-paste hidden characters. If all else fails, manually retype the above into vi editor\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** .modelfile is very sensitive to cut-and-paste hidden characters. If all else fails, manually retype the above into vi editor"
      ],
      "metadata": {
        "id": "VTMe5SN_y1UD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqXyc5XtFh4N"
      },
      "outputs": [],
      "source": [
        "%xterm\n",
        "\n",
        "# curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# ollama serve & ollama pull mistral\n",
        "\n",
        "# ollama pull mistral\n",
        "\n",
        "# lsof -i :11434\n",
        "\n",
        "# ollama show mistral --modelfile > mistral7bsenti.modelfile\n",
        "\n",
        "# vi mistral7bsenti.modelfile (insert new PARAMETERS and SYSTEM lines above)\n",
        "\n",
        "# ollama create mistral7bsenti --file mistral7bsenti.modelfile\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i :11434"
      ],
      "metadata": {
        "id": "SUtJk4CqA4Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk-OqFHfI8sn"
      },
      "source": [
        "## Ollama, LangChain and Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kC6WwsBuu7n"
      },
      "outputs": [],
      "source": [
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emZ20cGykZth"
      },
      "outputs": [],
      "source": [
        "!pip install Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVKek_uU7NG_"
      },
      "source": [
        "## NLP and Spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co1FOWUNjeEd"
      },
      "outputs": [],
      "source": [
        "!pip install pysbd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6blQ93MfMny"
      },
      "outputs": [],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy"
      ],
      "metadata": {
        "id": "1ulURZkUXdc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chardet"
      ],
      "metadata": {
        "id": "OhO1EzjhXeNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stylometry"
      ],
      "metadata": {
        "id": "lf3GmUq1yTKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5EBKicjtfqL"
      },
      "outputs": [],
      "source": [
        "# https://hlasse.github.io/TextDescriptives/\n",
        "\n",
        "!pip install textdescriptives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybb0AdXltU0K"
      },
      "outputs": [],
      "source": [
        "# https://github.com/LSYS/lexicalrichness\n",
        "\n",
        "!pip install lexicalrichness"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numeric and Graphing"
      ],
      "metadata": {
        "id": "z49LEOStkmt8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcngg5fHkZti"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5Jfhk_4kZtj"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "e0QTAAx_yhew"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlElbp_ZJEe-"
      },
      "source": [
        "## Common Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rHp3L7rDVd4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jICsw_KfxPjr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import json\n",
        "import pprint\n",
        "import logging\n",
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import string\n",
        "import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "import glob\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "import getpass\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "from tqdm import tqdm\n",
        "# from tqdm.auto import tqdm\n",
        "# from tqdm.notebook import tqdm\n",
        "\n",
        "from itertools import combinations\n",
        "import random\n",
        "\n",
        "# 20240525 from cleantext import clean\n",
        "# 20240525 import contractions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ollama, LangChain and Transformers"
      ],
      "metadata": {
        "id": "UCFRup6Tyto5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzsa9vMAigZv"
      },
      "source": [
        "#### ollama-python JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuQglUB8fPeu"
      },
      "outputs": [],
      "source": [
        "import ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBn-kgHCifKU"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# TEST:\n",
        "\n",
        "response = ollama.chat(\n",
        "    model='mistral7bsenti',\n",
        "    # model='mistral',\n",
        "    # messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
        "    messages=[{'role': 'user', 'content': 'I was unimpressed with the spectacle of the event?'}],\n",
        "    stream=False,\n",
        ")\n",
        "\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5qUZ5lMfPbe"
      },
      "outputs": [],
      "source": [
        "# from langchain_community.llms import Ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP and SpaCy"
      ],
      "metadata": {
        "id": "AURLiQGny5I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet"
      ],
      "metadata": {
        "id": "lwVComjcy6y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect, DetectorFactory"
      ],
      "metadata": {
        "id": "KIZTEH-jlF82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS0EHrvPjauk"
      },
      "outputs": [],
      "source": [
        "import pysbd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GU9stGLxPRp"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preinstalled on Google Colab, not on runpod.io VMs\n",
        "\n",
        "import ftfy"
      ],
      "metadata": {
        "id": "b15ByiRikw02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stylometry\n"
      ],
      "metadata": {
        "id": "yUV7HgvLk_E1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlx7evCTIocO"
      },
      "outputs": [],
      "source": [
        "import lexicalrichness"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lexicalrichness import LexicalRichness"
      ],
      "metadata": {
        "id": "1CiE6k-j65Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RLxr6nLIoGA"
      },
      "outputs": [],
      "source": [
        "import textdescriptives as td"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numeric and Graphing"
      ],
      "metadata": {
        "id": "wXiMSEvIlHmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTWZ7NkOHy9d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILz76DDY2Jkj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "from scipy.stats import gaussian_kde\n",
        "from scipy.stats import zscore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoAObYmivWoo"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jupyter Notebook Configurations\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "k91JTAs20rJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase the data rate limit\n",
        "%config NotebookApp.iopub_data_rate_limit=10000000.0  # 10 MB/sec"
      ],
      "metadata": {
        "id": "D7-Zn2pmDsR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python Interpreter Warnings\n",
        "# DEBUG: Comment out these lines\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "LgXtpaoJ0iNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAXTy1THUHwO"
      },
      "outputs": [],
      "source": [
        "# Matplotlib Plot Configurations\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzaE7PuejExE"
      },
      "source": [
        "# Benchmark Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzp6OrUUGtb1"
      },
      "source": [
        "### Sentiment Rubrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqP9lTqBGq51"
      },
      "outputs": [],
      "source": [
        "# NOTE: Unnecessary if using custom Ollama models with sentiment SYSTEM message\n",
        "\n",
        "SENTIMENT_RUBRIC = \"\"\"\n",
        "Evaluate this sentence for sentiment polarity\n",
        "as perceived in the language it was written in then\n",
        "return a floating point value anywhere betweeen -1.0 (most negative) to 0.0 (neutral) to 1.0 (most positive).\n",
        "Only return a floating point number between -1.0 and 1.0 and nothing else\n",
        "Do not respond with an introduction, description, definition, summary, or anything but a single floating point number\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmS7W3PfkfXp"
      },
      "source": [
        "## Translation Text (pick one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELvgfHJ1kl_I"
      },
      "source": [
        "### (a) Opening Paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZkRXCJUjPZ7"
      },
      "outputs": [],
      "source": [
        "# SAMPLE TRANSLATIONS:\n",
        "\n",
        "french_original_str = \"\"\"\n",
        "Longtemps, je me suis couché de bonne heure. Parfois, à peine ma\n",
        "bougie éteinte, mes yeux se fermaient si vite que je n’avais pas le\n",
        "temps de me dire: «Je m’endors.» Et, une demi-heure après, la pensée\n",
        "qu’il était temps de chercher le sommeil m’éveillait; je voulais poser\n",
        "le volume que je croyais avoir encore dans les mains et souffler ma\n",
        "lumière; je n’avais pas cessé en dormant de faire des réflexions sur\n",
        "ce que je venais de lire, mais ces réflexions avaient pris un tour un\n",
        "peu particulier; il me semblait que j’étais moi-même ce dont parlait\n",
        "l’ouvrage: une église, un quatuor, la rivalité de François Ier et de\n",
        "Charles Quint. Cette croyance survivait pendant quelques secondes à\n",
        "mon réveil; elle ne choquait pas ma raison mais pesait comme des\n",
        "écailles sur mes yeux et les empêchait de se rendre compte que le\n",
        "bougeoir n’était plus allumé. Puis elle commençait à me devenir\n",
        "inintelligible, comme après la métempsycose les pensées d’une\n",
        "existence antérieure; le sujet du livre se détachait de moi, j’étais\n",
        "libre de m’y appliquer ou non; aussitôt je recouvrais la vue et\n",
        "j’étais bien étonné de trouver autour de moi une obscurité, douce et\n",
        "reposante pour mes yeux, mais peut-être plus encore pour mon esprit, à\n",
        "qui elle apparaissait comme une chose sans cause, incompréhensible,\n",
        "comme une chose vraiment obscure. Je me demandais quelle heure il\n",
        "pouvait être; j’entendais le sifflement des trains qui, plus ou moins\n",
        "éloigné, comme le chant d’un oiseau dans une forêt, relevant les\n",
        "distances, me décrivait l’étendue de la campagne déserte où le\n",
        "voyageur se hâte vers la station prochaine; et le petit chemin qu’il\n",
        "suit va être gravé dans son souvenir par l’excitation qu’il doit à des\n",
        "lieux nouveaux, à des actes inaccoutumés, à la causerie récente et aux\n",
        "adieux sous la lampe étrangère qui le suivent encore dans le silence\n",
        "de la nuit, à la douceur prochaine du retour.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_davis_str = \"\"\"\n",
        "For a long time, I went to bed early.\n",
        "Sometimes, my candle scarcely out, my eyes would close so quickly that I did not have time to say to myself: ‘I’m falling asleep.’ And, half an hour later, the thought that it was time to try to sleep would wake me; I wanted to put down the book I thought I still had in my hands and blow out my light; I had not ceased while sleeping to form reflections on what I had just read, but these reflections had taken a rather peculiar turn; it seemed to me that I myself was what the book was talking about: a church, a quartet, the rivalry between François I and Charles V.\n",
        "This belief lived on for a few seconds after my waking; it did not shock my reason but lay heavy like scales on my eyes and kept them from realizing that the candlestick was no longer lit.\n",
        "Then it began to grow unintelligible to me, as after metempsychosis do the thoughts of an earlier existence; the subject of the book detached itself from me, I was free to apply myself to it or not; immediately I recovered my sight and I was amazed to find a darkness around me soft and restful for my eyes, but perhaps even more so for my mind, to which it appeared a thing without cause, incomprehensible, a thing truly dark.\n",
        "I would ask myself what time it might be; I could hear the whistling of the trains which, remote or near by, like the singing of a bird in a forest, plotting the distances, described to me the extent of the deserted countryside where the traveller hastens towards the nearest station; and the little road he is following will be engraved on his memory by the excitement he owes to new places, to unaccustomed activities, to the recent conversation and the farewells under the unfamiliar lamp that follow him still through the silence of the night, to the imminent sweetness of his return.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_enright_str = \"\"\"\n",
        "For a long time I would go to bed early.\n",
        "Sometimes, the candle barely out, my eyes closed so quickly that I did not have time to tell myself: “I’m falling asleep.”\n",
        "And half an hour later the thought that it was time to look for sleep would awaken me; I would make as if to put away the book which I imagined was still in my hands, and to blow out the light; I had gone on thinking, while I was asleep, about what I had just been reading, but these thoughts had taken a rather peculiar turn; it seemed to me that I myself was the immediate subject of my book: a church, a quartet, the rivalry between François I and Charles V.\n",
        "This impression would persist for some moments after I awoke; it did not offend my reason, but lay like scales upon my eyes and prevented them from registering the fact that the candle was no longer burning.\n",
        "Then it would begin to seem unintelligible, as the thoughts of a previous existence must be after reincarnation; the subject of my book would separate itself from me, leaving me free to apply myself to it or not; and at the same time my sight would return and I would be astonished to find myself in a state of darkness, pleasant and restful enough for my eyes, but even more, perhaps, for my mind, to which it appeared incomprehensible, without a cause, something dark indeed.\n",
        "I would ask myself what time it could be; I could hear the whistling of trains, which, now nearer and now further 1 off, punctuating the distance like the note of a bird in a forest, showed me in perspective the deserted countryside through which a traveller is hurrying towards the nearby station; and the path he is taking will be engraved in his memory by the excitement induced by strange surroundings, by unaccustomed activities, by the conversation he has had and the farewells exchanged beneath an unfamiliar lamp that still echo in his ears amid the silence of the night, and by the happy prospect of being home again.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_moncrieff_str = \"\"\"\n",
        "For a long time I used to go to bed early.\n",
        "Sometimes, when I had put out my candle, my eyes would close so quickly that I had not even time to say \"I'm going to sleep.\" And half an hour later the thought that it was time to go to sleep would awaken me; I would try to put away the book which, I imagined, was still in my hands, and to blow out the light; I had been thinking all the time, while I was asleep, of what I had just been reading, but my thoughts had run into a channel of their own, until I myself seemed actually to have become the subject of my book: a church, a quartet, the rivalry between François I and Charles V.\n",
        "This impression would persist for some moments after I was awake; it did not disturb my mind, but it lay like scales upon my eyes and prevented them from registering the fact that the candle was no longer burning.\n",
        "Then it would begin to seem unintelligible, as the thoughts of a former existence must be to a reincarnate spirit; the subject of my book would separate itself from me, leaving me free to choose whether I would form part of it or no; and at the same time my sight would return and I would be astonished to find myself in a state of darkness, pleasant and restful enough for the eyes, and even more, perhaps, for my mind, to which it appeared incomprehensible, without a cause, a matter dark I would ask myself what o'clock it could be; I could hear the whistling of trains, which, now nearer and now farther off, punctuating the distance like the note of a bird in a forest, shewed me in perspective the deserted countryside through which a traveller would be hurrying towards the nearest station: the path that he followed being fixed for ever in his memory by the general excitement due to being in a strange place, to doing unusual things, to the last words of conversation, to farewells exchanged beneath an unfamiliar lamp which echoed still in his ears amid the silence of the night; and to the delightful prospect of I would lay my cheeks gently against the comfortable cheeks of my pillow, as plump and blooming as the cheeks of babyhood.\n",
        "\"\"\";\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZSpH6UAkobm"
      },
      "source": [
        "### (b) Ending Paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MktRw7qlf1cu"
      },
      "outputs": [],
      "source": [
        "# SAMPLE TRANSLATIONS:\n",
        "\n",
        "french_original_str = \"\"\"\n",
        "Quelle horreur! Ma consolation c’est de penser aux femmes que j’ai connues, aujourd’hui qu’il n’y a plus d’élégance.\n",
        "Mais comment des gens qui contemplent ces horribles créatures sous leurs chapeaux couverts d’une volière ou d’un potager, pourraient-ils même sentir ce qu’il y avait de charmant à voir Mme Swann coiffée d’une simple capote mauve ou d’un petit chapeau que dépassait une seule fleur d’iris toute droite.\n",
        "Aurais-je même pu leur faire comprendre l’émotion que j’éprouvais par les matins d’hiver à rencontrer Mme Swann à pied, en paletot de loutre, coiffée d’un simple béret que dépassaient deux couteaux de plumes de perdrix, mais autour de laquelle la tiédeur factice de son appartement était évoquée, rien que par le bouquet de violettes qui s’écrasait à son corsage et dont le fleurissement vivant et bleu en face du ciel gris, de l’air glacé, des arbres aux branches nues, avait le même charme de ne prendre la saison et le temps que comme un cadre, et de vivre dans une atmosphère humaine, dans l’atmosphère de cette femme, qu’avaient dans les vases et les jardinières de son salon, près du feu allumé, devant le canapé de soie, les fleurs qui regardaient par la fenêtre close la neige tomber?\n",
        "D’ailleurs il ne m’eût pas suffi que les toilettes fussent les mêmes qu’en ces années-là.\n",
        "A cause de la solidarité qu’ont entre elles les différentes parties d’un souvenir et que notre mémoire maintient équilibrées dans un assemblage où il ne nous est pas permis de rien distraire, ni refuser, j’aurais voulu pouvoir aller finir la journée chez une de ces femmes, devant une tasse de thé, dans un appartement aux murs peints de couleurs sombres, comme était encore celui de Mme Swann (l’année d’après celle où se termine la première partie de ce récit) et où luiraient les feux orangés, la rouge combustion, la flamme rose et blanche des chrysanthèmes dans le crépuscule de novembre pendant des instants pareils à ceux où (comme on le verra plus tard) je n’avais pas su découvrir les plaisirs que je désirais.\n",
        "Mais maintenant, même ne me conduisant à rien, ces instants me semblaient avoir eu eux-mêmes assez de charme.\n",
        "Je voudrais les retrouver tels que je me les rappelais.\n",
        "Hélas! il n’y avait plus que des appartements Louis XVI tout blancs, émaillés d’hortensias bleus.\n",
        "D’ailleurs, on ne revenait plus à Paris que très tard.\n",
        "Mme Swann m’eût répondu d’un château qu’elle ne rentrerait qu’en février, bien après le temps des chrysanthèmes, si je lui avais demandé de reconstituer pour moi les éléments de ce souvenir que je sentais attaché à une année lointaine, à un millésime vers lequel il ne m’était pas permis de remonter, les éléments de ce désir devenu lui-même inaccessible comme le plaisir qu’il avait jadis vainement poursuivi.\n",
        "Et il m’eût fallu aussi que ce fussent les mêmes femmes, celles dont la toilette m’intéressait parce que, au temps où je croyais encore, mon imagination les avait individualisées et les avait pourvues d’une légende.\n",
        "Hélas! dans l’avenue des Acacias--l’allée de Myrtes--j’en revis quelques-unes, vieilles, et qui n’étaient plus que les ombres terribles de ce qu’elles avaient été, errant, cherchant désespérément on ne sait quoi dans les bosquets virgiliens.\n",
        "Elles avaient fui depuis longtemps que j’étais encore à interroger vainement les chemins désertés.\n",
        "Le soleil s’était caché.\n",
        "La nature recommençait à régner sur le Bois d’où s’était envolée l’idée qu’il était le Jardin élyséen de la Femme; au-dessus du moulin factice le vrai ciel était gris; le vent ridait le Grand Lac de petites vaguelettes, comme un lac; de gros oiseaux parcouraient rapidement le Bois, comme un bois, et poussant des cris aigus se posaient l’un après l’autre sur les grands chênes qui sous leur couronne druidique et avec une majesté dodonéenne semblaient proclamer le vide inhumain de la forêt désaffectée, et m’aidaient à mieux comprendre la contradiction que c’est de chercher dans la réalité les tableaux de la mémoire, auxquels manquerait toujours le charme qui leur vient de la mémoire même et de n’être pas perçus par les sens.\n",
        "La réalité que j’avais connue n’existait plus.\n",
        "Il suffisait que Mme Swann n’arrivât pas toute pareille au même moment, pour que l’Avenue fût autre.\n",
        "Les lieux que nous avons connus n’appartiennent pas qu’au monde de l’espace où nous les situons pour plus de facilité.\n",
        "Ils n’étaient qu’une mince tranche au milieu d’impressions contiguës qui formaient notre vie d’alors; le souvenir d’une certaine image n’est que le regret d’un certain instant; et les maisons, les routes, les avenues, sont fugitives, hélas, comme les années.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_davis_str = \"\"\"\n",
        "How awful! I said to myself: can anyone think these automobiles are as elegant as the old carriages and pairs? I’m probably too old already – but I’m not meant for a world in which women hobble themselves in dresses that aren’t even made of cloth. What’s the use of walking among these trees, if nothing is left of what used to gather under the delicate reddening leaves, if vulgarity and idiocy have taken the place of the exquisite thing they once framed? How awful! My consolation is to think about the women I have known, now that there is no more elegance. But how could anyone contemplating these horrible creatures under their hats topped with a birdcage or a vegetable patch even sense what was so charming about the sight of Mme Swann in a simple mauve hood or a little hat with a single stiff, straight iris poking up from it? Could I even have made them understand the emotion I felt on winter mornings when I met Mme Swann on foot, in a sealskin coat, wearing a simple beret with two blades of partridge feathers sticking up from it, but enveloped also by the artificial warmth of her apartment, which was conjured by nothing more than the bouquet of violets crushed at her breast whose live blue flowering against the grey sky, the icy air, the bare-branched trees, had the same charming manner of accepting the season and the weather merely as a setting, and of living in a human atmosphere, in the atmosphere of this woman, as had, in the vases and flower-stands of her drawing-room, close to the lit fire, before the silk sofa, the flowers that looked out through the closed window at the falling snow? But it would not have been enough for me anyway for the clothes to be the same as in those earlier times. Because of the dependence which the different parts of a recollection have on one another, parts which our memory keeps balanced in an aggregate from which we are not permitted to abstract anything, or reject anything, I would have wanted to be able to go and spend the last part of the day in the home of one of these women, over a cup of tea, in an apartment with walls painted in dark colours, as Mme Swann’s still was (in the year after the one in which the first part of this story ends) and in which the orange flares, the red combustion, the pink and white flame of the chrysanthemums would gleam in the November twilight, during moments like those in which (as we will see later) I was not able to discover the pleasures I desired. But now, even though they had led to nothing, those moments seemed to me to have had enough charm in themselves. I wanted to find them again as I remembered them. Alas, there was no longer anything but Louis XVI apartments all white and dotted with blue hydrangeas. Moreover, people no longer returned to Paris until very late. Mme Swann would have answered me from a country house that she would not be back until February, well after the time of the chrysanthemums, had I asked her to reconstruct for me the elements of that memory which I felt belonged to a distant year, to a vintage to which I was not allowed to go back, the elements of that desire which had itself become as inaccessible as the pleasure it had once vainly pursued. And I would also have needed them to be the same women, those whose clothing interested me because, at the time when I still believed, my imagination had individualized them and given them each a legend. Alas, in the avenue des Acacias – the allée de Myrtes – I did see a few of them again, old, now no more than terrible shadows of what they had been, wandering, desperately searching for who knows what in the Virgilian groves. They had fled long since as I still vainly questioned the deserted paths. The sun had hidden itself. Nature was resuming its rule over the Bois, from which the idea that it was the Elysian Garden of Woman had vanished; above the artificial mill the real sky was grey; the wind wrinkled the Grand Lac with little wavelets, like a real lake; large birds swiftly crossed the Bois, like a real wood, and uttering sharp cries alighted one after another in the tall oaks which under their druidical crowns and with a Dodonean39 majesty seemed to proclaim the inhuman emptiness of the disused forest, and helped me better understand what a contradiction it is to search in reality for memory’s pictures, which would never have the charm that comes to them from memory itself and from not being perceived by the senses. The reality I had known no longer existed. That Mme Swann did not arrive exactly the same at the same moment was enough to make the avenue different. The places we have known do not belong solely to the world of space in which we situate them for our greater convenience. They were only a thin slice among contiguous impressions that formed our life at that time; the memory of a certain image is only regret for a certain moment; and houses, roads, avenues are as fleeting, alas, as the years.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_enright_str = \"\"\"\n",
        "How horrible! I exclaimed to myself. Can anyone find these motor-cars as elegant as the old carriage-and-pair? I dare say I am too old now—but I was not intended for a world in which women shackle themselves in garments that are not even made of cloth. To what purpose shall I walk among these trees if there is nothing left now of the assembly that used to gather beneath this delicate tracery of reddening leaves, if vulgarity and folly have supplanted the exquisite thing that their branches once framed. How horrible! My consolation is to think of the women whom I knew in the past, now that there is no elegance left. But how could the people who watch these dreadful creatures hobble by beneath hats on which have been heaped the spoils of aviary or kitchen-garden, how could they even imagine the charm that there was in the sight of Mme Swann in a simple mauve bonnet or a little hat with a single iris sticking up out of it?\n",
        "Could I even have made them understand the emotion that I used to feel on winter mornings, when I met Mme Swann on foot, in an otter-skin coat, with a woolen cap from which stuck out two blade-like partridge-feathers, but enveloped also in the artificial warmth of her own house, which was suggested by nothing more than the bunch of violets crushed into her bosom, whose flowering, vivid and blue against the\n",
        "grey sky, the freezing air, the naked boughs, had the same charming effect of using the season and the weather merely as a setting, and of living actually in a human atmosphere, in the atmosphere of this woman, as had, in the vases and jardinières of her drawing-room, beside the blazing fire, in front of the silk-covered settee, the flowers that looked out through closed windows at the falling snow? But it would not have sufficed me that the costumes alone should still have been the same as those in distant years. Because of the solidarity that binds together the different parts of a general impression that our memory keeps in a balanced whole of which we are not permitted to subtract or to decline any fraction, I should have liked to be able to pass the rest of the day with one of those women, over a cup of tea, in an apartment with dark-painted walls (as Mme Swann’s were still in the year after that in which the first part of this story ends) against which would glow the orange flame, the red combustion, the pink and white flickering of her chrysanthemums in the twilight of a November evening, in moments similar to those in which (as we shall see) I had not managed to discover the pleasures for which I longed. But now, even though they had led to nothing, those moments struck me as having been charming enough in themselves. I wanted to find them again as I remembered them. Alas! there was nothing now but flats decorated in the Louis XVI style, all white, with a sprinkling of blue hydrangeas. Moreover, people did not return to Paris, now, until much later. Mme Swann would have written to me from a country house to say that she would not be in town before February, long after the chrysanthemum season, had I asked her to reconstruct for me the elements of that memory which I felt to belong to a particular distant year, a particular vintage towards which it was forbidden me to ascend again the fatal slope, the\n",
        "elements of that longing which had itself become as inaccessible as the pleasure that it had once vainly pursued.\n",
        "And I should have required also that they should be the same women, those whose costume interested me because, at the time when I still had faith, my imagination had individualised them and had provided each of them with a legend. Alas! in the acacia-avenue—the myrtle-alley—I did see some of them again, grown old, no more now than grim spectres of what they had once been, wandering, desperately searching for heaven knew what, through the Virgilian groves. They had long since fled, and still I stood vainly questioning the deserted paths. The sun had gone. Nature was resuming its reign over the Bois, from which had vanished all trace of the idea that it was the Elysian Garden of Woman; above the gimcrack windmill the real sky was grey; the wind wrinkled the surface of the Grand Lac in little wavelets, like a real lake; large birds flew swiftly over the Bois, as over a real wood, and with shrill cries perched, one after another, on the great oaks which, beneath their Druidical crown, and with Dodonian majesty, seemed to proclaim the inhuman emptiness of this deconsecrated forest, and helped me to understand how paradoxical it is to seek in reality for the pictures that are stored in one’s memory, which must inevitably lose the charm that comes to them from memory itself and from their not being apprehended by the senses. The reality that I had known no longer existed. It sufficed that Mme Swann did not appear, in the same attire and at the same moment, for the whole avenue to be altered.\n",
        "The places we have known do not belong only to the world of space on which we map them for our own convenience. They were only a thin slice, held between the contiguous impressions that composed our life at that time; the memory\n",
        "of a particular image is but regret for a particular moment; and houses, roads, avenues are as fugitive, alas, as the years.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_moncrieff_str = \"\"\"\n",
        "\"Oh, horrible!\" I exclaimed to myself: \"Does anyone really imagine that\n",
        "these motor-cars are as smart as the old carriage-and-pair? I dare say.\n",
        "I am too old now--but I was not intended for a world in which women\n",
        "shackle themselves in garments that are not even made of cloth. To what\n",
        "purpose shall I walk among these trees if there is nothing left now of\n",
        "the assembly that used to meet beneath the delicate tracery of reddening\n",
        "leaves, if vulgarity and fatuity have supplanted the exquisite thing\n",
        "that once their branches framed? Oh, horrible! My consolation is to\n",
        "think of the women whom I have known, in the past, now that there is\n",
        "no standard left of elegance. But how can the people who watch these\n",
        "dreadful creatures hobble by, beneath hats on which have been heaped\n",
        "the spoils of aviary or garden-bed,--how can they imagine the charm that\n",
        "there was in the sight of Mme. Swann, crowned with a close-fitting lilac\n",
        "bonnet, or with a tiny hat from which rose stiffly above her head a\n",
        "single iris?\" Could I ever have made them understand the emotion that\n",
        "I used to feel on winter mornings, when I met Mme. Swann on foot, in an\n",
        "otter-skin coat, with a woollen cap from which stuck out two blade-like\n",
        "partridge-feathers, but enveloped also in the deliberate, artificial\n",
        "warmth of her own house, which was suggested by nothing more than the\n",
        "bunch of violets crushed into her bosom, whose flowering, vivid and blue\n",
        "against the grey sky, the freezing air, the naked boughs, had the same\n",
        "charming effect of using the season and the weather merely as a setting,\n",
        "and of living actually in a human atmosphere, in the atmosphere of this\n",
        "woman, as had in the vases and beaupots of her drawing-room, beside the\n",
        "blazing fire, in front of the silk-covered sofa, the flowers that looked\n",
        "out through closed windows at the falling snow? But it would not have\n",
        "sufficed me that the costumes alone should still have been the same as\n",
        "in those distant years. Because of the solidarity that binds together\n",
        "the different parts of a general impression, parts that our memory keeps\n",
        "in a balanced whole, of which we are not permitted to subtract or to\n",
        "decline any fraction, I should have liked to be able to pass the rest\n",
        "of the day with one of those women, over a cup of tea, in a little house\n",
        "with dark-painted walls (as Mme. Swann's were still in the year after\n",
        "that in which the first part of this story ends) against which would\n",
        "glow the orange flame, the red combustion, the pink and white flickering\n",
        "of her chrysanthemums in the twilight of a November evening, in moments\n",
        "similar to those in which (as we shall see) I had not managed to\n",
        "discover the pleasures for which I longed. But now, albeit they had led\n",
        "to nothing, those moments struck me as having been charming enough in\n",
        "themselves. I sought to find them again as I remembered them. Alas!\n",
        "there was nothing now but flats decorated in the Louis XVI style, all\n",
        "white paint, with hortensias in blue enamel. Moreover, people did not\n",
        "return to Paris, now, until much later. Mme. Swann would have written to\n",
        "me, from a country house, that she would not be in town before February,\n",
        "had I asked her to reconstruct for me the elements of that memory which\n",
        "I felt to belong to a distant era, to a date in time towards which it\n",
        "was forbidden me to ascend again the fatal slope, the elements of that\n",
        "longing which had become, itself, as inaccessible as the pleasure that\n",
        "it had once vainly pursued. And I should have required also that they\n",
        "be the same women, those whose costume interested me because, at a time\n",
        "when I still had faith, my imagination had individualised them and had\n",
        "provided each of them with a legend. Alas! in the acacia-avenue--the\n",
        "myrtle-alley--I did see some of them again, grown old, no more now\n",
        "than grim spectres of what once they had been, wandering to and fro, in\n",
        "desperate search of heaven knew what, through the Virgilian groves. They\n",
        "had long fled, and still I stood vainly questioning the deserted paths.\n",
        "The sun's face was hidden. Nature began again to reign over the Bois,\n",
        "from which had vanished all trace of the idea that it was the Elysian\n",
        "Garden of Woman; above the gimcrack windmill the real sky was grey; the\n",
        "wind wrinkled the surface of the Grand Lac in little wavelets, like\n",
        "a real lake; large birds passed swiftly over the Bois, as over a real\n",
        "wood, and with shrill cries perched, one after another, on the great\n",
        "oaks which, beneath their Druidical crown, and with Dodonaic majesty,\n",
        "seemed to proclaim the unpeopled vacancy of this estranged forest, and\n",
        "helped me to understand how paradoxical it is to seek in reality for the\n",
        "pictures that are stored in one's memory, which must inevitably lose\n",
        "the charm that comes to them from memory itself and from their not\n",
        "being apprehended by the senses. The reality that I had known no longer\n",
        "existed. It sufficed that Mme. Swann did not appear, in the same attire\n",
        "and at the same moment, for the whole avenue to be altered. The places\n",
        "that we have known belong now only to the little world of space on which\n",
        "we map them for our own convenience. None of them was ever more than a\n",
        "thin slice, held between the contiguous impressions that composed our\n",
        "life at that time; remembrance of a particular form is but regret for a\n",
        "particular moment; and houses, roads, avenues are as fugitive, alas, as\n",
        "the years.\n",
        "\"\"\";\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6KFG3HUkqwQ"
      },
      "source": [
        "### (c) Any Paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4opi3VNDksKg"
      },
      "outputs": [],
      "source": [
        "# SAMPLE TRANSLATIONS:\n",
        "\n",
        "french_original_str = \"\"\"\n",
        "Quelle horreur! Ma consolation c’est de penser aux femmes que j’ai connues, aujourd’hui qu’il n’y a plus d’élégance.\n",
        "Mais comment des gens qui contemplent ces horribles créatures sous leurs chapeaux couverts d’une volière ou d’un potager, pourraient-ils même sentir ce qu’il y avait de charmant à voir Mme Swann coiffée d’une simple capote mauve ou d’un petit chapeau que dépassait une seule fleur d’iris toute droite.\n",
        "Aurais-je même pu leur faire comprendre l’émotion que j’éprouvais par les matins d’hiver à rencontrer Mme Swann à pied, en paletot de loutre, coiffée d’un simple béret que dépassaient deux couteaux de plumes de perdrix, mais autour de laquelle la tiédeur factice de son appartement était évoquée, rien que par le bouquet de violettes qui s’écrasait à son corsage et dont le fleurissement vivant et bleu en face du ciel gris, de l’air glacé, des arbres aux branches nues, avait le même charme de ne prendre la saison et le temps que comme un cadre, et de vivre dans une atmosphère humaine, dans l’atmosphère de cette femme, qu’avaient dans les vases et les jardinières de son salon, près du feu allumé, devant le canapé de soie, les fleurs qui regardaient par la fenêtre close la neige tomber?\n",
        "D’ailleurs il ne m’eût pas suffi que les toilettes fussent les mêmes qu’en ces années-là.\n",
        "A cause de la solidarité qu’ont entre elles les différentes parties d’un souvenir et que notre mémoire maintient équilibrées dans un assemblage où il ne nous est pas permis de rien distraire, ni refuser, j’aurais voulu pouvoir aller finir la journée chez une de ces femmes, devant une tasse de thé, dans un appartement aux murs peints de couleurs sombres, comme était encore celui de Mme Swann (l’année d’après celle où se termine la première partie de ce récit) et où luiraient les feux orangés, la rouge combustion, la flamme rose et blanche des chrysanthèmes dans le crépuscule de novembre pendant des instants pareils à ceux où (comme on le verra plus tard) je n’avais pas su découvrir les plaisirs que je désirais.\n",
        "Mais maintenant, même ne me conduisant à rien, ces instants me semblaient avoir eu eux-mêmes assez de charme.\n",
        "Je voudrais les retrouver tels que je me les rappelais.\n",
        "Hélas! il n’y avait plus que des appartements Louis XVI tout blancs, émaillés d’hortensias bleus.\n",
        "D’ailleurs, on ne revenait plus à Paris que très tard.\n",
        "Mme Swann m’eût répondu d’un château qu’elle ne rentrerait qu’en février, bien après le temps des chrysanthèmes, si je lui avais demandé de reconstituer pour moi les éléments de ce souvenir que je sentais attaché à une année lointaine, à un millésime vers lequel il ne m’était pas permis de remonter, les éléments de ce désir devenu lui-même inaccessible comme le plaisir qu’il avait jadis vainement poursuivi.\n",
        "Et il m’eût fallu aussi que ce fussent les mêmes femmes, celles dont la toilette m’intéressait parce que, au temps où je croyais encore, mon imagination les avait individualisées et les avait pourvues d’une légende.\n",
        "Hélas! dans l’avenue des Acacias--l’allée de Myrtes--j’en revis quelques-unes, vieilles, et qui n’étaient plus que les ombres terribles de ce qu’elles avaient été, errant, cherchant désespérément on ne sait quoi dans les bosquets virgiliens.\n",
        "Elles avaient fui depuis longtemps que j’étais encore à interroger vainement les chemins désertés.\n",
        "Le soleil s’était caché.\n",
        "La nature recommençait à régner sur le Bois d’où s’était envolée l’idée qu’il était le Jardin élyséen de la Femme; au-dessus du moulin factice le vrai ciel était gris; le vent ridait le Grand Lac de petites vaguelettes, comme un lac; de gros oiseaux parcouraient rapidement le Bois, comme un bois, et poussant des cris aigus se posaient l’un après l’autre sur les grands chênes qui sous leur couronne druidique et avec une majesté dodonéenne semblaient proclamer le vide inhumain de la forêt désaffectée, et m’aidaient à mieux comprendre la contradiction que c’est de chercher dans la réalité les tableaux de la mémoire, auxquels manquerait toujours le charme qui leur vient de la mémoire même et de n’être pas perçus par les sens.\n",
        "La réalité que j’avais connue n’existait plus.\n",
        "Il suffisait que Mme Swann n’arrivât pas toute pareille au même moment, pour que l’Avenue fût autre.\n",
        "Les lieux que nous avons connus n’appartiennent pas qu’au monde de l’espace où nous les situons pour plus de facilité.\n",
        "Ils n’étaient qu’une mince tranche au milieu d’impressions contiguës qui formaient notre vie d’alors; le souvenir d’une certaine image n’est que le regret d’un certain instant; et les maisons, les routes, les avenues, sont fugitives, hélas, comme les années.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_davis_str = \"\"\"\n",
        "How awful! I said to myself: can anyone think these automobiles are as elegant as the old carriages and pairs? I’m probably too old already – but I’m not meant for a world in which women hobble themselves in dresses that aren’t even made of cloth. What’s the use of walking among these trees, if nothing is left of what used to gather under the delicate reddening leaves, if vulgarity and idiocy have taken the place of the exquisite thing they once framed? How awful! My consolation is to think about the women I have known, now that there is no more elegance. But how could anyone contemplating these horrible creatures under their hats topped with a birdcage or a vegetable patch even sense what was so charming about the sight of Mme Swann in a simple mauve hood or a little hat with a single stiff, straight iris poking up from it? Could I even have made them understand the emotion I felt on winter mornings when I met Mme Swann on foot, in a sealskin coat, wearing a simple beret with two blades of partridge feathers sticking up from it, but enveloped also by the artificial warmth of her apartment, which was conjured by nothing more than the bouquet of violets crushed at her breast whose live blue flowering against the grey sky, the icy air, the bare-branched trees, had the same charming manner of accepting the season and the weather merely as a setting, and of living in a human atmosphere, in the atmosphere of this woman, as had, in the vases and flower-stands of her drawing-room, close to the lit fire, before the silk sofa, the flowers that looked out through the closed window at the falling snow? But it would not have been enough for me anyway for the clothes to be the same as in those earlier times. Because of the dependence which the different parts of a recollection have on one another, parts which our memory keeps balanced in an aggregate from which we are not permitted to abstract anything, or reject anything, I would have wanted to be able to go and spend the last part of the day in the home of one of these women, over a cup of tea, in an apartment with walls painted in dark colours, as Mme Swann’s still was (in the year after the one in which the first part of this story ends) and in which the orange flares, the red combustion, the pink and white flame of the chrysanthemums would gleam in the November twilight, during moments like those in which (as we will see later) I was not able to discover the pleasures I desired. But now, even though they had led to nothing, those moments seemed to me to have had enough charm in themselves. I wanted to find them again as I remembered them. Alas, there was no longer anything but Louis XVI apartments all white and dotted with blue hydrangeas. Moreover, people no longer returned to Paris until very late. Mme Swann would have answered me from a country house that she would not be back until February, well after the time of the chrysanthemums, had I asked her to reconstruct for me the elements of that memory which I felt belonged to a distant year, to a vintage to which I was not allowed to go back, the elements of that desire which had itself become as inaccessible as the pleasure it had once vainly pursued. And I would also have needed them to be the same women, those whose clothing interested me because, at the time when I still believed, my imagination had individualized them and given them each a legend. Alas, in the avenue des Acacias – the allée de Myrtes – I did see a few of them again, old, now no more than terrible shadows of what they had been, wandering, desperately searching for who knows what in the Virgilian groves. They had fled long since as I still vainly questioned the deserted paths. The sun had hidden itself. Nature was resuming its rule over the Bois, from which the idea that it was the Elysian Garden of Woman had vanished; above the artificial mill the real sky was grey; the wind wrinkled the Grand Lac with little wavelets, like a real lake; large birds swiftly crossed the Bois, like a real wood, and uttering sharp cries alighted one after another in the tall oaks which under their druidical crowns and with a Dodonean39 majesty seemed to proclaim the inhuman emptiness of the disused forest, and helped me better understand what a contradiction it is to search in reality for memory’s pictures, which would never have the charm that comes to them from memory itself and from not being perceived by the senses. The reality I had known no longer existed. That Mme Swann did not arrive exactly the same at the same moment was enough to make the avenue different. The places we have known do not belong solely to the world of space in which we situate them for our greater convenience. They were only a thin slice among contiguous impressions that formed our life at that time; the memory of a certain image is only regret for a certain moment; and houses, roads, avenues are as fleeting, alas, as the years.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_enright_str = \"\"\"\n",
        "How horrible! I exclaimed to myself. Can anyone find these motor-cars as elegant as the old carriage-and-pair? I dare say I am too old now—but I was not intended for a world in which women shackle themselves in garments that are not even made of cloth. To what purpose shall I walk among these trees if there is nothing left now of the assembly that used to gather beneath this delicate tracery of reddening leaves, if vulgarity and folly have supplanted the exquisite thing that their branches once framed. How horrible! My consolation is to think of the women whom I knew in the past, now that there is no elegance left. But how could the people who watch these dreadful creatures hobble by beneath hats on which have been heaped the spoils of aviary or kitchen-garden, how could they even imagine the charm that there was in the sight of Mme Swann in a simple mauve bonnet or a little hat with a single iris sticking up out of it?\n",
        "Could I even have made them understand the emotion that I used to feel on winter mornings, when I met Mme Swann on foot, in an otter-skin coat, with a woolen cap from which stuck out two blade-like partridge-feathers, but enveloped also in the artificial warmth of her own house, which was suggested by nothing more than the bunch of violets crushed into her bosom, whose flowering, vivid and blue against the\n",
        "grey sky, the freezing air, the naked boughs, had the same charming effect of using the season and the weather merely as a setting, and of living actually in a human atmosphere, in the atmosphere of this woman, as had, in the vases and jardinières of her drawing-room, beside the blazing fire, in front of the silk-covered settee, the flowers that looked out through closed windows at the falling snow? But it would not have sufficed me that the costumes alone should still have been the same as those in distant years. Because of the solidarity that binds together the different parts of a general impression that our memory keeps in a balanced whole of which we are not permitted to subtract or to decline any fraction, I should have liked to be able to pass the rest of the day with one of those women, over a cup of tea, in an apartment with dark-painted walls (as Mme Swann’s were still in the year after that in which the first part of this story ends) against which would glow the orange flame, the red combustion, the pink and white flickering of her chrysanthemums in the twilight of a November evening, in moments similar to those in which (as we shall see) I had not managed to discover the pleasures for which I longed. But now, even though they had led to nothing, those moments struck me as having been charming enough in themselves. I wanted to find them again as I remembered them. Alas! there was nothing now but flats decorated in the Louis XVI style, all white, with a sprinkling of blue hydrangeas. Moreover, people did not return to Paris, now, until much later. Mme Swann would have written to me from a country house to say that she would not be in town before February, long after the chrysanthemum season, had I asked her to reconstruct for me the elements of that memory which I felt to belong to a particular distant year, a particular vintage towards which it was forbidden me to ascend again the fatal slope, the\n",
        "elements of that longing which had itself become as inaccessible as the pleasure that it had once vainly pursued.\n",
        "And I should have required also that they should be the same women, those whose costume interested me because, at the time when I still had faith, my imagination had individualised them and had provided each of them with a legend. Alas! in the acacia-avenue—the myrtle-alley—I did see some of them again, grown old, no more now than grim spectres of what they had once been, wandering, desperately searching for heaven knew what, through the Virgilian groves. They had long since fled, and still I stood vainly questioning the deserted paths. The sun had gone. Nature was resuming its reign over the Bois, from which had vanished all trace of the idea that it was the Elysian Garden of Woman; above the gimcrack windmill the real sky was grey; the wind wrinkled the surface of the Grand Lac in little wavelets, like a real lake; large birds flew swiftly over the Bois, as over a real wood, and with shrill cries perched, one after another, on the great oaks which, beneath their Druidical crown, and with Dodonian majesty, seemed to proclaim the inhuman emptiness of this deconsecrated forest, and helped me to understand how paradoxical it is to seek in reality for the pictures that are stored in one’s memory, which must inevitably lose the charm that comes to them from memory itself and from their not being apprehended by the senses. The reality that I had known no longer existed. It sufficed that Mme Swann did not appear, in the same attire and at the same moment, for the whole avenue to be altered.\n",
        "The places we have known do not belong only to the world of space on which we map them for our own convenience. They were only a thin slice, held between the contiguous impressions that composed our life at that time; the memory\n",
        "of a particular image is but regret for a particular moment; and houses, roads, avenues are as fugitive, alas, as the years.\n",
        "\"\"\";\n",
        "\n",
        "english_translation_moncrieff_str = \"\"\"\n",
        "\"Oh, horrible!\" I exclaimed to myself: \"Does anyone really imagine that\n",
        "these motor-cars are as smart as the old carriage-and-pair? I dare say.\n",
        "I am too old now--but I was not intended for a world in which women\n",
        "shackle themselves in garments that are not even made of cloth. To what\n",
        "purpose shall I walk among these trees if there is nothing left now of\n",
        "the assembly that used to meet beneath the delicate tracery of reddening\n",
        "leaves, if vulgarity and fatuity have supplanted the exquisite thing\n",
        "that once their branches framed? Oh, horrible! My consolation is to\n",
        "think of the women whom I have known, in the past, now that there is\n",
        "no standard left of elegance. But how can the people who watch these\n",
        "dreadful creatures hobble by, beneath hats on which have been heaped\n",
        "the spoils of aviary or garden-bed,--how can they imagine the charm that\n",
        "there was in the sight of Mme. Swann, crowned with a close-fitting lilac\n",
        "bonnet, or with a tiny hat from which rose stiffly above her head a\n",
        "single iris?\" Could I ever have made them understand the emotion that\n",
        "I used to feel on winter mornings, when I met Mme. Swann on foot, in an\n",
        "otter-skin coat, with a woollen cap from which stuck out two blade-like\n",
        "partridge-feathers, but enveloped also in the deliberate, artificial\n",
        "warmth of her own house, which was suggested by nothing more than the\n",
        "bunch of violets crushed into her bosom, whose flowering, vivid and blue\n",
        "against the grey sky, the freezing air, the naked boughs, had the same\n",
        "charming effect of using the season and the weather merely as a setting,\n",
        "and of living actually in a human atmosphere, in the atmosphere of this\n",
        "woman, as had in the vases and beaupots of her drawing-room, beside the\n",
        "blazing fire, in front of the silk-covered sofa, the flowers that looked\n",
        "out through closed windows at the falling snow? But it would not have\n",
        "sufficed me that the costumes alone should still have been the same as\n",
        "in those distant years. Because of the solidarity that binds together\n",
        "the different parts of a general impression, parts that our memory keeps\n",
        "in a balanced whole, of which we are not permitted to subtract or to\n",
        "decline any fraction, I should have liked to be able to pass the rest\n",
        "of the day with one of those women, over a cup of tea, in a little house\n",
        "with dark-painted walls (as Mme. Swann's were still in the year after\n",
        "that in which the first part of this story ends) against which would\n",
        "glow the orange flame, the red combustion, the pink and white flickering\n",
        "of her chrysanthemums in the twilight of a November evening, in moments\n",
        "similar to those in which (as we shall see) I had not managed to\n",
        "discover the pleasures for which I longed. But now, albeit they had led\n",
        "to nothing, those moments struck me as having been charming enough in\n",
        "themselves. I sought to find them again as I remembered them. Alas!\n",
        "there was nothing now but flats decorated in the Louis XVI style, all\n",
        "white paint, with hortensias in blue enamel. Moreover, people did not\n",
        "return to Paris, now, until much later. Mme. Swann would have written to\n",
        "me, from a country house, that she would not be in town before February,\n",
        "had I asked her to reconstruct for me the elements of that memory which\n",
        "I felt to belong to a distant era, to a date in time towards which it\n",
        "was forbidden me to ascend again the fatal slope, the elements of that\n",
        "longing which had become, itself, as inaccessible as the pleasure that\n",
        "it had once vainly pursued. And I should have required also that they\n",
        "be the same women, those whose costume interested me because, at a time\n",
        "when I still had faith, my imagination had individualised them and had\n",
        "provided each of them with a legend. Alas! in the acacia-avenue--the\n",
        "myrtle-alley--I did see some of them again, grown old, no more now\n",
        "than grim spectres of what once they had been, wandering to and fro, in\n",
        "desperate search of heaven knew what, through the Virgilian groves. They\n",
        "had long fled, and still I stood vainly questioning the deserted paths.\n",
        "The sun's face was hidden. Nature began again to reign over the Bois,\n",
        "from which had vanished all trace of the idea that it was the Elysian\n",
        "Garden of Woman; above the gimcrack windmill the real sky was grey; the\n",
        "wind wrinkled the surface of the Grand Lac in little wavelets, like\n",
        "a real lake; large birds passed swiftly over the Bois, as over a real\n",
        "wood, and with shrill cries perched, one after another, on the great\n",
        "oaks which, beneath their Druidical crown, and with Dodonaic majesty,\n",
        "seemed to proclaim the unpeopled vacancy of this estranged forest, and\n",
        "helped me to understand how paradoxical it is to seek in reality for the\n",
        "pictures that are stored in one's memory, which must inevitably lose\n",
        "the charm that comes to them from memory itself and from their not\n",
        "being apprehended by the senses. The reality that I had known no longer\n",
        "existed. It sufficed that Mme. Swann did not appear, in the same attire\n",
        "and at the same moment, for the whole avenue to be altered. The places\n",
        "that we have known belong now only to the little world of space on which\n",
        "we map them for our own convenience. None of them was ever more than a\n",
        "thin slice, held between the contiguous impressions that composed our\n",
        "life at that time; remembrance of a particular form is but regret for a\n",
        "particular moment; and houses, roads, avenues are as fugitive, alas, as\n",
        "the years.\n",
        "\"\"\";\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb7T0OCmlABK"
      },
      "source": [
        "## Translation Rubrics (pick one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep_0Ha-GlFLY"
      },
      "source": [
        "### (a) Count 4: Merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX6DgHbblhQ6"
      },
      "outputs": [],
      "source": [
        "SCORING_RUBRIC_FOUR = \"\"\"\n",
        "Evaluate the English translation of the French text using the following criteria, each scored from 0(terrible) to 5 (perfect):\n",
        "A. Accuracy-Adequacy (40%): Does the translation fully convey the meaning, intent, and information of the source text with minimal or no errors?\n",
        "B. Fluency-Readability (30%): Is the translation  fluent, with natural phrasing, correct grammar, and excellent readability, closely resembling native language usage?\n",
        "C. Terminology-Consistency-Style (20%): Consistently uses accurate and appropriate terminology/domain-specific terms, maintaining a consistent style, tone, and register throughout?\n",
        "D. Cultural-Linguistic-Appropriateness (10%): Does the translation handle cultural element, nuances, and idiomatic expressions effectively, reflecting the target language and culture?\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffpwaqJRlI-P"
      },
      "source": [
        "### (b) Count 8: Jon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXZ9uNA5cIMH"
      },
      "outputs": [],
      "source": [
        "SCORING_RUBRIC_EIGHT = \"\"\"\n",
        "Evaluate the quality of the ##ENGLISH_TRANSLATION of the ###FRENCH_ORIGINAL text using the following criteria, each scored from 0(terrible) to 5 (perfect):\n",
        "\n",
        "1. Accuracy-Adequacy: Preserves source language meaning, information, and fidelity to the source text.\n",
        "\n",
        "2. Fluency: Preserves naturalness, readability, and grammatical correctness of the target language.\n",
        "\n",
        "3. Terminology: Accurate and consistent use of domain-specific terms.\n",
        "\n",
        "4. Style-Tone: Adheres to the appropriate tone, register, formality, and alignment with the source text and target audience.\n",
        "\n",
        "5. Cultural-Appropriateness: Conveys cultural nuances, context-specific meanings, and idiomatic expressions.\n",
        "\n",
        "6. Consistency: Has coherence and cohesion within the translated text, including pronoun agreement and discourse markers.\n",
        "\n",
        "7. Punctuation-Format: Correctness of punctuation and adherence to formatting guidelines.\n",
        "\n",
        "8. Idiomatic: Correct use of idiomatic expressions in the target language, ensuring they are contextually appropriate and sound natural.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOz0_h4MlLPI"
      },
      "source": [
        "### (c) Count 8: Kate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyPsHlB-lNLH"
      },
      "outputs": [],
      "source": [
        "# KATE 5/28/2024\n",
        "# Sentiment (0 very negative to 5 very positive)\n",
        "# Formality: (0 conversational to 5 formal tone)\n",
        "# Impersonality: (0 very personal to 5 very impersonal)\n",
        "# Lexical Density: (0 to 5)\n",
        "# Lexical Diversity: (0 to 5)\n",
        "\n",
        "\n",
        "SCORING_RUBRIC_EIGHT = \"\"\"\n",
        "Evaluate the quality of the ##ENGLISH_TRANSLATION of the ###FRENCH_ORIGINAL text using the following criteria, each scored from 0(terrible) to 5 (perfect):\n",
        "\n",
        "1. Accuracy-Adequacy: Preserves source language meaning, information, and fidelity to the source text.\n",
        "\n",
        "2. Fluency: Preserves naturalness, readability, and grammatical correctness of the target language.\n",
        "\n",
        "3. Terminology: Accurate and consistent use of domain-specific terms.\n",
        "\n",
        "4. Style-Tone: Adheres to the appropriate tone, register, formality, and alignment with the source text and target audience.\n",
        "\n",
        "5. Cultural-Appropriateness: Conveys cultural nuances, context-specific meanings, and idiomatic expressions.\n",
        "\n",
        "6. Consistency: Has coherence and cohesion within the translated text, including pronoun agreement and discourse markers.\n",
        "\n",
        "7. Punctuation-Format: Correctness of punctuation and adherence to formatting guidelines.\n",
        "\n",
        "8. Idiomatic: Correct use of idiomatic expressions in the target language, ensuring they are contextually appropriate and sound natural.\n",
        "\n",
        "\"\"\";\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqLNZq62HImu"
      },
      "source": [
        "# Get Raw Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuZxqDOJb9LE"
      },
      "source": [
        "### Upload Hand-Cleaned Files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        " book_proust_en_swans-way_davis_original_verified.txt\n",
        " book_proust_en_swans-way_enright_original_verified.txt\n",
        " book_proust_en_swans-way_moncrieff_original_verified.txt\n",
        " book_proust_fr_swans-way_proust_original_verified.txt\n",
        " ```"
      ],
      "metadata": {
        "id": "SkWNPu0MB6Ec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vq8JEhwI9Yo"
      },
      "outputs": [],
      "source": [
        "# 20240525 Get clean segmented text for individual book translations\n",
        "# e.g. data/step1_segments/book_proust_en_swans-way_davis/book_proust_en_swans-way_davis_sentence_clean.txt\n",
        "\n",
        "# Upload combo files:\n",
        "\n",
        "uploaded_raw_text = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR4qPj4kAcwx"
      },
      "outputs": [],
      "source": [
        "# !ls *_clean.txt\n",
        "!ls *_verified.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYIQ5aLmAgxD"
      },
      "outputs": [],
      "source": [
        "filenames_in_list = [f for f in os.listdir() if f.endswith('_verified.txt')]\n",
        "print(filenames_in_list)\n",
        "print(f\"\\n TOTAL: {len(filenames_in_list)} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F_TqVuXK6KY"
      },
      "outputs": [],
      "source": [
        "# print(uploaded_raw_text)\n",
        "\n",
        "!head -n 10 book_proust_en_swans-way_davis_original_verified.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSdxnj2FcBFt"
      },
      "source": [
        "### Read File into Clean String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8qsVTkIRQrV"
      },
      "outputs": [],
      "source": [
        "def read_file_to_text(filename_in):\n",
        "    \"\"\"\n",
        "    Reads a text file, handles multiple languages and encodings,\n",
        "    removes non-printable and illegal characters, and returns a clean string in UTF-8.\n",
        "\n",
        "    Parameters:\n",
        "    filename_in (str): The input filename.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned string with only printable characters in UTF-8 encoding.\n",
        "    \"\"\"\n",
        "    # Read the raw bytes from the file\n",
        "    with open(filename_in, 'rb') as file:\n",
        "        raw_data = file.read()\n",
        "\n",
        "    # Detect the encoding of the file\n",
        "    detected_encoding = chardet.detect(raw_data)['encoding']\n",
        "\n",
        "    # Decode the raw data to a string\n",
        "    decoded_text = raw_data.decode(detected_encoding, errors='ignore')\n",
        "\n",
        "    # Fix text encoding issues\n",
        "    fixed_text = ftfy.fix_text(decoded_text)\n",
        "\n",
        "    # Normalize the text to NFKD (Normalization Form KD)\n",
        "    normalized_text = unicodedata.normalize('NFKD', fixed_text)\n",
        "\n",
        "    # Create a set of all printable characters\n",
        "    printable_chars = set(string.printable)\n",
        "\n",
        "    # Filter out non-printable characters\n",
        "    cleaned_text = ''.join(c for c in normalized_text if c in printable_chars)\n",
        "\n",
        "    # Ensure the cleaned text is in UTF-8 encoding\n",
        "    cleaned_text_utf8 = cleaned_text.encode('utf-8').decode('utf-8')\n",
        "\n",
        "    return cleaned_text_utf8\n",
        "\n",
        "# Example usage (commented out for PCI):\n",
        "# cleaned = read_file_to_text('example.txt')\n",
        "# print(cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VlW60tuRbz4"
      },
      "outputs": [],
      "source": [
        "# Read File to Text\n",
        "clean_text_dict = {}\n",
        "for filename_index, filename_now in enumerate(filenames_in_list):\n",
        "  print(f\"PROCESSSING #{filename_index}: {filename_now}\")\n",
        "  clean_text_dict[filename_now] = read_file_to_text(filename_now)\n",
        "  print(f\"LENGTH: {len(clean_text_dict[filename_now])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajY-fo39Rbu7"
      },
      "outputs": [],
      "source": [
        "for filename_in_list_now in clean_text_dict.keys():\n",
        "  print(f\"FILENAME: {filename_in_list_now}\")\n",
        "  print(clean_text_dict[filename_in_list_now][:500])\n",
        "  print(\"\\n\\n==========\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEhQ0i5qPWZb"
      },
      "outputs": [],
      "source": [
        "def reformat_paragraphs(text_output: str) -> str:\n",
        "    \"\"\"\n",
        "    Reformats the paragraphs in the given text to remove hard returns.\n",
        "\n",
        "    Parameters:\n",
        "    text_output (str): The input text to be reformatted.\n",
        "\n",
        "    Returns:\n",
        "    str: The reformatted text with hard returns removed.\n",
        "    \"\"\"\n",
        "    # Split the text into paragraphs based on blank lines (one or more newlines)\n",
        "    paragraphs = re.split(r'\\n\\s*\\n', text_output.strip())\n",
        "\n",
        "    # Process each paragraph to remove hard returns\n",
        "    reformatted_paragraphs = []\n",
        "    for paragraph in paragraphs:\n",
        "        # Replace hard returns (newlines within a paragraph) with a space\n",
        "        reformatted_paragraph = paragraph.replace('\\n', ' ')\n",
        "        reformatted_paragraphs.append(reformatted_paragraph)\n",
        "\n",
        "    # Join paragraphs back with double newlines to separate them\n",
        "    reformatted_text = '\\n\\n'.join(reformatted_paragraphs)\n",
        "\n",
        "    return reformatted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25-a-hVWPWWG"
      },
      "outputs": [],
      "source": [
        "def write_str_to_file(directory_output: str, filename_output: str, text_output: str) -> bool:\n",
        "    \"\"\"\n",
        "    Writes the given text to a file in the specified output directory after checking for hard returns within paragraphs.\n",
        "\n",
        "    Parameters:\n",
        "    directory_output (str): The directory where the file will be saved.\n",
        "    filename_output (str): The name of the output file.\n",
        "    text_output (str): The text to be written to the file.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the file is written successfully, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure the output directory exists\n",
        "        if not os.path.exists(directory_output):\n",
        "            os.makedirs(directory_output)\n",
        "\n",
        "        # Reformat the text to remove hard returns within paragraphs\n",
        "        reformatted_text = reformat_paragraphs(text_output)\n",
        "\n",
        "        # Determine the full path for the output file\n",
        "        output_file_path = os.path.join(directory_output, filename_output)\n",
        "\n",
        "        # Write the reformatted text to the output file\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(reformatted_text)\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example usage (commented out for PCI):\n",
        "# result = write_str_to_file('output_directory', 'cleaned_text_file.txt', 'This is a sample text with hard returns within paragraphs.\\nHere is the next line of the same paragraph.\\n\\nThis is a new paragraph.')\n",
        "# print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlyDkyoAaJKC"
      },
      "outputs": [],
      "source": [
        "# Specify the output directory\n",
        "directory_clean_output = \"./clean\"\n",
        "\n",
        "clean_text_reformat_dict = {}\n",
        "\n",
        "# Iterate over the dictionary\n",
        "for filename_input, cleaned_text in clean_text_dict.items():\n",
        "    # Print the processing message\n",
        "    print(f\"PROCESSING: {filename_input}\")\n",
        "\n",
        "    # Create the output filename by replacing '_verified.txt' with '_cleaned.txt'\n",
        "    filename_output = filename_input.replace('_verified.txt', '_cleaned.txt')\n",
        "\n",
        "    # Call the function to write the cleaned text to the file\n",
        "    result = write_str_to_file(directory_clean_output, filename_output, cleaned_text)\n",
        "\n",
        "    # Create clean reformatted text dictionary\n",
        "    clean_text_reformat_dict[filename_input] = reformat_paragraphs(clean_text_dict[filename_input])\n",
        "\n",
        "    # Print the result of the call\n",
        "    print(f\"Result of writing {filename_output}: {result}\")\n",
        "\n",
        "# Example usage (commented out for PCI):\n",
        "# clean_text_dict = {\n",
        "#     'book_proust_en_swans-way_moncrieff_original_verified.txt': 'Cleaned text content for book 1.',\n",
        "#     'another_book_verified.txt': 'Cleaned text content for another book.',\n",
        "#     # Add more entries as needed\n",
        "# }\n",
        "# directory_clean_output = \"./\"\n",
        "# for filename_input, cleaned_text in clean_text_dict.items():\n",
        "#     print(f\"PROCESSING: {filename_input}\")\n",
        "#     filename_output = filename_input.replace('_verified.txt', '_cleaned.txt')\n",
        "#     result = write_str_to_file(directory_clean_output, filename_output, cleaned_text)\n",
        "#     print(f\"Result of writing {filename_output}: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y89dOY9jWbac"
      },
      "outputs": [],
      "source": [
        "for text_name, text_clean in clean_text_reformat_dict.items():\n",
        "  print(f\"FILENAME: {text_name}\")\n",
        "  print(text_clean[:3000])\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L0UvXR8cuvV"
      },
      "source": [
        "# A. Segment Text: Create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQjgWgrefz0l"
      },
      "outputs": [],
      "source": [
        "def detect_language_from_filename(filename: str) -> str:\n",
        "    \"\"\"\n",
        "    Detects the language from the given filename based on substrings '_en_', '_fr_', '_de_'.\n",
        "\n",
        "    Parameters:\n",
        "    filename (str): The filename to extract the language code from.\n",
        "\n",
        "    Returns:\n",
        "    str: The language code ('en', 'fr', 'de').\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"FILENAME: {filename}\")\n",
        "    if '_en_' in filename:\n",
        "        return 'en'\n",
        "    elif '_fr_' in filename:\n",
        "        return 'fr'\n",
        "    elif '_de_' in filename:\n",
        "        return 'de'\n",
        "    else:\n",
        "        # Default to English if language detection fails\n",
        "        return 'en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKBsMCoOf5w-"
      },
      "outputs": [],
      "source": [
        "for filename_clean_now in os.listdir(directory_clean_output):\n",
        "  print(f\"FILENAME: {filename_clean_now}\")\n",
        "  print(f\"          {detect_language_from_filename(filename_clean_now)}\")\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOWnoTVCTKF6"
      },
      "outputs": [],
      "source": [
        "# Ensure consistent language detection\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "def detect_language(text_str: str) -> str:\n",
        "    \"\"\"\n",
        "    Detects the language of the given text using langdetect.\n",
        "\n",
        "    Parameters:\n",
        "    text_str (str): The input text whose language needs to be detected.\n",
        "\n",
        "    Returns:\n",
        "    str: The language code ('en', 'fr', 'de').\n",
        "    \"\"\"\n",
        "    lang = detect(text_str)\n",
        "    if '_en_' in lang:\n",
        "        return 'en'\n",
        "    elif '_fr_' in lang:\n",
        "        return 'fr'\n",
        "    elif '_de_' in lang:\n",
        "        return 'de'\n",
        "    else:\n",
        "        # Default to English if language detection fails\n",
        "        return 'en'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiUQPqZmVHoU"
      },
      "outputs": [],
      "source": [
        "def segment_text(text_str: str, segment_type: str, language_code: str = 'en') -> List[str]:\n",
        "    \"\"\"\n",
        "    Segments the input text into a list of strings based on the segment_type method.\n",
        "\n",
        "    Parameters:\n",
        "    text_str (str): The input text to be segmented.\n",
        "    segment_type (str): The method of segmentation ('sentence', 'paragraph', 'windowDDDD').\n",
        "    language_code (str): The language code for sentence segmentation ('en', 'fr', 'de'). If None, detect language automatically.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of segmented strings.\n",
        "    \"\"\"\n",
        "    # Detect the language of the text if not provided\n",
        "    if language_code is None:\n",
        "        language_code = detect_language(text_str)\n",
        "\n",
        "    if segment_type == 'sentence':\n",
        "        if language_code == 'en':\n",
        "            # Use PySBD for English\n",
        "            print(f\"USING PySBD FOR LANGUAGE CODE: {language_code}\")\n",
        "            segmenter = pysbd.Segmenter(language=language_code, clean=False)\n",
        "            segments = segmenter.segment(text_str)\n",
        "            segments = [x.strip() for x in segments]\n",
        "            return segments\n",
        "        elif language_code == 'fr':\n",
        "            # Use improved RegEx for French\n",
        "            # print(f\"USING RegEx FOR LANGUAGE CODE: {language_code}\")\n",
        "            # sentence_endings = re.compile(r'(?<=[.!?])\\s+|(?<=;\\s)')\n",
        "            # segments = sentence_endings.split(text_str)\n",
        "            print(f\"USING PySBD FOR LANGUAGE CODE: {language_code}\")\n",
        "            segmenter = pysbd.Segmenter(language=language_code, clean=False)\n",
        "            segments = segmenter.segment(text_str)\n",
        "            segments = [x.strip() for x in segments]\n",
        "            return segments\n",
        "        elif language_code == 'de':\n",
        "            # Use SpaCy for German\n",
        "            # print(f\"USING SpaCy FOR LANGUAGE CODE: {language_code}\")\n",
        "            # nlp = spacy.load('de_core_news_lg')\n",
        "            # doc = nlp(text_str)\n",
        "            # segments = [sent.text for sent in doc.sents]\n",
        "            print(f\"USING PySBD FOR LANGUAGE CODE: {language_code}\")\n",
        "            segmenter = pysbd.Segmenter(language=language_code, clean=False)\n",
        "            segments = segmenter.segment(text_str)\n",
        "            segments = [x.strip() for x in segments]\n",
        "            return segments\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid language code: {language_code}\")\n",
        "\n",
        "    elif segment_type == 'paragraph':\n",
        "        # Split paragraphs based on one or more blank lines\n",
        "        return re.split(r'\\n\\s*\\n', text_str.strip())\n",
        "\n",
        "    elif segment_type.startswith('window'):\n",
        "        # Extract the window size from segment_type (e.g., 'window500')\n",
        "        match = re.match(r'window(\\d+)', segment_type)\n",
        "        if match:\n",
        "            window_size = int(match.group(1))\n",
        "            words = text_str.split()\n",
        "            # Ensure the window size chunking is done by word tokens\n",
        "            segments = [' '.join(words[i:i + window_size]) for i in range(0, len(words), window_size)]\n",
        "            return segments\n",
        "        else:\n",
        "            raise ValueError(\"Invalid segment_type format for 'window'. It should be like 'window500'.\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid segment_type. It should be 'sentence', 'paragraph', or 'windowDDDD'.\")\n",
        "\n",
        "# Example usage (commented out for PCI):\n",
        "# text = \"This is a sample text. It contains multiple sentences. And also paragraphs.\\n\\nThis is a new paragraph.\"\n",
        "# segments = segment_text(text, 'sentence', 'en')\n",
        "# print(segments)\n",
        "# segments = segment_text(text, 'paragraph')\n",
        "# print(segments)\n",
        "# segments = segment_text(text, 'window500')\n",
        "# print(segments)\n",
        "\n",
        "# Example usage with French text (commented out for PCI):\n",
        "# clean_text_dict = {\n",
        "#     'book_proust_fr_swans-way_proust_original_verified.txt': \"Longtemps, je me suis couché de bonne heure. Parfois, à peine ma bougie éteinte, mes yeux se fermaient si vite que je n'avais pas le temps de me dire: 'Je m'endors.' Et, une demi-heure après, la pensée qu'il était temps de chercher le sommeil m'éveillait; je voulais poser le volume que je croyais avoir encore dans les mains et souffler ma lumière.\"\n",
        "# }\n",
        "# segments = segment_text(clean_text_dict['book_proust_fr_swans-way_proust_original_verified.txt'], 'sentence', 'fr')\n",
        "# print(segments[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8o8qzIIkrtV"
      },
      "outputs": [],
      "source": [
        "# segments_list = segment_text(clean_text_reformat_dict['book_proust_fr_swans-way_proust_original_verified.txt'], 'sentence', 'fr')\n",
        "# print(segments_list[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfdSFSm6dw2T"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# segment_text\n",
        "clean_text_reformat_seg_dict = {}\n",
        "\n",
        "# Loop over each key in clean_text_reformat_dict\n",
        "for key in clean_text_reformat_dict.keys():\n",
        "    print(f\"PROCESSING: {key}\")\n",
        "    # Extract the language code from the filename key\n",
        "    language_code = detect_language_from_filename(key)\n",
        "    # Call segment_text() for each value with the extracted language code\n",
        "    segments_list = segment_text(clean_text_reformat_dict[key], 'sentence', language_code)\n",
        "    # Save the resulting list of strings into the new dictionary\n",
        "    clean_text_reformat_seg_dict[key] = segments_list\n",
        "\n",
        "# Example: Print the first 5 sentences for each key to verify\n",
        "for key, segments in clean_text_reformat_seg_dict.items():\n",
        "    print(f\"Key: {key}\")\n",
        "    print(\"First 5 sentences:\")\n",
        "    for segment in segments[:5]:\n",
        "        print(segment)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJIvCiqCbZhp"
      },
      "source": [
        "## Filter out Subtitles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEayZFEqgh6S"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HJEuMPjgh10"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_dict['book_proust_en_swans-way_moncrieff_original_verified.txt'][:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gsF0ljrkhOT"
      },
      "outputs": [],
      "source": [
        "%whos dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for akey in clean_text_reformat_seg_dict.keys():\n",
        "  print(f\"{akey}: {len(clean_text_reformat_seg_dict[akey])}\")"
      ],
      "metadata": {
        "id": "iXQOJ-BbE59q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3FR4n3MhFvm"
      },
      "outputs": [],
      "source": [
        "def filter_lines(segments_list, segment_char_min=5):\n",
        "    \"\"\"\n",
        "    Filters the input list of strings based on specified criteria.\n",
        "\n",
        "    Parameters:\n",
        "    segments_list (List[str]): The input list of strings to be filtered.\n",
        "    segment_char_min (int): Minimum number of characters a line must have to not be filtered out.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: The filtered list of strings.\n",
        "    \"\"\"\n",
        "    def is_blank_or_non_printing(line):\n",
        "        return not line.strip()\n",
        "\n",
        "    def is_all_caps(line):\n",
        "        return line.isupper() and not any(c.islower() for c in line)\n",
        "\n",
        "    def is_only_numbers(line):\n",
        "        arabic_numbers = r'^\\d+[\\s]*[.!?,;:]*$'\n",
        "        roman_numerals = r'\\b(M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3}))\\b[\\s]*[.!?,;:]*$'\n",
        "        number_words = r'^(zero|one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred|thousand|million|billion)[\\s]*[.!?,;:]*$'\n",
        "        return bool(re.match(arabic_numbers, line, re.IGNORECASE) or\n",
        "                    re.match(roman_numerals, line, re.IGNORECASE) or\n",
        "                    re.match(number_words, line, re.IGNORECASE))\n",
        "\n",
        "    def starts_with_chapter_section_part_episode_book(line):\n",
        "        pattern = r'^(Chapter|Section|Part|Episode|Book)(\\s+[\\dIVXLCDM]+[\\s]*[.!?,;:]*|[.!?,;:]*\\s*[\\dIVXLCDM]*)?$'\n",
        "        return bool(re.match(pattern, line, re.IGNORECASE))\n",
        "\n",
        "    filtered_segments = []\n",
        "    for line in segments_list:\n",
        "        trimmed_line = line.strip()\n",
        "        if (len(trimmed_line) < segment_char_min or\n",
        "            is_blank_or_non_printing(trimmed_line) or\n",
        "            is_all_caps(trimmed_line) or\n",
        "            is_only_numbers(trimmed_line) or\n",
        "            starts_with_chapter_section_part_episode_book(trimmed_line)):\n",
        "            continue\n",
        "        filtered_segments.append(line)\n",
        "\n",
        "    return filtered_segments\n",
        "\"\"\"\n",
        "# Example usage (commented out for PCI):\n",
        "# Process each file and segment text\n",
        "\n",
        "directory_clean_output = './clean'\n",
        "for filename_clean_now in os.listdir(directory_clean_output):\n",
        "    print(f\"PROCESSING: {filename_clean_now}\")\n",
        "    filepath = os.path.join(directory_clean_output, filename_clean_now)\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    language_code = detect_language(content)\n",
        "    # segments = segment_text(content, 'sentence', language_code)\n",
        "    filtered_segments = filter_lines(segments)\n",
        "\n",
        "    print(f\"FILENAME: {filename_clean_now}\")\n",
        "    print(\"First 5 sentences:\")\n",
        "    for segment in filtered_segments[:5]:\n",
        "        print(segment)\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlKpaZaKhrAM"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2KzqfWnhsyF"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_dict[\"book_proust_en_swans-way_davis_original_verified.txt\"][:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TTTKUuLehMe"
      },
      "outputs": [],
      "source": [
        "# CREATE: clean_text_reformat_seg_filter_dict\n",
        "clean_text_reformat_seg_filter_dict = {}\n",
        "\n",
        "# Loop over each key in clean_text_reformat_dict\n",
        "for key in clean_text_reformat_seg_dict.keys():\n",
        "    print(f\"PROCESSING: {key}\")\n",
        "    # Extract the language code from the filename key\n",
        "    language_code = detect_language_from_filename(key)\n",
        "    # Call segment_text() for each value with the extracted language code\n",
        "    segments_list = filter_lines(clean_text_reformat_seg_dict[key])\n",
        "    # Save the resulting list of strings into the new dictionary\n",
        "    clean_text_reformat_seg_filter_dict[key] = segments_list\n",
        "\n",
        "# Example: Print the first 5 sentences for each key to verify\n",
        "for key, segments in clean_text_reformat_seg_filter_dict.items():\n",
        "    print(f\"Key: {key}\")\n",
        "    print(\"First 5 sentences:\")\n",
        "    for segment_index, segment_str in enumerate(segments[:10]):\n",
        "        print(f\"  Line #{segment_index}: {segment_str}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc3RmM2geg0t"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea-bjwd8mLhF"
      },
      "source": [
        "## Save Clean Filtered Segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJTgshzNkZtx"
      },
      "outputs": [],
      "source": [
        "def write_dict_of_lists_to_files(directory_out, dict_of_lists, segment_type='segments'):\n",
        "    \"\"\"\n",
        "    Saves each list of strings from the dictionary to separate files in the specified directory.\n",
        "\n",
        "    Parameters:\n",
        "    directory_out (str): The directory where the files will be saved.\n",
        "    dict_of_lists (dict): Dictionary where keys are filenames and values are lists of strings.\n",
        "    segment_type (str): The suffix to be added to the output filenames.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with filenames as keys and their paths as values.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    file_paths = {}\n",
        "\n",
        "    for key in dict_of_lists.keys():\n",
        "        # Create the output filename\n",
        "        filename_out = key.replace('_verified.txt', f'_{segment_type}.txt')\n",
        "        output_file_path = os.path.join(directory_out, filename_out)\n",
        "\n",
        "        # Debug: Print the current filename and output path\n",
        "        print(f\"Saving file: {output_file_path}\")\n",
        "\n",
        "        # Write the list of strings to the file, one string per line\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "            for i, line in enumerate(dict_of_lists[key]):\n",
        "                file.write(line + '\\n')\n",
        "                # Print only the first few lines for debugging\n",
        "                if i < 5:\n",
        "                    print(f\"Writing line {i+1}: {line}\")\n",
        "                elif i == 5:\n",
        "                    print(\"... (more lines not shown)\")\n",
        "\n",
        "        # Store the filename and its path in the dictionary\n",
        "        file_paths[filename_out] = output_file_path\n",
        "\n",
        "    return file_paths\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segmented_file_paths = write_dict_of_lists_to_files('./segmented', clean_text_reformat_seg_filter_dict, 'segments')\n",
        "print(segmented_file_paths)\n",
        "\n",
        "# Verify the content of the files by reading them back\n",
        "for filename, filepath in segmented_file_paths.items():\n",
        "    print(f\"Verifying content of {filename}:\")\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        for i, line in enumerate(file):\n",
        "            if i < 5:\n",
        "                print(line.strip())\n",
        "            elif i == 5:\n",
        "                print(\"... (more lines not shown)\")\n",
        "                break\n"
      ],
      "metadata": {
        "id": "zr9Ldbb3K261"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a zip archive of these files\n",
        "subdir = 'segmented'\n",
        "\n",
        "# Zip the subdirectory\n",
        "shutil.make_archive(subdir, 'zip', subdir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(subdir + '.zip')"
      ],
      "metadata": {
        "id": "b7FvzeEsA-Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqox3TFHxnD-"
      },
      "source": [
        "# B. Segment Text: Upload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%whos dict"
      ],
      "metadata": {
        "id": "2cQKvvl7zctk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ],
      "metadata": {
        "id": "TmvuPwtSzlKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(clean_text_reformat_seg_filter_dict[list(clean_text_reformat_seg_filter_dict.keys())[0]])"
      ],
      "metadata": {
        "id": "4-en7WK4zIIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_segments(segments_subdir=\"segmented\", overwrite_flag=False):\n",
        "    \"\"\"\n",
        "    Uploads multiple files to the specified directory in the Colab VM.\n",
        "\n",
        "    Parameters:\n",
        "    segments_subdir (str): The subdirectory where the files will be uploaded.\n",
        "    overwrite_flag (bool): If True, existing files will be overwritten.\n",
        "    \"\"\"\n",
        "    # Step 1: Create the directory if it does not exist\n",
        "    if not os.path.exists(segments_subdir):\n",
        "        os.makedirs(segments_subdir)\n",
        "        print(f\"Created directory: {segments_subdir}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {segments_subdir}\")\n",
        "\n",
        "    # Step 2: Upload multiple files\n",
        "    uploaded_files = files.upload()\n",
        "\n",
        "    # Step 3: Move uploaded files to the specified directory, considering the overwrite_flag\n",
        "    for filename in uploaded_files.keys():\n",
        "        src_path = os.path.join(\"/content\", filename)\n",
        "        dest_path = os.path.join(segments_subdir, filename)\n",
        "\n",
        "        if os.path.exists(dest_path):\n",
        "            if overwrite_flag:\n",
        "                shutil.move(src_path, dest_path)\n",
        "                print(f\"Overwritten existing file: {filename}\")\n",
        "            else:\n",
        "                os.remove(src_path)\n",
        "                print(f\"File already exists and overwrite_flag is False: {filename}\")\n",
        "        else:\n",
        "            shutil.move(src_path, dest_path)\n",
        "            print(f\"Saved new file: {filename}\")\n",
        "\n",
        "# Example usage:\n",
        "# upload_segments(\"segmented\", True)\n"
      ],
      "metadata": {
        "id": "efbdMa41CBTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_segments(\"segmented\", False)"
      ],
      "metadata": {
        "id": "Nhou8XmXCDcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def read_txt_files_into_dict_of_lists(directory_in):\n",
        "    \"\"\"\n",
        "    Reads each .txt file from the specified directory and stores the content\n",
        "    into a dictionary with filename roots as keys and lists of strings as values.\n",
        "\n",
        "    Parameters:\n",
        "    directory_in (str): The directory from where the files will be read.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with filename roots as keys and lists of strings as values.\n",
        "    \"\"\"\n",
        "    dict_of_lists = {}\n",
        "\n",
        "    # Iterate over the files in the directory\n",
        "    for filename in os.listdir(directory_in):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(directory_in, filename)\n",
        "\n",
        "            # Read the file and store its lines in a list\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                lines = file.readlines()\n",
        "                lines = [line.strip() for line in lines]  # Strip newline characters\n",
        "\n",
        "            # Remove the suffix to get filename_root\n",
        "            filename_root = filename.replace('_original_segments.txt', '')\n",
        "\n",
        "            # Store the list of strings in the dictionary with the filename_root as the key\n",
        "            dict_of_lists[filename_root] = lines\n",
        "\n",
        "    return dict_of_lists\n"
      ],
      "metadata": {
        "id": "dMNcfb3HyEQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def process_files_in_directory(directory_in='./segmented'):\n",
        "    clean_text_reformat_seg_filter_dict = {}\n",
        "\n",
        "    for afile in os.listdir(directory_in):\n",
        "        file_path = os.path.join(directory_in, afile)\n",
        "        if os.path.isfile(file_path):\n",
        "            print(f\"PROCESS file: {afile}:\")\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                lines_in = file.readlines()\n",
        "                lines_clean_in = [line.strip() for line in lines_in]  # Strip newline characters\n",
        "                filename_key = afile.replace('_original_segments.txt', '')\n",
        "                clean_text_reformat_seg_filter_dict[filename_key] = lines_clean_in\n",
        "        else:\n",
        "            print(f\"Skipping directory: {afile}\")\n",
        "\n",
        "    print(clean_text_reformat_seg_filter_dict.keys())\n",
        "    return clean_text_reformat_seg_filter_dict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t5QipzZOEG0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "clean_text_reformat_seg_filter_dict = process_files_in_directory('./segmented')"
      ],
      "metadata": {
        "id": "4M52B_dWEItR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key,list in clean_text_reformat_seg_filter_dict.items():\n",
        "  print(f\"{key}: {len(list)}\")"
      ],
      "metadata": {
        "id": "D43wAcNYz-sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [END]"
      ],
      "metadata": {
        "id": "HvGWLuAR1-qd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8onV_67z-ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqNJBaHEmKtZ"
      },
      "outputs": [],
      "source": [
        "# Read in cleaned, filtered segments from ./segments/<files>_segements.txt\n",
        "\n",
        "def read_seg_files_to_dict(directory):\n",
        "    \"\"\"\n",
        "    Reads all files in the given directory matching the *_segments.txt pattern and returns a dictionary\n",
        "    with filenames as keys and lists of strings as values.\n",
        "\n",
        "    Parameters:\n",
        "    directory (str): The directory path containing the segment files.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with keys as filenames and values as lists of strings (one per line).\n",
        "    \"\"\"\n",
        "    segments_dictionary = {}\n",
        "\n",
        "    # Ensure the directory path ends with a separator\n",
        "    directory = os.path.join(directory, '')\n",
        "\n",
        "    # Get the list of all files matching *_segments.txt in the directory\n",
        "    file_pattern = os.path.join(directory, '*_segments.txt')\n",
        "    segment_files = glob.glob(file_pattern)\n",
        "\n",
        "    for file_path in segment_files:\n",
        "        # Extract the filename without the directory path\n",
        "        filename = os.path.basename(file_path)\n",
        "\n",
        "        # Read the file contents into a list of strings\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            lines = file.readlines()\n",
        "            segments = [line.strip() for line in lines]\n",
        "\n",
        "        # Store the list of strings in the dictionary\n",
        "        segments_dictionary[filename] = segments\n",
        "\n",
        "    return segments_dictionary\n",
        "\n",
        "# Example usage\n",
        "# directory = './segments_directory'\n",
        "# segments_dict = read_seg_files_to_dict(directory)\n",
        "# print(segments_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPlQuWx5mKqz"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict = read_seg_files_to_dict(\"./segments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujV3pm5KmKnj"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_SZkw8pegx8"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict['book_proust_en_swans-way_moncrieff_original_segments.txt'][:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz7SroGzkZty"
      },
      "outputs": [],
      "source": [
        "# [END]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyk2Mw5cbnmm"
      },
      "outputs": [],
      "source": [
        "segments_list = segments\n",
        "SAMPLE_LEN = 50\n",
        "print(f\"len(segments_list): {len(segments_list)}\")\n",
        "print(f\"segments_list[:SAMPLE_LEN]:\\n\")\n",
        "segments_list_first10 = [segment_now.strip() for segment_now in segments_list[:SAMPLE_LEN]]\n",
        "# Printing the first 10 strings in the list, one per line, after stripping whitespace\n",
        "for segment_now in segments_list_first10[:SAMPLE_LEN]:\n",
        "    print(segment_now.strip())\n",
        "print(f\"segments_list[-SAMPLE_LEN:]:\\n\") #  {segments_list[-SAMPLE_LEN:]}\\n\\n\")\n",
        "segments_list_lastN = [segment_now.strip() for segment_now in segments_list[-SAMPLE_LEN:]]\n",
        "for segment_now in segments_list_lastN: # [-SAMPLE_LEN:]:\n",
        "    print(segment_now.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ie-sncdbnjN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBTu1WI0ReAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SXtO6R9i-hC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Directory containing cleaned files\n",
        "directory_clean_output = './clean'\n",
        "\n",
        "# Iterate over files in the directory\n",
        "dir_file_list_sorted = reversed(sorted(os.listdir(directory_clean_output)))\n",
        "for filename_clean_now in dir_file_list_sorted:\n",
        "    print(f\"FILENAME: {filename_clean_now}\")\n",
        "\n",
        "    # Read the content of the file into a string\n",
        "    filepath = os.path.join(directory_clean_output, filename_clean_now)\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Extract the language code from the filename\n",
        "    try:\n",
        "        language_code = get_language_from_filename(filename_clean_now)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Segment the text using the language code\n",
        "    print(f\"  calling segment_text with language_code = {language_code}\")\n",
        "    segments = segment_text(content, 'sentence', language_code)\n",
        "\n",
        "    # Print the total number of lines\n",
        "    print(f\"Total number of lines: {len(segments)}\")\n",
        "\n",
        "    # Print the first 50 lines\n",
        "    for line in segments[:50]:\n",
        "        print(line)\n",
        "\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SedaODCHs6xJ"
      },
      "outputs": [],
      "source": [
        "%whos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeuG28Kzi-d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns8vh181i-bF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlfzPTvCfcQR"
      },
      "outputs": [],
      "source": [
        "for filename_clean_now in os.listdir(directory_clean_output):\n",
        "  print(f\"FILENAME: {filename_clean_now}\")\n",
        "  print(f\"          {segment_text(filename_clean_now)}\")\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tiivk0wfcMq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIkXAqtpcs-q"
      },
      "outputs": [],
      "source": [
        "def segment_text(text_str: str, segment_type: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Segments the input text into a list of strings based on the segment_type method.\n",
        "\n",
        "    Parameters:\n",
        "    text_str (str): The input text to be segmented.\n",
        "    segment_type (str): The method of segmentation ('sentence', 'paragraph', 'windowDDDD').\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of segmented strings.\n",
        "    \"\"\"\n",
        "    if segment_type == 'sentence':\n",
        "        # Detect the language and use the appropriate SpaCy model\n",
        "        if re.search(r'[a-zA-Z]', text_str):\n",
        "            doc = nlp_en(text_str)\n",
        "        elif re.search(r'[a-zA-Zéèêëàâçùûô]', text_str):\n",
        "            doc = nlp_fr(text_str)\n",
        "        else:\n",
        "            doc = nlp_de(text_str)\n",
        "        return [sent.text for sent in doc.sents]\n",
        "\n",
        "    elif segment_type == 'paragraph':\n",
        "        # Split paragraphs based on one or more blank lines\n",
        "        return re.split(r'\\n\\s*\\n', text_str.strip())\n",
        "\n",
        "    elif segment_type.startswith('window'):\n",
        "        # Extract the window size from segment_type (e.g., 'window500')\n",
        "        match = re.match(r'window(\\d+)', segment_type)\n",
        "        if match:\n",
        "            window_size = int(match.group(1))\n",
        "            words = text_str.split()\n",
        "            segments = [' '.join(words[i:i + window_size]) for i in range(0, len(words), window_size)]\n",
        "            return segments\n",
        "        else:\n",
        "            raise ValueError(\"Invalid segment_type format for 'window'. It should be like 'window500'.\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid segment_type. It should be 'sentence', 'paragraph', or 'windowDDDD'.\")\n",
        "\n",
        "# Example usage (commented out for PCI):\n",
        "# text = \"This is a sample text. It contains multiple sentences. And also paragraphs.\\n\\nThis is a new paragraph.\"\n",
        "# segments = segment_text(text, 'sentence')\n",
        "# print(segments)\n",
        "# segments = segment_text(text, 'paragraph')\n",
        "# print(segments)\n",
        "# segments = segment_text(text, 'window500')\n",
        "# print(segments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqfJd455cs6w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_J4czalZ_PW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlQuvNPGZ_LO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpYlyRY_V-UC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdO12j4V-Q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ9Ep9UfUVRn"
      },
      "outputs": [],
      "source": [
        "clean_text_dict = {}\n",
        "for filename_index, filename_now in enumerate(filenames_in_list):\n",
        "  print(f\"PROCESSSING #{filename_index}: {filename_now}\")\n",
        "  clean_text_dict[filename_now] = read_file_to_text(filename_now)\n",
        "  print(f\"LENGTH: {len(clean_text_dict[filename_now])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-xjKNIuUVO8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo3Skq2uUVLi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNQCRJikD4BO"
      },
      "outputs": [],
      "source": [
        "def remove_unprintable_characters(text):\n",
        "    \"\"\"\n",
        "    Removes or converts unprintable characters from a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned string with printable characters.\n",
        "    \"\"\"\n",
        "    # Normalize the text to NFKD (Normalization Form KD)\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Encode to ASCII bytes, ignoring non-ASCII characters\n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    # Decode back to string\n",
        "    text = text.decode('ascii')\n",
        "    return text\n",
        "\n",
        "def dictionary_of_list_sentences_from_file_list(filenames):\n",
        "    \"\"\"\n",
        "    Reads a list of files and returns a dictionary with translators as keys and lists of sentences as values.\n",
        "\n",
        "    Parameters:\n",
        "    filenames (list of str): A list of filenames to read.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with translator names as keys and lists of sentences as values.\n",
        "    \"\"\"\n",
        "    translator_dict = {}\n",
        "    translators = ['davis', 'enright', 'moncrieff', 'proust']\n",
        "\n",
        "    for filename in filenames:\n",
        "        # Identify the translator's name from the filename\n",
        "        translator = None\n",
        "        for t in translators:\n",
        "            if re.search(fr'_{t}_', filename):\n",
        "                translator = t\n",
        "                break\n",
        "\n",
        "        if translator is None:\n",
        "            raise ValueError(f\"Translator not found in filename: {filename}\")\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            sentences = file.readlines()\n",
        "            # Remove trailing newline characters and unprintable characters\n",
        "            sentences = [remove_unprintable_characters(sentence.strip()) for sentence in sentences]\n",
        "            translator_dict[translator] = sentences\n",
        "\n",
        "    return translator_dict\n",
        "\n",
        "# Example usage (ensure you have appropriate files to test this):\n",
        "# filenames = [\n",
        "#     'book_proust_en_swans-way_davis_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_enright_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_moncrieff_sentence_clean.txt',\n",
        "#     'book_proust_fr_swans-way_proust_sentence_clean.txt'\n",
        "# ]\n",
        "translator_sentences_dt = dictionary_of_list_sentences_from_file_list(list_clean_filenames)\n",
        "# Displaying a small sample to avoid large outputs\n",
        "for translator, sentences in translator_sentences_dt.items():\n",
        "    print(f\"Sentence Count: {len(sentences)}\")  # Print only the first 5 sentences for each translator\n",
        "    print(f\"{translator}: {sentences[:5]}\")  # Print only the first 5 sentences for each translator\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYk6cmPrC9Py"
      },
      "outputs": [],
      "source": [
        "print(translator_sentences_dt.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7AUe4vACtfc"
      },
      "outputs": [],
      "source": [
        "print(json.dumps(translator_sentences_dt['davis'][:50], indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPzWPFtyD3HK"
      },
      "outputs": [],
      "source": [
        "print(json.dumps(translator_sentences_dt['davis'][:50], indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqy5_DvrcTcT"
      },
      "outputs": [],
      "source": [
        "translator_sentences_dt.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kncXmKaJP3X5"
      },
      "source": [
        "### [SHORTCUT] LangChain Ollama Sentiment Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzorRQ9NROJH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "response = ollama.chat(model=model_name, messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': 'Explain why love is blind, Ray Charles is blind, yet Ray Charles is not love?',\n",
        "  },\n",
        "])\n",
        "\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6v-Mkdcep2P"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "response = ollama.chat(\n",
        "    model=\"mistral\",\n",
        "    messages='Explain why love is blind, Ray Charles is blind, yet Ray Charles is not love?',\n",
        "    format=\"json\",\n",
        "    options=Options(\n",
        "        temperature=0.0,\n",
        "        num_ctx=100000,\n",
        "        num_predict=-1,\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u90i4Bladr3N"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "response = ollama.generate(\n",
        "    model=model_name,\n",
        "    prompt='Explain why love is blind, Ray Charles is blind, yet Ray Charles is not love?'\n",
        ")\n",
        "\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bzwm9HW8QX5g"
      },
      "outputs": [],
      "source": [
        "print(SENTIMENT_RUBRIC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQUx277Zc2Fq"
      },
      "outputs": [],
      "source": [
        "response = ollama.chat(model=model_name, messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': 'Explain why love is blind, Ray Charles is blind, yet Ray Charles is not love?',\n",
        "  },\n",
        "])\n",
        "\n",
        "print(response['message']['content'])\n",
        "\n",
        "def get_ollama_sentiment(text_str):\n",
        "    \"\"\"\n",
        "    Mock function to simulate sentiment analysis.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    float: A mock sentiment score.\n",
        "    \"\"\"\n",
        "    # construct Prompt\n",
        "    sentiment_prompt = f\"\"\"\n",
        "\n",
        "    ###SENTENCE:\n",
        "    {text_str}\n",
        "\n",
        "    ###INSTRUCTIONS:\n",
        "    {SENTIMENT_RUBRIC}\n",
        "    \"\"\"\n",
        "\n",
        "    sentiment_polarity_float_str = llm.invoke(sentiment_prompt)\n",
        "    print(f\"sentiment_polarity_float_str: \\n\\n{sentiment_polarity_float_str}\\n\\n\")\n",
        "\n",
        "    return sentiment_polarity_float_str  # Replace with actual sentiment analysis call\n",
        "\n",
        "resp_polarity_float_str = get_ollama_sentiment(\"I don't care about lint\")\n",
        "print(f\"resp_polarity_float_str: {resp_polarity_float_str}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pIno8aWdmyZ"
      },
      "outputs": [],
      "source": [
        "            completion = ollama.chat(\n",
        "                model=\"mistral\",\n",
        "                messages=messages,\n",
        "                format=\"json\",\n",
        "                options=Options(\n",
        "                    temperature=0.0,\n",
        "                    num_ctx=100000,\n",
        "                    num_predict=-1,\n",
        "                ),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-q5DHB8c2CL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZifKwtgVe1U"
      },
      "outputs": [],
      "source": [
        "print(f\"USING LLM model_name: {model_name}\")\n",
        "\n",
        "llm = Ollama(model = model_name, temperature=0.0, format=\"JSON\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzSVhq-jP1CN"
      },
      "outputs": [],
      "source": [
        "def get_ollama_sentiment(text_str):\n",
        "    \"\"\"\n",
        "    Mock function to simulate sentiment analysis.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    float: A mock sentiment score.\n",
        "    \"\"\"\n",
        "    # construct Prompt\n",
        "    sentiment_prompt = f\"\"\"\n",
        "\n",
        "    ###SENTENCE:\n",
        "    {text_str}\n",
        "\n",
        "    ###INSTRUCTIONS:\n",
        "    {SENTIMENT_RUBRIC}\n",
        "    \"\"\"\n",
        "\n",
        "    sentiment_polarity_float_str = llm.invoke(sentiment_prompt)\n",
        "    print(f\"sentiment_polarity_float_str: \\n\\n{sentiment_polarity_float_str}\\n\\n\")\n",
        "\n",
        "    return sentiment_polarity_float_str  # Replace with actual sentiment analysis call\n",
        "\n",
        "resp_polarity_float_str = get_ollama_sentiment(\"I don't care about lint\")\n",
        "print(f\"resp_polarity_float_str: {resp_polarity_float_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKyA4dq7bFW9"
      },
      "source": [
        "#### Version #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuEz3OcOO6u-"
      },
      "outputs": [],
      "source": [
        "def remove_unprintable_characters(text):\n",
        "    \"\"\"\n",
        "    Removes or converts unprintable characters from a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned string with printable characters.\n",
        "    \"\"\"\n",
        "    # Normalize the text to NFKD (Normalization Form KD)\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Encode to ASCII bytes, ignoring non-ASCII characters\n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    # Decode back to string\n",
        "    text = text.decode('ascii')\n",
        "    return text\n",
        "\n",
        "def dictionary_of_list_sentences_from_file_list(filenames):\n",
        "    \"\"\"\n",
        "    Reads a list of files and returns a dictionary with translators as keys and lists of sentences as values,\n",
        "    and their corresponding sentiment scores with modified keys.\n",
        "\n",
        "    Parameters:\n",
        "    filenames (list of str): A list of filenames to read.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with translator names as keys and lists of sentences as values,\n",
        "          and sentiment scores with modified keys.\n",
        "    \"\"\"\n",
        "    translator_dict = {}\n",
        "    translators = ['davis', 'enright', 'moncrieff', 'proust']\n",
        "\n",
        "    for filename in filenames:\n",
        "        # Identify the translator's name from the filename\n",
        "        translator = None\n",
        "        for t in translators:\n",
        "            if re.search(fr'_{t}_', filename):\n",
        "                translator = t\n",
        "                break\n",
        "\n",
        "        if translator is None:\n",
        "            raise ValueError(f\"Translator not found in filename: {filename}\")\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            sentences = file.readlines()\n",
        "            # Remove trailing newline characters and unprintable characters\n",
        "            sentences = [remove_unprintable_characters(sentence.strip()) for sentence in sentences]\n",
        "            translator_dict[translator] = sentences\n",
        "\n",
        "            # Calculate sentiment scores for each sentence\n",
        "            sentiment_scores = [get_ollama_sentiment(sentence) for sentence in sentences]\n",
        "            # sentiment_scores = [get_ollama_sentiment(sentence) for sentence in tqdm(sentences, desc=f\"Processing {translator}\")]\n",
        "            sentiment_key = f\"{translator}_sentiment\"\n",
        "            translator_dict[sentiment_key] = sentiment_scores\n",
        "\n",
        "    return translator_dict\n",
        "\n",
        "# Example usage (ensure you have appropriate files to test this):\n",
        "# filenames = [\n",
        "#     'book_proust_en_swans-way_davis_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_enright_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_moncrieff_sentence_clean.txt',\n",
        "#     'book_proust_fr_swans-way_proust_sentence_clean.txt'\n",
        "# ]\n",
        "translator_sentences_dict = dictionary_of_list_sentences_from_file_list(list_clean_filenames)\n",
        "# Displaying a small sample to avoid large outputs\n",
        "for translator, sentences in translator_sentences_dict.items():\n",
        "  print(f\"{translator}: {sentences[:5]}\")  # Print only the first 5 sentences for each translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k2i5qD1YJ7s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "493plGDmbCwr"
      },
      "source": [
        "#### Version #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed_4DEk2YJ1R"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "def remove_unprintable_characters(text):\n",
        "    \"\"\"\n",
        "    Removes or converts unprintable characters from a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned string with printable characters.\n",
        "    \"\"\"\n",
        "    # Normalize the text to NFKD (Normalization Form KD)\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Encode to ASCII bytes, ignoring non-ASCII characters\n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    # Decode back to string\n",
        "    text = text.decode('ascii')\n",
        "    return text\n",
        "\n",
        "def get_ollama_sentiment(text_str):\n",
        "    \"\"\"\n",
        "    Function to simulate sentiment analysis.\n",
        "\n",
        "    Parameters:\n",
        "    text_str (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    float: A sentiment score.\n",
        "    \"\"\"\n",
        "    # Construct Prompt\n",
        "    sentiment_prompt = f\"\"\"\n",
        "\n",
        "    ###SENTENCE:\n",
        "    {text_str}\n",
        "\n",
        "    ###INSTRUCTIONS:\n",
        "    {SENTIMENT_RUBRIC}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Assuming llm.invoke is the method to call the sentiment API\n",
        "        # Mock implementation here for demo purposes\n",
        "        sentiment_polarity_float_str = llm.invoke(sentiment_prompt)\n",
        "        print(f\"sentiment_polarity_float_str: \\n\\n{sentiment_polarity_float_str}\\n\\n\")\n",
        "        return sentiment_polarity_float_str  # Replace with actual sentiment analysis call\n",
        "    except requests.ConnectionError as e:\n",
        "        print(f\"Connection error: {e}\")\n",
        "        return None\n",
        "\n",
        "def dictionary_of_list_sentences_from_file_list(filenames):\n",
        "    \"\"\"\n",
        "    Reads a list of files and returns a dictionary with translators as keys and lists of sentences as values,\n",
        "    and their corresponding sentiment scores with modified keys.\n",
        "\n",
        "    Parameters:\n",
        "    filenames (list of str): A list of filenames to read.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with translator names as keys and lists of sentences as values,\n",
        "          and sentiment scores with modified keys.\n",
        "    \"\"\"\n",
        "    translator_dict = {}\n",
        "    translators = ['davis', 'enright', 'moncrieff', 'proust']\n",
        "\n",
        "    for filename in filenames:\n",
        "        # Identify the translator's name from the filename\n",
        "        translator = None\n",
        "        for t in translators:\n",
        "            if re.search(fr'_{t}_', filename):\n",
        "                translator = t\n",
        "                break\n",
        "\n",
        "        if translator is None:\n",
        "            raise ValueError(f\"Translator not found in filename: {filename}\")\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            sentences = file.readlines()\n",
        "            # Remove trailing newline characters and unprintable characters\n",
        "            sentences = [remove_unprintable_characters(sentence.strip()) for sentence in sentences]\n",
        "            translator_dict[translator] = sentences\n",
        "\n",
        "            # Calculate sentiment scores for each sentence with progress bar\n",
        "            sentiment_scores = [get_ollama_sentiment(sentence) for sentence in tqdm(sentences, desc=f\"Processing {translator}\")]\n",
        "            sentiment_key = f\"{translator}_sentiment\"\n",
        "            translator_dict[sentiment_key] = sentiment_scores\n",
        "\n",
        "    return translator_dict\n",
        "\n",
        "# Example usage (ensure you have appropriate files to test this):\n",
        "# filenames = [\n",
        "#     'book_proust_en_swans-way_davis_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_enright_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_moncrieff_sentence_clean.txt',\n",
        "#     'book_proust_fr_swans-way_proust_sentence_clean.txt'\n",
        "# ]\n",
        "# translator_sentences = dictionary_of_list_sentences_from_file_list(filenames)\n",
        "# Displaying a small sample to avoid large outputs\n",
        "# for translator, sentences in translator_sentences.items():\n",
        "#     print(f\"{translator}: {sentences[:5]}\")  # Print only the first 5 sentences for each translator\n",
        "\n",
        "translator_sentences_dict = dictionary_of_list_sentences_from_file_list(list_clean_filenames)\n",
        "# Displaying a small sample to avoid large outputs\n",
        "for translator, sentences in translator_sentences_dict.items():\n",
        "  print(f\"{translator}: {sentences[:5]}\")  # Print only the first 5 sentences for each translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2YcgOv4YJyQ"
      },
      "outputs": [],
      "source": [
        "translator_sentences_dict = dictionary_of_list_sentences_from_file_list(list_clean_filenames)\n",
        "print(json.dumps(translator_sentences_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0cA0-Ewa-l0"
      },
      "source": [
        "#### Version #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47PMAwYuYJvV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "\n",
        "def remove_unprintable_characters(text):\n",
        "    \"\"\"\n",
        "    Removes or converts unprintable characters from a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input string.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned string with printable characters.\n",
        "    \"\"\"\n",
        "    # Normalize the text to NFKD (Normalization Form KD)\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Encode to ASCII bytes, ignoring non-ASCII characters\n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    # Decode back to string\n",
        "    text = text.decode('ascii')\n",
        "    return text\n",
        "\n",
        "def batch_sentences(sentences, batch_size=10):\n",
        "    \"\"\"\n",
        "    Splits the sentences into batches of specified size.\n",
        "\n",
        "    Parameters:\n",
        "    sentences (list of str): The list of sentences.\n",
        "    batch_size (int): The size of each batch.\n",
        "\n",
        "    Returns:\n",
        "    generator: A generator that yields batches of sentences.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        yield sentences[i:i + batch_size]\n",
        "\n",
        "def get_ollama_sentiment_batch(sentences_batch):\n",
        "    \"\"\"\n",
        "    Function to simulate sentiment analysis for a batch of sentences.\n",
        "\n",
        "    Parameters:\n",
        "    sentences_batch (list of str): The batch of input sentences.\n",
        "\n",
        "    Returns:\n",
        "    list of float: A list of sentiment scores.\n",
        "    \"\"\"\n",
        "    sentiment_scores = []\n",
        "    for sentence in sentences_batch:\n",
        "        # Construct Prompt\n",
        "        sentiment_prompt = f\"\"\"\n",
        "        ###SENTENCE:\n",
        "        {sentence}\n",
        "\n",
        "        ###INSTRUCTIONS:\n",
        "        {SENTIMENT_RUBRIC}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Mock implementation here for demo purposes\n",
        "            sentiment_polarity_float_str = llm.invoke(sentiment_prompt)\n",
        "            print(f\"sentiment_polarity_float_str: \\n\\n{sentiment_polarity_float_str}\\n\\n\")\n",
        "            sentiment_scores.append(sentiment_polarity_float_str)  # Replace with actual sentiment analysis call\n",
        "        except requests.ConnectionError as e:\n",
        "            print(f\"Connection error: {e}\")\n",
        "            sentiment_scores.append(None)\n",
        "\n",
        "    return sentiment_scores\n",
        "\n",
        "def dictionary_of_list_sentences_from_file_list(filenames, batch_size=10):\n",
        "    \"\"\"\n",
        "    Reads a list of files and returns a dictionary with translators as keys and lists of sentences as values,\n",
        "    and their corresponding sentiment scores with modified keys.\n",
        "\n",
        "    Parameters:\n",
        "    filenames (list of str): A list of filenames to read.\n",
        "    batch_size (int): The number of sentences to process in each batch.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with translator names as keys and lists of sentences as values,\n",
        "          and sentiment scores with modified keys.\n",
        "    \"\"\"\n",
        "    translator_dict = {}\n",
        "    translators = ['davis', 'enright', 'moncrieff', 'proust']\n",
        "\n",
        "    for filename in filenames:\n",
        "        # Identify the translator's name from the filename\n",
        "        translator = None\n",
        "        for t in translators:\n",
        "            if re.search(fr'_{t}_', filename):\n",
        "                translator = t\n",
        "                break\n",
        "\n",
        "        if translator is None:\n",
        "            raise ValueError(f\"Translator not found in filename: {filename}\")\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            sentences = file.readlines()\n",
        "            # Remove trailing newline characters and unprintable characters\n",
        "            sentences = [remove_unprintable_characters(sentence.strip()) for sentence in sentences]\n",
        "            translator_dict[translator] = sentences\n",
        "\n",
        "            # Process sentiment scores in batches\n",
        "            sentiment_scores = []\n",
        "            for sentences_batch in tqdm(batch_sentences(sentences, batch_size), desc=f\"Processing {translator}\"):\n",
        "                batch_scores = get_ollama_sentiment_batch(sentences_batch)\n",
        "                sentiment_scores.extend(batch_scores)\n",
        "\n",
        "            sentiment_key = f\"{translator}_sentiment\"\n",
        "            translator_dict[sentiment_key] = sentiment_scores\n",
        "\n",
        "    return translator_dict\n",
        "\n",
        "# Example usage (ensure you have appropriate files to test this):\n",
        "# filenames = [\n",
        "#     'book_proust_en_swans-way_davis_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_enright_sentence_clean.txt',\n",
        "#     'book_proust_en_swans-way_moncrieff_sentence_clean.txt',\n",
        "#     'book_proust_fr_swans-way_proust_sentence_clean.txt'\n",
        "# ]\n",
        "# translator_sentences = dictionary_of_list_sentences_from_file_list(filenames)\n",
        "# Displaying a small sample to avoid large outputs\n",
        "# for translator, sentences in translator_sentences.items():\n",
        "#     print(f\"{translator}: {sentences[:5]}\")  # Print only the first 5 sentences for each translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIab03adYJra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qDqlu3GO6ri"
      },
      "outputs": [],
      "source": [
        "print(f\"USING LLM model_name: {model_name}\")\n",
        "\n",
        "llm = Ollama(model = model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QxIelo-PoMk"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Test JSON metrics only call\n",
        "\n",
        "score_json_only = llm.invoke(prompt_score_translation_json_only)\n",
        "print(f\"score_json_only: \\n\\n{score_json_only}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxFGdbOrPoJg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdvMKKTDPoGv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceXC9DOCO6oe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf1Br5jCMTwD"
      },
      "outputs": [],
      "source": [
        "# Get the filename from the uploaded files\n",
        "upload_filename = list(uploaded_raw_text.keys())[0]\n",
        "\n",
        "# Extract the book title from the filename\n",
        "book_title = \"_\".join(upload_filename.split(\".\")[0].split(\"_\")[1:5])\n",
        "print(book_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHYfzjhxI9Yo"
      },
      "outputs": [],
      "source": [
        "lines_list = []\n",
        "for fn in uploaded_raw_text.keys():\n",
        "  with open(fn, 'r') as fp:\n",
        "    lines_list = fp.readlines()\n",
        "\n",
        "print(f\" len(lines_list): {len(lines_list)}\")\n",
        "print(lines_list[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwSUZQ4NJir9"
      },
      "source": [
        "# Sentence Length Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_p46HTmI9Yo"
      },
      "outputs": [],
      "source": [
        "# Calculate the length of each line\n",
        "def plot_histogram_line_lengths(book_title, lines_list):\n",
        "    line_lengths = [len(line) for line in lines_list]\n",
        "\n",
        "    # Plot the histogram of line lengths\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(line_lengths, bins=100, edgecolor='black', alpha=0.7)\n",
        "    plt.title(f'Histogram of Line Lengths\\n{book_title}', fontsize=14)\n",
        "    plt.xlabel('Line Length', fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for book_title, lines_list, in clean_text_reformat_seg_filter_dict.items():\n",
        "  print(f\"{book_title}: {len(lines_list)}\")\n",
        "  plot_histogram_line_lengths(book_title, lines_list)"
      ],
      "metadata": {
        "id": "F3ybSe7ZLLQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_kde_line_lengths(book_title, lines_list):\n",
        "    # Convert lines_list to an array of line lengths\n",
        "    line_lengths = np.array([len(line) for line in lines_list], dtype=np.float64)\n",
        "\n",
        "    # Compute the KDE of the line lengths\n",
        "    kde = gaussian_kde(line_lengths)\n",
        "    x_values = np.linspace(min(line_lengths), max(line_lengths), 1000)\n",
        "    kde_values = kde(x_values)\n",
        "\n",
        "    # Plot the KDE\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x_values, kde_values, color='blue')\n",
        "    plt.title(f'KDE of Line Lengths\\n{book_title}', fontsize=14)\n",
        "    plt.xlabel('Line Length', fontsize=12)\n",
        "    plt.ylabel('Density', fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ou8_tvSSLgiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for book_title, lines_list, in clean_text_reformat_seg_filter_dict.items():\n",
        "  print(f\"{book_title}: {len(lines_list)}\")\n",
        "  plot_kde_line_lengths(book_title, lines_list)"
      ],
      "metadata": {
        "id": "xeHlwysHMJMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into n Chunks"
      ],
      "metadata": {
        "id": "moz2XSu_sMoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%whos dict"
      ],
      "metadata": {
        "id": "gCUTFehGsg4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for book_title, lines_list, in clean_text_reformat_seg_filter_dict.items():\n",
        "  print(f\"{book_title}: {len(lines_list)}\")\n",
        "\n",
        "# len(clean_text_reformat_seg_filter_dict[list(clean_text_reformat_seg_filter_dict.keys())[0]])"
      ],
      "metadata": {
        "id": "NvoFzjrWsjMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_dict_of_lists(dict_of_list, chunk_count):\n",
        "    def chunk_list(lst, chunk_count):\n",
        "        chunks = [[] for _ in range(chunk_count)]\n",
        "        for i, item in enumerate(lst):\n",
        "            chunks[i % chunk_count].append(item)\n",
        "        return [\" \".join(chunk) for chunk in chunks]\n",
        "\n",
        "    chunked_dict = {key: chunk_list(value, chunk_count) for key, value in dict_of_list.items()}\n",
        "    return chunked_dict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qe8zJQOot8cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into 100 Chunks\n",
        "# Assuming clean_text_reformat_seg_filter_dict is defined as the input dictionary\n",
        "clean_text_chunked100_dict = chunk_dict_of_lists(clean_text_reformat_seg_filter_dict, 100)\n",
        "\n",
        "for book_title, lines_list in clean_text_chunked100_dict.items():\n",
        "  print(f\"{book_title}: {len(lines_list)}\")"
      ],
      "metadata": {
        "id": "5ntT_PA_t8U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into 500 Chunks\n",
        "# Assuming clean_text_reformat_seg_filter_dict is defined as the input dictionary\n",
        "clean_text_chunked500_dict = chunk_dict_of_lists(clean_text_reformat_seg_filter_dict, 500)\n",
        "\n",
        "for book_title, lines_list in clean_text_chunked500_dict.items():\n",
        "  print(f\"{book_title}: {len(lines_list)}\")"
      ],
      "metadata": {
        "id": "7-9Iv6TRsRMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDK8W3oBr0XS"
      },
      "source": [
        "# Lexical Richness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl2JNgCaq3dU"
      },
      "source": [
        "## Extract Test Lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz7IYarSq3Td"
      },
      "outputs": [],
      "source": [
        "def extract_text(lines_list, start_per, length_per):\n",
        "    # Step 1: Concatenate the entire lines_list into big_string\n",
        "    big_string = ''.join(lines_list)\n",
        "\n",
        "    # Step 2: Calculate the start and end character indexes\n",
        "    total_chars = len(big_string)\n",
        "    char_index_start = int(start_per / 100 * total_chars)\n",
        "    char_index_end = char_index_start + int(length_per / 100 * total_chars)\n",
        "\n",
        "    # Ensure char_index_end does not exceed the total length\n",
        "    if char_index_end > total_chars:\n",
        "        char_index_end = total_chars\n",
        "\n",
        "    # Step 3: Translate char indexes into line indexes\n",
        "    cumulative_length = 0\n",
        "    line_index_start = line_index_end = None\n",
        "\n",
        "    for i, line in enumerate(lines_list):\n",
        "        cumulative_length += len(line)\n",
        "        if line_index_start is None and cumulative_length > char_index_start:\n",
        "            line_index_start = i\n",
        "        if line_index_end is None and cumulative_length >= char_index_end:\n",
        "            line_index_end = i\n",
        "            break\n",
        "\n",
        "    # If line_index_end was not set, it means char_index_end was the last character\n",
        "    if line_index_end is None:\n",
        "        line_index_end = len(lines_list) - 1\n",
        "\n",
        "    # Step 4: Extract the sublines list\n",
        "    sublines_list = lines_list[line_index_start:line_index_end+1]\n",
        "\n",
        "    return sublines_list\n",
        "\n",
        "# Example usage\n",
        "lines_test_list = [\n",
        "    \"This is the first line.\\n\",\n",
        "    \"This is the second line.\\n\",\n",
        "    \"This is the third line.\\n\",\n",
        "    \"This is the fourth line.\\n\",\n",
        "    \"This is the fifth line.\\n\"\n",
        "]\n",
        "start_per = 20  # Start extraction from 20% into the text\n",
        "length_per = 30  # Extract 30% of the text length\n",
        "\n",
        "extracted_lines = extract_text(lines_test_list, start_per, length_per)\n",
        "for line in extracted_lines:\n",
        "    print(line, end='')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc7QGulxrJML"
      },
      "outputs": [],
      "source": [
        "len(lines_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOvysjssrJI9"
      },
      "outputs": [],
      "source": [
        "start_per = 0  # Start extraction from 20% into the text\n",
        "length_per = 10  # Extract 30% of the text length\n",
        "\n",
        "extracted_lines = extract_text(lines_list, start_per, length_per)\n",
        "print(f\"len(extracted_lines): {len(extracted_lines)}\")\n",
        "# for line in extracted_lines:\n",
        "#     print(line, end='')\n",
        "\n",
        "extracted_string = ' '.join(extracted_lines)\n",
        "print(f\"len(extracted_string): {len(extracted_string)}\")\n",
        "print(extracted_string[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics on Test Line"
      ],
      "metadata": {
        "id": "kjdISGW_NV74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novel_title = \"Swan's Way\""
      ],
      "metadata": {
        "id": "QAFI-8AZNb8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_4FcBJaq3HQ"
      },
      "outputs": [],
      "source": [
        "lex = LexicalRichness(extracted_string)\n",
        "\n",
        "print(f\"Lexical Richness\")\n",
        "print(f\"       novel_title: {novel_title}\")\n",
        "print(f\"   start char len%: {start_per}\")\n",
        "print(f\"  length char len%: {length_per}\")\n",
        "print(\"==================================================\")\n",
        "\n",
        "print(\"\\nwords\")\n",
        "print(f\"lex.words: {lex.words}\")\n",
        "\n",
        "print(\"\\nterms\")\n",
        "print(f\"lex.terms: {lex.terms}\")\n",
        "\n",
        "print(\"\\ntype-token ratio (TTR) of text\")\n",
        "print(f\"lex.ttr: {lex.ttr}\")\n",
        "\n",
        "print(\"\\nroot type-token ratio (RTTR) of text\")\n",
        "print(f\"lex.rttr: {lex.rttr}\")\n",
        "\n",
        "print(\"\\ncorrected type-token ratio (CTTR) of text\")\n",
        "print(f\"lex.cttr: {lex.cttr}\")\n",
        "\n",
        "print(\"\\nmean segmental type-token ratio (MSTTR)\")\n",
        "print(f\"lex.msttr(segment_window=25): {lex.msttr(segment_window=25)}\")\n",
        "\n",
        "print(\"\\nmoving average type-token ratio (MATTR)\")\n",
        "print(f\"lex.mattr(window_size=25): {lex.mattr(window_size=25)}\")\n",
        "\n",
        "print(\"\\nMeasure of Textual Lexical Diversity (MTLD)\")\n",
        "print(f\"lex.mtld(threshold=0.72): {lex.mtld(threshold=0.72)}\")\n",
        "\n",
        "print(\"\\nhypergeometric distribution diversity (HD-D) measure\")\n",
        "print(f\"lex.hdd(draws=42) : {lex.hdd(draws=42)}\")\n",
        "\n",
        "print(\"\\nvoc-D measure\")\n",
        "print(f\"lex.vocd(ntokens=50, within_sample=100, iterations=3): {lex.vocd(ntokens=50, within_sample=100, iterations=3)}\")\n",
        "\n",
        "print(\"\\nHerdan's lexical diversity measure\")\n",
        "print(f\"lex.Herdan: {lex.Herdan}\")\n",
        "\n",
        "print(\"\\nSummer's lexical diversity measure\")\n",
        "print(f\"lex.Summer: {lex.Summer}\")\n",
        "\n",
        "print(\"\\nDugast's lexical diversity measure\")\n",
        "print(f\"lex.Dugast: {lex.Dugast}\")\n",
        "\n",
        "print(\"\\nMaas's lexical diversity measure\")\n",
        "print(f\"lex.Maas: {lex.Maas}\")\n",
        "\n",
        "print(\"\\nYule's K\")\n",
        "print(f\"lex.yulek: {lex.yulek}\")\n",
        "\n",
        "print(\"\\nYule's I\")\n",
        "print(f\"lex.yulei: {lex.yulei}\")\n",
        "\n",
        "print(\"\\nHerdan's Vm\")\n",
        "print(f\"lex.herdanvm: {lex.herdanvm}\")\n",
        "\n",
        "print(\"\\nSimpson's D\")\n",
        "print(f\"lex.simpsond: {lex.simpsond}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics on Translations"
      ],
      "metadata": {
        "id": "OW9Z67GhnPNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lexical_richness_metrics(lines_list):\n",
        "    metrics = []\n",
        "\n",
        "    for line in lines_list:\n",
        "        lex = LexicalRichness(line)\n",
        "\n",
        "        metrics.append({\n",
        "            \"words\": lex.words,\n",
        "            \"terms\": lex.terms,\n",
        "            \"ttr\": lex.ttr,\n",
        "            \"rttr\": lex.rttr,\n",
        "            \"cttr\": lex.cttr,\n",
        "            \"msttr\": lex.msttr(segment_window=3),\n",
        "            \"mattr\": lex.mattr(window_size=5),\n",
        "            \"mtld\": lex.mtld(threshold=0.72),\n",
        "            \"hdd\": lex.hdd(draws=42),\n",
        "            \"vocd\": lex.vocd(ntokens=50, within_sample=100, iterations=3),\n",
        "            \"Herdan\": lex.Herdan,\n",
        "            \"Summer\": lex.Summer,\n",
        "            \"Dugast\": lex.Dugast,\n",
        "            \"Maas\": lex.Maas,\n",
        "            \"yulek\": lex.yulek,\n",
        "            \"yulei\": lex.yulei,\n",
        "            \"herdanvm\": lex.herdanvm,\n",
        "            \"simpsond\": lex.simpsond\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(metrics)\n",
        "\n",
        "    # Interpolate to handle NaN values\n",
        "    df = df.interpolate(method='linear', limit_direction='both', axis=0)\n",
        "\n",
        "    # Check if there are still NaN values after interpolation\n",
        "    if df.isnull().values.any():\n",
        "        print(\"NaN values found in the dataframe after interpolation. Filling remaining NaN values with column means.\")\n",
        "        # Fill any remaining NaN values with the mean of the column\n",
        "        df = df.fillna(df.mean())\n",
        "\n",
        "    return df\n",
        "\n",
        "\"\"\";\n",
        "# SOME METRICS DO NOT WORK ON SHORT TEXT LIKE THIS\n",
        "\n",
        "\n",
        "\n",
        "# Mock data and dictionary for testing\n",
        "clean_text_reformat_seg_filter_test_dict = {\n",
        "    \"Book1\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book2\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book3\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book4\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book5\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book6\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book7\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book8\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book9\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book10\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "\n",
        "}\n",
        "\n",
        "lexical_richness_test_dict = {}\n",
        "\n",
        "for book_title, segments_list in clean_text_reformat_seg_filter_test_dict.items():\n",
        "    print(f\"{book_title}: {len(segments_list)}\")\n",
        "    lexical_richness_test_dict[book_title] = get_lexical_richness_metrics(segments_list)\n",
        "\n",
        "for book_title, metrics_df in lexical_richness_test_dict.items():\n",
        "    print(f\"Metrics for {book_title}:\")\n",
        "    print(metrics_df)\n",
        "    print(\"-\" * 30)\n",
        "\"\"\";"
      ],
      "metadata": {
        "id": "5ZLVX5ynnR48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dictionary to hold the lexical richness metrics dataframes\n",
        "\n",
        "lexical_richness_chunks100_dict = {}"
      ],
      "metadata": {
        "id": "dWtHzFYxFcKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Iterate over the chunked dictionary and calculate lexical richness metrics\n",
        "\n",
        "for book_title, chunks in clean_text_chunked100_dict.items():\n",
        "  if \"_en_\" in book_title or True:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    lexical_richness_chunks100_dict[book_title] = get_lexical_richness_metrics(chunks)\n"
      ],
      "metadata": {
        "id": "g0APq2BTwPzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_richness_chunks100_dict[\"book_proust_en_swans-way_moncrieff\"][:5]\n"
      ],
      "metadata": {
        "id": "TqXaLL5PwPwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_richness_chunks100_dict[\"book_proust_en_swans-way_moncrieff\"].info()"
      ],
      "metadata": {
        "id": "0QLqKM5iMJHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_richness_chunks100_dict[\"book_proust_en_swans-way_moncrieff\"].describe()"
      ],
      "metadata": {
        "id": "pibh8pXFMI6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dictionary to hold the lexical richness metrics dataframes\n",
        "\n",
        "lexical_richness_chunks500_dict = {}"
      ],
      "metadata": {
        "id": "JzOJylhvF5u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Iterate over the chunked dictionary and calculate lexical richness metrics\n",
        "\n",
        "for book_title, chunks in clean_text_chunked500_dict.items():\n",
        "  if \"_en_\" in book_title:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    lexical_richness_chunks500_dict[book_title] = get_lexical_richness_metrics(chunks)\n",
        "  elif \"_fr_\" in book_title:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    lexical_richness_chunks500_dict[book_title] = get_lexical_richness_metrics(chunks)\n",
        "  else:\n",
        "    print(f\"ERROR: Illegal language_type: {book_title}\")\n",
        "    print(f\"SKIPPING...\\n\")\n",
        "    continue"
      ],
      "metadata": {
        "id": "J-67fOP8zBbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_richness_chunks500_dict[\"book_proust_en_swans-way_moncrieff\"][:5]"
      ],
      "metadata": {
        "id": "nXMqMIMF36M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_richness_chunks500_dict[\"book_proust_en_swans-way_moncrieff\"].info()"
      ],
      "metadata": {
        "id": "xupT1CbyKQ-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_richness_chunks500_dict[\"book_proust_en_swans-way_moncrieff\"].describe()"
      ],
      "metadata": {
        "id": "-5XkJbhKKZZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save\n"
      ],
      "metadata": {
        "id": "faOsyFpfBje9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dict_of_df(dict_of_df, subdir):\n",
        "    # Create the subdirectory if it doesn't exist\n",
        "    if not os.path.exists(subdir):\n",
        "        os.makedirs(subdir)\n",
        "\n",
        "    for filename, df in dict_of_df.items():\n",
        "        # Sanitize filename to remove or replace invalid characters and ensure a single .csv extension\n",
        "        sanitized_filename = re.sub(r'[^\\w\\-_ ]', '_', filename)\n",
        "        sanitized_filename = re.sub(r'\\.[^.]*$', '', sanitized_filename) + '.csv'\n",
        "\n",
        "        # Full path to save the file in the specified subdirectory\n",
        "        full_path = os.path.join(subdir, sanitized_filename)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        df.to_csv(full_path, index=False)\n",
        "        print(f\"Saved {full_path}\")"
      ],
      "metadata": {
        "id": "d5bJpffwBjQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dict_of_df(lexical_richness_chunks100_dict, \"lexical_richness100\")"
      ],
      "metadata": {
        "id": "CDL5Z7rKBjMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a zip archive of these files\n",
        "subdir = 'lexical_richness100'\n",
        "\n",
        "# Zip the subdirectory\n",
        "shutil.make_archive(subdir, 'zip', subdir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(subdir + '.zip')"
      ],
      "metadata": {
        "id": "XTyRBASTEQsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dict_of_df(lexical_richness_chunks500_dict, \"lexical_richness500\")"
      ],
      "metadata": {
        "id": "YVE1xuj3e9fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a zip archive of these files\n",
        "subdir = 'lexical_richness500'\n",
        "\n",
        "# Zip the subdirectory\n",
        "shutil.make_archive(subdir, 'zip', subdir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(subdir + '.zip')"
      ],
      "metadata": {
        "id": "2ErX1Dake9f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "ZHSx812Z26gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMMENT OUT any metric you don't want to plot\n",
        "\n",
        "metric_list = [\n",
        "    'msttr',\n",
        "    'mattr',\n",
        "    'mtld',\n",
        "    'hdd',\n",
        "    'vocd',\n",
        "    # 'Herdan',\n",
        "    # 'Summer',\n",
        "    # 'Dugast',\n",
        "    # 'Maas',\n",
        "    # 'yulek',\n",
        "    # 'yulei',\n",
        "    'herdanvm',\n",
        "    'simpsond'\n",
        "    ]"
      ],
      "metadata": {
        "id": "LZsJ0WxhJWOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_normalized_smoothed_metrics(dict_of_dataframes, metric_list):\n",
        "    \"\"\"\n",
        "    Plots the normalized and smoothed metrics from the dataframes in the given dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    dict_of_dataframes (dict): Dictionary where keys are book titles and values are pandas dataframes with metrics.\n",
        "    metric_list (list): List of metrics to be plotted.\n",
        "    \"\"\"\n",
        "    for book_title, df in dict_of_dataframes.items():\n",
        "        # Filter the dataframe to include only the specified metrics\n",
        "        filtered_df = df[metric_list]\n",
        "\n",
        "        # Z-score normalization\n",
        "        normalized_df = filtered_df.apply(zscore)\n",
        "\n",
        "        # 10% window size for SMA smoothing\n",
        "        window_size = max(1, len(df) // 10)\n",
        "        smoothed_df = normalized_df.rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        for column in smoothed_df.columns:\n",
        "            plt.plot(smoothed_df[column], label=column)\n",
        "\n",
        "        plt.title(f\"Metrics for {book_title}\")\n",
        "        plt.xlabel(\"Chunk Index\")\n",
        "        plt.ylabel(\"Z-score Normalized Value\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Place legend outside the plot area\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the layout to make space for the legend\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "LY7y_hXrJJ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_normalized_smoothed_metrics(lexical_richness_chunks100_dict, metric_list)"
      ],
      "metadata": {
        "id": "is7d7vncJLhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_normalized_smoothed_metrics(lexical_richness_chunks500_dict, metric_list)"
      ],
      "metadata": {
        "id": "_9uifPsIKIiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm7uGu6RvU5P"
      },
      "source": [
        "# Text Descriptives (SpaCy: en/fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azZIU9JovXrA"
      },
      "outputs": [],
      "source": [
        "# View Available/Default Metrics\n",
        "\n",
        "td.get_valid_metrics()\n",
        "# {'quality', 'readability', 'all', 'descriptive_stats', 'dependency_distance', 'pos_proportions', 'information_theory', 'coherence'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGOEn98IvXoR"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "test_str = \"The world is changed. I feel it in the water. I feel it in the earth. I smell it in the air. Much that once was is lost, for none now live who remember it.\"\n",
        "\n",
        "df = td.extract_metrics(text=test_str, spacy_model=\"en_core_web_lg\", metrics=[\"readability\", \"coherence\"])\n",
        "df.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pmtYkvjyHRA"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "df = td.extract_metrics(text=test_str, spacy_model=\"en_core_web_lg\", metrics=None) # [\"readability\", \"coherence\"])\n",
        "\n",
        "df.transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use SpaCy Pipeline"
      ],
      "metadata": {
        "id": "dxJEaN7UdWIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NlYTeomws0V"
      },
      "outputs": [],
      "source": [
        "# load your favourite spacy model (remember to install it first using e.g. `python -m spacy download en_core_web_sm`)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "nlp.add_pipe(\"textdescriptives/all\")\n",
        "doc = nlp(\"The world is changed. I feel it in the water. I feel it in the earth. I smell it in the air. Much that once was is lost, for none now live who remember it.\")\n",
        "\n",
        "# access some of the values\n",
        "doc._.readability\n",
        "doc._.token_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEm9umACxdRB"
      },
      "outputs": [],
      "source": [
        "doc._.descriptive_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqKrCBpKxivl"
      },
      "outputs": [],
      "source": [
        "doc._.entropy\n",
        "doc._.coherence\n",
        "doc._.quality\n",
        "doc._.dependency_distance\n",
        "doc._.pos_proportions\n",
        "doc._.information_theory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "td.extract_dict(doc)"
      ],
      "metadata": {
        "id": "C9BA7tOEdkqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_metrics_df = td.extract_df(doc)\n",
        "text_metrics_df.transpose()"
      ],
      "metadata": {
        "id": "-eGD0pkpdlaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Eaq51p4wsgh"
      },
      "outputs": [],
      "source": [
        "print(type(td.extract_dict(doc)))\n",
        "print(type(td.extract_df(doc)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSp_LvNhxKjP"
      },
      "outputs": [],
      "source": [
        "# Get metrics in dataframe and pivot vertically\n",
        "\n",
        "# text_metrics_df.head()\n",
        "\n",
        "text_metrics_vertical_df = text_metrics_df.T\n",
        "text_metrics_vertical_df.columns = [\"value\"]\n",
        "\n",
        "text_metrics_vertical_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiGt77lhx8pq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Create datetime string in datetime_now str\n",
        "datetime_now_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "# Create filename with datetime suffix\n",
        "filename_download = f'text_metrics_{book_title}_{datetime_now_str}.csv'\n",
        "\n",
        "print(filename_download)\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY9uTFvUyMWB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Download text_stylo_metrics to file\n",
        "\n",
        "text_metrics_vertical_df.head()\n",
        "text_metrics_vertical_df.to_csv(filename_download, index=False)\n",
        "\n",
        "# Assuming text_metrics_vertical_df is your vertical dataframe\n",
        "text_metrics_vertical_df = text_metrics_vertical_df.reset_index()\n",
        "text_metrics_vertical_df.columns = ['Metric', 'Value']\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "text_metrics_vertical_df.to_csv(filename_download, index=False)\n",
        "\n",
        "files.download(filename_download)\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics on Text Descriptives"
      ],
      "metadata": {
        "id": "P9tdLbI11n6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "nlp.add_pipe(\"textdescriptives/all\")\n",
        "doc = nlp(\"The world is changed. I feel it in the water. I feel it in the earth. I smell it in the air. Much that once was is lost, for none now live who remember it.\")\n",
        "\n",
        "# access some of the values\n",
        "doc._.readability\n",
        "doc._.token_length"
      ],
      "metadata": {
        "id": "q7JnM9AKAbxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load spaCy model and add textdescriptives pipeline\n",
        "# nlp = spacy.load(\"en_core_web_lg\")\n",
        "# nlp.add_pipe(\"textdescriptives/all\")\n",
        "\n",
        "def get_text_descriptive_metrics(lines_list, language_type='en'):\n",
        "    if language_type == 'en':\n",
        "        print(f\"  In get_text_descriptive_metrics(): loading en\")\n",
        "        nlp = spacy.load(\"en_core_web_lg\")\n",
        "        nlp.add_pipe(\"textdescriptives/all\")\n",
        "    elif language_type == 'fr':\n",
        "        print(f\"  In get_text_descriptive_metrics(): loading fr\")\n",
        "        nlp = spacy.load(\"fr_core_news_lg\")\n",
        "        nlp.add_pipe(\"textdescriptives/all\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid language type. Please choose 'en' or 'fr'.\")\n",
        "        exit()\n",
        "\n",
        "\n",
        "    metrics = []\n",
        "\n",
        "    for line in lines_list:\n",
        "        doc = nlp(line)\n",
        "\n",
        "\n",
        "        metrics.append({\n",
        "            \"flesch_reading_ease\": doc._.readability.get('flesch_reading_ease'),\n",
        "            \"flesch_kincaid_grade\": doc._.readability.get('flesch_kincaid_grade'),\n",
        "            \"smog\": doc._.readability.get('smog'),\n",
        "            \"gunning_fog\": doc._.readability.get('gunning_fog'),\n",
        "            \"automated_readability_index\": doc._.readability.get('automated_readability_index'),\n",
        "            \"coleman_liau_index\": doc._.readability.get('coleman_liau_index'),\n",
        "            \"lix\": doc._.readability.get('lix'),\n",
        "            \"rix\": doc._.readability.get('rix'),\n",
        "            \"token_length_mean\": doc._.token_length.get('token_length_mean'),\n",
        "            \"token_length_median\": doc._.token_length.get('token_length_median'),\n",
        "            \"token_length_std\": doc._.token_length.get('token_length_std')\n",
        "        })\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(metrics)\n",
        "    return df\n",
        "\n",
        "# Mock data and dictionary for testing\n",
        "clean_text_reformat_seg_filter_test_dict = {\n",
        "    \"Book1\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book2\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book3\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book4\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book5\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book6\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book7\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book8\": [\"Yet another sample text.\", \"More text for testing.\"],\n",
        "    \"Book9\": [\"This is a sample text.\", \"Another line of text.\"],\n",
        "    \"Book10\": [\"Yet another sample text.\", \"More text for testing.\"]\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6WIcTr1p1noG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dictionary to hold the lexical richness metrics dataframes\n",
        "\n",
        "textdescriptives_chunks100_dict = {}"
      ],
      "metadata": {
        "id": "mSYVq7pqFmst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Iterate over the chunked dictionary and calculate lexical richness metrics\n",
        "\n",
        "for book_title, chunks in clean_text_chunked100_dict.items():\n",
        "  print(f\"PROCESSING: book_title: {book_title}\")\n",
        "  if \"_en_\" in book_title:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    textdescriptives_chunks100_dict[book_title] = get_text_descriptive_metrics(chunks, \"en\")\n",
        "  elif \"_fr_\" in book_title:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    textdescriptives_chunks100_dict[book_title] = get_text_descriptive_metrics(chunks, \"fr\")\n",
        "  else:\n",
        "    print(f\"ERROR: Illegal language_type: {book_title}\")\n",
        "    print(f\"SKIPPING...\\n\")\n",
        "    continue"
      ],
      "metadata": {
        "id": "nIlwJxir2Yp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textdescriptives_chunks100_dict.keys()"
      ],
      "metadata": {
        "id": "GzN7zs4i4KX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textdescriptives_chunks100_dict[\"book_proust_en_swans-way_moncrieff\"].info()"
      ],
      "metadata": {
        "id": "L0HJyb8hVt8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(textdescriptives_chunks100_dict)"
      ],
      "metadata": {
        "id": "YMpUcU-6DLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textdescriptives_chunks100_dict[\"book_proust_en_swans-way_moncrieff\"].info()"
      ],
      "metadata": {
        "id": "4nkT4YflePmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textdescriptives_chunks100_dict[\"book_proust_en_swans-way_moncrieff\"].describe()"
      ],
      "metadata": {
        "id": "9B1Pegw25LqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dictionary to hold the lexical richness metrics dataframes\n",
        "\n",
        "textdescriptives_chunks500_dict = {}"
      ],
      "metadata": {
        "id": "FXG95YGHFV-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Iterate over the chunked dictionary and calculate lexical richness metrics\n",
        "\n",
        "for book_title, chunks in clean_text_chunked500_dict.items():\n",
        "  if \"_en_\" in book_title:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    textdescriptives_chunks500_dict[book_title] = get_text_descriptive_metrics(chunks, \"en\")\n",
        "  elif \"_fr_\" in book_title:\n",
        "    print(f\"{book_title}: {len(chunks)}\")\n",
        "    textdescriptives_chunks500_dict[book_title] = get_text_descriptive_metrics(chunks, \"fr\")\n",
        "  else:\n",
        "    print(f\"ERROR: Illegal language_type: {book_title}\")\n",
        "    print(f\"SKIPPING...\\n\")\n",
        "    continue"
      ],
      "metadata": {
        "id": "0HdPLu_Q3qQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(textdescriptives_chunks500_dict)"
      ],
      "metadata": {
        "id": "DdOMiVlqDEkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# textdescriptives_chunks500_dict[list(textdescriptives_chunks500_dict.keys())[0]][:5]"
      ],
      "metadata": {
        "id": "ekHmCjwg4PaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textdescriptives_chunks500_dict[\"book_proust_en_swans-way_moncrieff\"].info()"
      ],
      "metadata": {
        "id": "HIIaMi_yec2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textdescriptives_chunks500_dict[\"book_proust_en_swans-way_moncrieff\"].describe()"
      ],
      "metadata": {
        "id": "Ijxl8UlkecyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save"
      ],
      "metadata": {
        "id": "y6h0UlDdBmRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dict_of_df(lexical_richness_chunks100_dict, \"text_descriptives100\")"
      ],
      "metadata": {
        "id": "nY-rs8_CBmIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a zip archive of these files\n",
        "subdir = 'text_descriptives100'\n",
        "\n",
        "# Zip the subdirectory\n",
        "shutil.make_archive(subdir, 'zip', subdir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(subdir + '.zip')"
      ],
      "metadata": {
        "id": "YzRZRSUwBmEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dict_of_df(lexical_richness_chunks500_dict, \"text_descriptives500\")"
      ],
      "metadata": {
        "id": "cxfxdQ4qepGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a zip archive of these files\n",
        "subdir = 'text_descriptives500'\n",
        "\n",
        "# Zip the subdirectory\n",
        "shutil.make_archive(subdir, 'zip', subdir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(subdir + '.zip')"
      ],
      "metadata": {
        "id": "QTs8M1lEe3Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "LP5cyg3O3LZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMMENT OUT any metric you don't want to plot\n",
        "\n",
        "metric_list = [\n",
        "    'flesch_reading_ease',\n",
        "    'flesch_kincaid_grade',\n",
        "    'smog',\n",
        "    'gunning_fog',\n",
        "    'automated_readability_index',\n",
        "    'coleman_liau_index',\n",
        "    'lix',\n",
        "    'rix',\n",
        "    'token_length_mean',\n",
        "    'token_length_median',\n",
        "    'token_length_std'\n",
        "    ]"
      ],
      "metadata": {
        "id": "rtxBhv6af_3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "# Assuming lexical_richness_dict is the dictionary containing the DataFrames with metrics\n",
        "plot_normalized_smoothed_metrics(textdescriptives_chunks100_dict, metric_list)"
      ],
      "metadata": {
        "id": "BKnO18vA2Rgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "# Assuming lexical_richness_dict is the dictionary containing the DataFrames with metrics\n",
        "plot_normalized_smoothed_metrics(textdescriptives_chunks500_dict, metric_list)"
      ],
      "metadata": {
        "id": "k7QkaVMD3eGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiments"
      ],
      "metadata": {
        "id": "T-NbcOJyN_BA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjOufCOHvP7d"
      },
      "outputs": [],
      "source": [
        "# Test sentence lists in en and fr\n",
        "\n",
        "sentence_test_en_list = [\n",
        "    \"I hate this so much, it's the worst experience I've ever had.\",  # Very negative\n",
        "    \"This is absolutely terrible, I can't believe how bad it is.\",   # Very negative\n",
        "    \"I'm really disappointed and upset with how things turned out.\",  # Negative\n",
        "    \"This is not what I expected at all, quite frustrating.\",        # Negative\n",
        "    \"I feel indifferent about this, it neither excites me nor bothers me.\",  # Neutral\n",
        "    \"It's okay, not great but not bad either.\",                      # Neutral\n",
        "    \"This is pretty good, I'm quite satisfied with it.\",             # Positive\n",
        "    \"I really enjoyed this, it made my day better.\",                 # Positive\n",
        "    \"Absolutely fantastic! I'm thrilled and very happy with it.\",    # Very positive\n",
        "    \"This is the best thing ever, I'm ecstatic and over the moon!\"   # Very positive\n",
        "]\n",
        "\n",
        "sentence_test_fr_list = [\n",
        "    \"Je déteste ça tellement, c'est la pire expérience que j'ai jamais eue.\",  # Very negative\n",
        "    \"C'est absolument terrible, je ne peux pas croire à quel point c'est mauvais.\",  # Very negative\n",
        "    \"Je suis vraiment déçu et contrarié par la tournure des événements.\",  # Negative\n",
        "    \"Ce n'est pas du tout ce à quoi je m'attendais, c'est assez frustrant.\",  # Negative\n",
        "    \"Je me sens indifférent à ce sujet, ça ne me dérange ni ne m'excite.\",  # Neutral\n",
        "    \"C'est correct, pas génial mais pas mauvais non plus.\",  # Neutral\n",
        "    \"C'est plutôt bien, je suis assez satisfait.\",  # Positive\n",
        "    \"J'ai vraiment apprécié ça, ça a égayé ma journée.\",  # Positive\n",
        "    \"Absolument fantastique ! Je suis ravi et très heureux.\",  # Very positive\n",
        "    \"C'est la meilleure chose qui soit, je suis extatique et sur un nuage !\"  # Very positive\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4LpqmFinse3"
      },
      "source": [
        "*italicized text*# II. Compute NEW SENTIMENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGeQ31vCkZuB"
      },
      "source": [
        "## VADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4HdMIk0n0ML"
      },
      "outputs": [],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ykJEF5xohjV"
      },
      "outputs": [],
      "source": [
        "def convert_stars_to_int(star_string):\n",
        "    \"\"\"\n",
        "    Converts a star rating string to an integer.\n",
        "\n",
        "    :param star_string: A string representing the star rating (e.g., \"3 stars\").\n",
        "    :return: An integer representing the star rating (1 to 5).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Split the string to extract the numeric part\n",
        "        parts = star_string.split()\n",
        "\n",
        "        # Extract the first part and convert to integer\n",
        "        star_int = int(parts[0])\n",
        "\n",
        "        # Check if the integer is within the valid range\n",
        "        if 1 <= star_int <= 5:\n",
        "            return star_int\n",
        "        else:\n",
        "            raise ValueError(\"Star rating out of valid range (1 to 5).\")\n",
        "    except (ValueError, IndexError) as e:\n",
        "        print(f\"Error converting star string to int: {e}\")\n",
        "        return None  # or raise an exception, or handle it as per your requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEx6dMvDn3wI"
      },
      "outputs": [],
      "source": [
        "# Sentiment: VADER (English Only)\n",
        "# pip install vaderSentiment\n",
        "# https://github.com/cjhutto/vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYoRfWKHnxd6"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_vader_list(sentence_list):\n",
        "    \"\"\"\n",
        "    Given an input list of strings, returns an equal length list of the sentiment polarity values\n",
        "    for corresponding strings using VADER.\n",
        "\n",
        "    :param sentence_list: List of sentences (strings) to analyze.\n",
        "    :return: List of sentiment polarity values.\n",
        "    \"\"\"\n",
        "    # Initialize the VADER sentiment intensity analyzer\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Analyze the sentiment for each sentence in the list\n",
        "    sentiment_scores = []\n",
        "    for sentence in tqdm(sentence_list, desc=\"VADER Sentiment Analysis\"):\n",
        "        # Check if the sentence is not empty\n",
        "        if sentence.strip():\n",
        "            sentiment = analyzer.polarity_scores(sentence)\n",
        "            # Append the compound score to the results list\n",
        "            sentiment_scores.append(sentiment['compound'])\n",
        "        else:\n",
        "            # Append a neutral score for empty sentences\n",
        "            sentiment_scores.append(0.0)\n",
        "\n",
        "    return sentiment_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgo9nVvIuwv-"
      },
      "outputs": [],
      "source": [
        "# Test English\n",
        "get_sentiment_vader_list(sentence_test_en_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB1Ugl6hvV80"
      },
      "outputs": [],
      "source": [
        "# Test French\n",
        "get_sentiment_vader_list(sentence_test_fr_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsRD3lKykZuC"
      },
      "source": [
        "## TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoVo9nuBoCWj"
      },
      "outputs": [],
      "source": [
        "# Sentiment: TextBlob (Fr with extension)\n",
        "!pip install -U textblob\n",
        "!pip install -U textblob-fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfdJzmLhoCKR"
      },
      "outputs": [],
      "source": [
        "\n",
        "from textblob import TextBlob\n",
        "from textblob import Blobber\n",
        "from textblob_fr import PatternTagger, PatternAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePtsv_GioCF8"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_textblob_list(sentence_list, language=\"en\"):\n",
        "\n",
        "    sentiment_scores = []\n",
        "\n",
        "    if language == \"en\":\n",
        "\n",
        "        # Analyze the sentiment for each sentence in the list\n",
        "        for sentence in tqdm(sentence_list, desc=\"TextBlob Sentiment Analysis\"):\n",
        "            # Check if the sentence is not empty\n",
        "            if sentence.strip():\n",
        "                textblob_analysis = TextBlob(sentence)\n",
        "                # Append the compound score to the results list\n",
        "                sentiment_scores.append(textblob_analysis.sentiment.polarity)\n",
        "            else:\n",
        "                # Append a neutral score for empty sentences\n",
        "                sentiment_scores.append(0.0)\n",
        "\n",
        "    elif language == \"fr\":\n",
        "\n",
        "        tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
        "\n",
        "        # Analyze the sentiment for each sentence in the list\n",
        "        for sentence in sentence_list:\n",
        "            # Check if the sentence is not empty\n",
        "            if sentence.strip():\n",
        "                sentiment_blob = tb(sentence)\n",
        "                # Append the compound score to the results list\n",
        "                sentiment_scores.append(sentiment_blob.sentiment[0])\n",
        "            else:\n",
        "                # Append a neutral score for empty sentences\n",
        "                sentiment_scores.append(0.0)\n",
        "\n",
        "    else:\n",
        "        print(f\"  ERROR: Invalid language for TextBlob: {language}\")\n",
        "        exit()\n",
        "\n",
        "    return sentiment_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFH3djq9u6Ll"
      },
      "outputs": [],
      "source": [
        "# Test English\n",
        "get_sentiment_textblob_list(sentence_test_en_list, \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmms7ZcDvdAJ"
      },
      "outputs": [],
      "source": [
        "# Test French\n",
        "get_sentiment_textblob_list(sentence_test_fr_list, \"fr\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iq6hj11kZuC"
      },
      "source": [
        "## BERTMulti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqASGwmAoaT0"
      },
      "outputs": [],
      "source": [
        "# Sentiment: Huggingface Transformers BERTMulti\n",
        "# pip install -q transformers\n",
        "from transformers import pipeline, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8iGC7N4oaQP"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_bertmulti_list(sentence_list, language=\"en\"):\n",
        "    \"\"\"\n",
        "    Given an input list of strings, returns an equal length list of the sentiment polarity values\n",
        "    for corresponding strings using VADER.\n",
        "\n",
        "    :param sentence_list: List of sentences (strings) to analyze.\n",
        "    :return: List of sentiment polarity values.\n",
        "    \"\"\"\n",
        "    # Initialize the HF Transformer sentiment model\n",
        "    hf_model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "    MAX_BERTMULTI_LEN = 350 # 512 is token limit * 3/4 word/token = 350 + ~50 padding\n",
        "    tokenizer = AutoTokenizer.from_pretrained(hf_model_name)\n",
        "    sentiment_bertmulti_pipeline = pipeline(\"sentiment-analysis\", model=hf_model_name, tokenizer=tokenizer)\n",
        "\n",
        "    # Analyze the sentiment for each sentence in the list\n",
        "    sentiment_scores = []\n",
        "    for sentence in tqdm(sentence_list, desc=\"BERT-Multi Sentiment Analysis\"):\n",
        "        # Trim sentence to MAX_BERTMULTI_LEN = 512\n",
        "        sentence_trimmed = sentence[:MAX_BERTMULTI_LEN]\n",
        "        if sentence_trimmed.strip():\n",
        "            sentiment = sentiment_bertmulti_pipeline(sentence_trimmed)\n",
        "            # Append the compound score to the results list\n",
        "            # print(f\" type(sentiment): {type(sentiment)}\")\n",
        "            # print(f\" sentiment: {sentiment}\")\n",
        "            # print(f\" dir(sentiment): {dir(sentiment)}\")\n",
        "            sentiment_star_int = convert_stars_to_int(sentiment[0]['label'])\n",
        "            sentiment_scores.append(sentiment_star_int)\n",
        "        else:\n",
        "            # Append a neutral score for empty sentences\n",
        "            sentiment_scores.append(0.0)\n",
        "\n",
        "    return sentiment_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMO3eaddvuHG"
      },
      "outputs": [],
      "source": [
        "# Test English\n",
        "get_sentiment_bertmulti_list(sentence_test_en_list, \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWf9XKWJvuBX"
      },
      "outputs": [],
      "source": [
        "# Test French\n",
        "get_sentiment_bertmulti_list(sentence_test_fr_list, \"fr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqgTh7ovkZuC"
      },
      "source": [
        "## Mistral LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1goo4gNgoaMT"
      },
      "outputs": [],
      "source": [
        "MODEL_OLLAMA = \"mistral7bsenti\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OoNlMlennzg"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_ollama_list(sentence_list, language=\"en\", ollama_model=MODEL_OLLAMA):\n",
        "\n",
        "    failure_count = 0\n",
        "    sentiment_scores = []\n",
        "    # for sentence in tqdm(sentence_list, desc=\"Ollama Sentiment Analysis\"):\n",
        "    # tqdm.tqdm(epochs, position=0, leave=True)\n",
        "    # from tqdm.auto import tqdm\n",
        "    for sentence in sentence_list:\n",
        "\n",
        "        response = ollama.generate(\n",
        "            model=ollama_model,\n",
        "            # PROMPT #1: Directional Correctness for human validation of model results\n",
        "            # prompt=f\"###SENTENCE:\\n{sentence}\\n\\n###INSTRUCTIONS:\\nGiven the above ###SENTENCE, estimate the sentiment as either 'negative', 'neutral', or 'positive' Return only one word for sentiment and nothing else, no header, explaination, introduction, summary, conclusion. Only return a single float number for the sentiment polarity\"\n",
        "            # PROMPT #2: Precise -1.0 to +1.0 sentiment for calcuation\n",
        "            prompt=f\"###SENTENCE:\\n{sentence}\\n\\n###INSTRUCTIONS:\\nGiven the above ###SENTENCE, estimate the sentiment as a float number from -1.0 (most negative) to 0.0 (neutral) to 1.0 (most positive). Return only one float number between -1.0 and 1.0   for sentiment polarity and nothing else, no header, explaination, introduction, summary, conclusion. Only return a single float number for the sentiment polarity\"\n",
        "        )\n",
        "\n",
        "        sentiment_polarity = response['response'].strip()\n",
        "        # print(f\"sentiment_polarity: {sentiment_polarity}\")\n",
        "        # print(f\"type(sentiment_polarity): {type(sentiment_polarity)}\")\n",
        "\n",
        "        try:\n",
        "            sentiment_polarity = float(sentiment_polarity)\n",
        "            if sentiment_polarity > 1.0:\n",
        "                sentiment_scores.append(1.0)\n",
        "            elif sentiment_polarity < -1.0:\n",
        "                sentiment_scores.append(-1.0)\n",
        "            else:\n",
        "                sentiment_scores.append(sentiment_polarity)\n",
        "        except (ValueError, TypeError):\n",
        "            # In case of error, default to 0.0\n",
        "            failure_count += 1\n",
        "            sentiment_scores.append(0.0)\n",
        "\n",
        "    print(f\"FAILURE COUNT: {failure_count}\")\n",
        "    print(f\"FAILURE RATE: {(failure_count/len(sentence_list)):.2f}\")\n",
        "    return sentiment_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ2ie5ynv7SB"
      },
      "outputs": [],
      "source": [
        "# Test English\n",
        "get_sentiment_ollama_list(sentence_test_en_list, \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpC7RTgjv7On"
      },
      "outputs": [],
      "source": [
        "# Test French\n",
        "get_sentiment_ollama_list(sentence_test_fr_list, \"fr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezKZTkjskZuD"
      },
      "source": [
        "## Combine into a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ],
      "metadata": {
        "id": "gip5npqzlDf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for asent in clean_text_reformat_seg_filter_dict['book_proust_fr_swans-way_proust'][:10]:\n",
        "  asentiment = get_sentiment_ollama_list([asent], \"fr\")\n",
        "  print(f\"  SENTIMENT: {asentiment} for {asent}\\n\\n\")"
      ],
      "metadata": {
        "id": "v5VyvjOAlhSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(clean_text_reformat_seg_filter_dict[list(clean_text_reformat_seg_filter_dict.keys())[0]])"
      ],
      "metadata": {
        "id": "E_p19HxAlDct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FKS8vM7uYnZ"
      },
      "outputs": [],
      "source": [
        "def create_sentiment_dataframes(clean_text_reformat_seg_filter_dict):\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in clean_text_reformat_seg_filter_dict.items():\n",
        "        print(f\"Processing sentiments for: {key}\")\n",
        "\n",
        "        vader_sentiments = get_sentiment_vader_list(segment_list)\n",
        "        textblob_sentiments = get_sentiment_textblob_list(segment_list, language=\"en\")\n",
        "        bertmulti_sentiments = get_sentiment_bertmulti_list(segment_list, language=\"en\")\n",
        "        ollama_sentiments = get_sentiment_ollama_list(segment_list, language=\"en\") # , ollama_model=MODEL_OLLAMA)\n",
        "\n",
        "        data = {\n",
        "            'text': segment_list,\n",
        "            'vader': vader_sentiments,\n",
        "            'textblob': textblob_sentiments,\n",
        "            'bertmulti': bertmulti_sentiments,\n",
        "            'mistral': ollama_sentiments\n",
        "        }\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        clean_text_sentiments_dict[key] = df\n",
        "\n",
        "    return clean_text_sentiments_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8dOzFDYkZuD"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93RPEiQakZuD"
      },
      "outputs": [],
      "source": [
        "# type(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff_original_segments.txt\"])\n",
        "\n",
        "type(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff\"])\n",
        "\n",
        "len(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u9AROYJkZuD"
      },
      "outputs": [],
      "source": [
        "# clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff_original_segments.txt\"][:10]\n",
        "\n",
        "clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff\"][:5]\n",
        "len(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SSKCXbPkZuD"
      },
      "outputs": [],
      "source": [
        "# len(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff_original_segments.txt\"])\n",
        "\n",
        "len(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z4Nv-VdkZuD"
      },
      "source": [
        "## Truncate Strings for Transformer (max tokens 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyWimwdNkZuD"
      },
      "outputs": [],
      "source": [
        "MAX_STRING_LEN = 350"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIyJvMAJkZuD"
      },
      "outputs": [],
      "source": [
        "def truncate_strings_in_dict_of_lists(dictionary_in, shorter_length=MAX_STRING_LEN):\n",
        "    \"\"\"\n",
        "    Truncates the individual strings in the input dictionary's lists to the specified shorter length.\n",
        "\n",
        "    Parameters:\n",
        "    dictionary_in (dict): The input dictionary with lists of strings as values.\n",
        "    shorter_length (int): The length to which each string should be truncated.\n",
        "\n",
        "    Returns:\n",
        "    dict: A copy of the input dictionary with truncated strings.\n",
        "    \"\"\"\n",
        "    truncated_dict = {}\n",
        "\n",
        "    for key, value_list in dictionary_in.items():\n",
        "        # Truncate each string in the list to the specified length\n",
        "        truncated_list = [s[:shorter_length] for s in value_list]\n",
        "        print(f\"   TRUNCATED Original length for first string in {key}: {len(value_list[0]) if value_list else 0}\")\n",
        "        print(f\"             Truncated length for first string in {key}: {len(truncated_list[0]) if truncated_list else 0}\")\n",
        "        # Store the list with truncated strings in the output dictionary\n",
        "        truncated_dict[key] = truncated_list\n",
        "\n",
        "    return truncated_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FzMQVJpkZuD"
      },
      "outputs": [],
      "source": [
        "%whos list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tijJs0r8kZuD"
      },
      "outputs": [],
      "source": [
        "clean_test_reformat_seg_filter_truncate_dict = truncate_strings_in_dict_of_lists(clean_text_reformat_seg_filter_dict, MAX_STRING_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhPcdas8kZuE"
      },
      "outputs": [],
      "source": [
        "clean_test_reformat_seg_filter_truncate_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIuh52_0kZuE"
      },
      "outputs": [],
      "source": [
        "# clean_test_reformat_seg_filter_test_dict['book_proust_en_swans-way_moncrieff_original_segments.txt'][:10]\n",
        "\n",
        "clean_test_reformat_seg_filter_truncate_dict['book_proust_en_swans-way_moncrieff'][:10]\n",
        "len(clean_test_reformat_seg_filter_truncate_dict['book_proust_en_swans-way_moncrieff'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8chNJukkZuE"
      },
      "outputs": [],
      "source": [
        "# len(clean_test_reformat_seg_filter_test_dict['book_proust_en_swans-way_moncrieff'])\n",
        "\n",
        "len(clean_test_reformat_seg_filter_truncate_dict['book_proust_en_swans-way_moncrieff'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGkAj6YrkZuE"
      },
      "source": [
        "### Get Sentiments One String per"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "id": "6gEZGeQ9JhPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CALL_OLLAMA = 3"
      ],
      "metadata": {
        "id": "fnQoidA2J0N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_ollama(text: str) -> float:\n",
        "    for attempt in range(1, MAX_CALL_OLLAMA + 1):\n",
        "        try:\n",
        "            logging.info(f\"Attempt {attempt}: Sending text to Ollama for sentiment analysis\")\n",
        "            res = ollama.chat(\n",
        "                model=\"mistral7bsenti\",\n",
        "                messages=[{'role': 'user', 'content': f'Only give the sentiment polarity float value between -1.0 and 1.0 for: {text}'}],\n",
        "                stream=False,\n",
        "                options={\"temperature\": 0.3, \"top_p\": 0.5}\n",
        "            )\n",
        "            if 'message' in res and 'content' in res['message']:\n",
        "                text_sentiment_float_str = res['message']['content'].strip()\n",
        "                try:\n",
        "                    text_sentiment_float = float(text_sentiment_float_str)\n",
        "                    logging.info(f\"Received sentiment analysis response and successfully converted to float\")\n",
        "                    return text_sentiment_float\n",
        "                except ValueError:\n",
        "                    logging.warning(f\"Attempt {attempt}: Could not convert response to float: {text_sentiment_float_str}\")\n",
        "            else:\n",
        "                logging.error(f\"Attempt {attempt}: Unexpected API response format: {res}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Attempt {attempt}: Error during sentiment analysis for text: {e}\")\n",
        "    logging.error(f\"All {MAX_CALL_OLLAMA} attempts failed for text: {text}. Returning 0.0\")\n",
        "    return 0.0"
      ],
      "metadata": {
        "id": "3GjP1gjtJd4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Sentiments by List"
      ],
      "metadata": {
        "id": "NV_Kq6hMldEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_str = \"I love lint\"\n",
        "test_list = [\"i love lint\", \"I don't care\", \"I hate you\"]\n",
        "\n",
        "# sentiment_polarity = get_sentiment_ollama(test_str)\n",
        "\n",
        "# sentiment_polarity = get_sentiment_ollama_list([test_str], \"en\")\n",
        "sentiment_polarity = get_sentiment_ollama_list(test_list, \"en\")\n",
        "print(sentiment_polarity)"
      ],
      "metadata": {
        "id": "40EetD-mJooq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NsParOUkZuE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def get_sentiment_vader_safe(segment_list, language, dir_out):\n",
        "    try:\n",
        "        vader_sentiments = get_sentiment_vader_list(segment_list)  # Placeholder for actual sentiment analysis\n",
        "        df = pd.DataFrame({'text': segment_list, 'vader': vader_sentiments})\n",
        "        partial_vader_path = os.path.join(dir_out, 'vader_partial.csv')\n",
        "        df.to_csv(partial_vader_path, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_vader: {e}\")\n",
        "        return False\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_vader_safe(segment_list, language, dir_out, book_title):\n",
        "    try:\n",
        "        vader_sentiments = get_sentiment_vader_list(segment_list)  # Placeholder for actual sentiment analysis\n",
        "        df = pd.DataFrame({'text': segment_list, 'vader': vader_sentiments})\n",
        "        partial_vader_path = os.path.join(dir_out, f\"{book_title}_vader_partial.csv\")\n",
        "        df.to_csv(partial_vader_path, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_vader: {e}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "WpGYi_lXrjzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTsmA4eGkZuE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def get_sentiment_textblob_safe(segment_list, language, dir_out):\n",
        "    try:\n",
        "        textblob_sentiments = get_sentiment_textblob_list(segment_list)  # Placeholder for actual sentiment analysis\n",
        "        df = pd.DataFrame({'text': segment_list, 'textblob': textblob_sentiments})\n",
        "        partial_textblob_path = os.path.join(dir_out, 'textblob_partial.csv')\n",
        "        df.to_csv(partial_textblob_path, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_textblob: {e}\")\n",
        "        return False\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_sentiment_textblob_safe(segment_list, language, dir_out, book_title):\n",
        "    try:\n",
        "        textblob_sentiments = get_sentiment_textblob_list(segment_list, language)  # Placeholder for actual sentiment analysis\n",
        "        df = pd.DataFrame({'text': segment_list, 'textblob': textblob_sentiments})\n",
        "        partial_textblob_path = os.path.join(dir_out, f\"{book_title}_textblob_partial.csv\")\n",
        "        df.to_csv(partial_textblob_path, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_textblob: {e}\")\n",
        "        return False\n",
        "\n"
      ],
      "metadata": {
        "id": "Ob0Vxlodrwl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVBxxpjhkZuE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def get_sentiment_bertmulti_safe(segment_list, language, dir_out):\n",
        "    try:\n",
        "        bertmulti_sentiments = get_sentiment_bertmulti_list(segment_list)  # Placeholder for actual sentiment analysis\n",
        "        df = pd.DataFrame({'text': segment_list, 'bertmulti': bertmulti_sentiments})\n",
        "        partial_bertmulti_path = os.path.join(dir_out, 'bertmulti_partial.csv')\n",
        "        df.to_csv(partial_bertmulti_path, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_bertmulti: {e}\")\n",
        "        return False\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_sentiment_bertmulti_safe(segment_list, language, dir_out, book_title):\n",
        "    try:\n",
        "        bertmulti_sentiments = get_sentiment_bertmulti_list(segment_list)  # Placeholder for actual sentiment analysis\n",
        "        df = pd.DataFrame({'text': segment_list, 'bertmulti': bertmulti_sentiments})\n",
        "        partial_bertmulti_path = os.path.join(dir_out, f\"{book_title}_bertmulti_partial.csv\")\n",
        "        df.to_csv(partial_bertmulti_path, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_bertmulti: {e}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "J75-vmREtmZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_OLLAMA = 'mistral7bsenti'"
      ],
      "metadata": {
        "id": "FxstzK3X8okH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_OLLAMA = 'mistral7bsenti'\n",
        "\n",
        "def get_sentiment_ollama_list(sentence_list, language=\"en\", dir_out=\"\", ollama_model=MODEL_OLLAMA):\n",
        "    output_file = os.path.join(dir_out, 'ollama_sentiment.csv')\n",
        "\n",
        "    # Check if the output file already exists\n",
        "    if os.path.exists(output_file):\n",
        "        try:\n",
        "            df = pd.read_csv(output_file)\n",
        "            # Ensure the existing data matches the input sentence list\n",
        "            if list(df['text']) == sentence_list:\n",
        "                print(\"Output file already exists and matches the input sentence list.\")\n",
        "                return df['ollama_sentiment'].tolist()\n",
        "            else:\n",
        "                print(\"Output file exists but does not match the input sentence list. Reprocessing...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading existing output file: {e}. Reprocessing...\")\n",
        "\n",
        "    failure_count = 0\n",
        "    sentiment_scores = []\n",
        "\n",
        "    for sentence in sentence_list:\n",
        "        response = ollama.generate(\n",
        "            model=ollama_model,\n",
        "            prompt=f\"###SENTENCE:\\n{sentence}\\n\\n###INSTRUCTIONS:\\nGiven the above ###SENTENCE, estimate the sentiment as a float number from -1.0 (most negative) to 0.0 (neutral) to 1.0 (most positive). Return only one float number between -1.0 and 1.0 for sentiment polarity and nothing else, no header, explanation, introduction, summary, conclusion. Only return a single float number for the sentiment polarity\"\n",
        "        )\n",
        "\n",
        "        sentiment_polarity = response['response'].strip()\n",
        "\n",
        "        try:\n",
        "            sentiment_polarity = float(sentiment_polarity)\n",
        "            if sentiment_polarity > 1.0:\n",
        "                sentiment_scores.append(1.0)\n",
        "            elif sentiment_polarity < -1.0:\n",
        "                sentiment_scores.append(-1.0)\n",
        "            else:\n",
        "                sentiment_scores.append(sentiment_polarity)\n",
        "        except (ValueError, TypeError):\n",
        "            failure_count += 1\n",
        "            sentiment_scores.append(0.0)\n",
        "\n",
        "    df = pd.DataFrame({'text': sentence_list, 'ollama_sentiment': sentiment_scores})\n",
        "    try:\n",
        "        df.to_csv(output_file, index=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving output file: {e}\")\n",
        "\n",
        "    print(f\"FAILURE COUNT: {failure_count}\")\n",
        "    print(f\"FAILURE RATE: {(failure_count/len(sentence_list)):.2f}\")\n",
        "\n",
        "    return sentiment_scores\n"
      ],
      "metadata": {
        "id": "T3v8zL74mjo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5IrFeG0kZuE"
      },
      "outputs": [],
      "source": [
        "# USE: get_sentiment_ollama_list()\n",
        "\n",
        "\"\"\"\n",
        "def get_sentiment_ollama_safe(segment_list, language, dir_out):\n",
        "    try:\n",
        "      ollama_sentiment_list = []\n",
        "      for asegment in segment_list:\n",
        "        # print(asegment)\n",
        "        ollama_sentiment = get_sentiment_ollama(segment_list)  # Placeholder for actual sentiment analysis\n",
        "        ollama_sentiment_list.append(ollama_sentiment)\n",
        "      df = pd.DataFrame({'text': segment_list, 'mistral': ollama_sentiment_list})\n",
        "      partial_ollama_path = os.path.join(dir_out, 'ollama_partial.csv')\n",
        "      df.to_csv(partial_ollama_path, index=False)\n",
        "      return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in get_sentiment_ollama: {e}\")\n",
        "        return False\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJatn1kKkZuE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def get_sentiment_all(dictionary_of_lists, directory_out):\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in dictionary_of_lists.items():\n",
        "        print(f\"Processing: {key} with len(segment_list) = {len(segment_list)}\")\n",
        "\n",
        "        if get_sentiment_vader(segment_list, 'en', directory_out) and \\\n",
        "           get_sentiment_textblob(segment_list, 'en', directory_out) and \\\n",
        "           get_sentiment_bertmulti(segment_list, 'en', directory_out) and \\\n",
        "           get_sentiment_ollama(segment_list, 'en', directory_out):\n",
        "\n",
        "            vader_path = os.path.join(directory_out, 'vader_partial.csv')\n",
        "            textblob_path = os.path.join(directory_out, 'textblob_partial.csv')\n",
        "            bertmulti_path = os.path.join(directory_out, 'bertmulti_partial.csv')\n",
        "            ollama_path = os.path.join(directory_out, 'ollama_partial.csv')\n",
        "\n",
        "            vader_df = pd.read_csv(vader_path)\n",
        "            textblob_df = pd.read_csv(textblob_path)\n",
        "            bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "            ollama_df = pd.read_csv(ollama_path)\n",
        "\n",
        "            final_df = vader_df\n",
        "            final_df['textblob'] = textblob_df['textblob']\n",
        "            final_df['bertmulti'] = bertmulti_df['bertmulti']\n",
        "            final_df['mistral'] = ollama_df['mistral']\n",
        "\n",
        "            clean_text_sentiments_dict[key] = final_df\n",
        "\n",
        "            # Optionally, save the final combined dataframe\n",
        "            final_output_path = os.path.join(directory_out, key.replace('_verified.txt', '_segments.csv'))\n",
        "            final_df.to_csv(final_output_path, index=False)\n",
        "\n",
        "    return clean_text_sentiments_dict\n",
        "\n",
        "# Example usage\n",
        "clean_test_reformat_seg_filter_dict = {\n",
        "    'book_proust_fr_swans-way_proust_original_verified.txt': [\"Sentence 1\", \"Sentence 2\", \"Sentence 3\", \"Sentence 4\"],\n",
        "    'book_proust_en_swans-way_enright_original_verified.txt': [\"Sentence A\", \"Sentence B\", \"Sentence C\", \"Sentence D\"],\n",
        "    'book_proust_en_swans-way_davis_original_verified.txt': [\"Sentence X\", \"Sentence Y\", \"Sentence Z\"],\n",
        "    'book_proust_en_swans-way_moncrieff_original_verified.txt': [\"Sentence Alpha\", \"Sentence Beta\"]\n",
        "}\n",
        "\n",
        "# sentiments_test_dict = get_sentiment_all(clean_test_reformat_seg_filter_test_dict, 'sentiments')\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-fIMNiLkZuE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def get_sentiment_all(dictionary_of_lists, directory_out):\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in dictionary_of_lists.items():\n",
        "        filename_root, filename_ext = os.path.splitext(key)\n",
        "        print(f\"Processing: {key} with len(segment_list) = {len(segment_list)}\")\n",
        "\n",
        "        success = True\n",
        "\n",
        "        # Process VADER sentiments\n",
        "        if not get_sentiment_vader_safe(segment_list, 'en', directory_out, filename_root):\n",
        "            print(f\"Failed to process VADER for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            vader_path = os.path.join(directory_out, 'vader_partial.csv')\n",
        "            vader_df = pd.read_csv(vader_path)\n",
        "\n",
        "        # Process TextBlob sentiments\n",
        "        if not get_sentiment_textblob_safe(segment_list, 'en', directory_out, filename_root):\n",
        "            print(f\"Failed to process TextBlob for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            textblob_path = os.path.join(directory_out, 'textblob_partial.csv')\n",
        "            textblob_df = pd.read_csv(textblob_path)\n",
        "\n",
        "        # Process BERT multi-language sentiments\n",
        "        if not get_sentiment_bertmulti_safe(segment_list, 'en', directory_out, filename_root):\n",
        "            print(f\"Failed to process BERTMulti for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            bertmulti_path = os.path.join(directory_out, 'bertmulti_partial.csv')\n",
        "            bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "\n",
        "        # Process Ollama sentiments\n",
        "        if not get_sentiment_ollama_list(segment_list, 'en', directory_out, filename_root, ollama_model=\"mistral7bsenti\"):\n",
        "            print(f\"Failed to process Ollama for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            ollama_path = os.path.join(directory_out, 'ollama_partial.csv')\n",
        "            ollama_df = pd.read_csv(ollama_path)\n",
        "\n",
        "        if success:\n",
        "            # Combine results\n",
        "            final_df = vader_df\n",
        "            final_df['textblob'] = textblob_df['textblob']\n",
        "            final_df['bertmulti'] = bertmulti_df['bertmulti']\n",
        "            final_df['mistral'] = ollama_df['mistral']\n",
        "\n",
        "            clean_text_sentiments_dict[key] = final_df\n",
        "\n",
        "            # Save the final combined dataframe\n",
        "            final_output_path = os.path.join(directory_out, key.replace('_verified.txt', '_sentiments.csv'))\n",
        "            final_df.to_csv(final_output_path, index=False)\n",
        "        else:\n",
        "            print(f\"Skipping final combination for {key} due to previous failures.\")\n",
        "\n",
        "    return clean_text_sentiments_dict\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def get_sentiment_all(dictionary_of_lists, directory_out):\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in dictionary_of_lists.items():\n",
        "        filename_root, filename_ext = os.path.splitext(key)\n",
        "        print(f\"Processing: {key} with len(segment_list) = {len(segment_list)}\")\n",
        "\n",
        "        success = True\n",
        "\n",
        "        # Process VADER sentiments\n",
        "        if not get_sentiment_vader_safe(segment_list, 'en', directory_out, filename_root):\n",
        "            print(f\"Failed to process VADER for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            vader_path = os.path.join(directory_out, f\"{filename_root}_vader_partial.csv\")\n",
        "            vader_df = pd.read_csv(vader_path)\n",
        "\n",
        "        # Process TextBlob sentiments\n",
        "        if not get_sentiment_textblob_safe(segment_list, 'en', directory_out, filename_root):\n",
        "            print(f\"Failed to process TextBlob for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            textblob_path = os.path.join(directory_out, f\"{filename_root}_textblob_partial.csv\")\n",
        "            textblob_df = pd.read_csv(textblob_path)\n",
        "\n",
        "        # Process BERT multi-language sentiments\n",
        "        if not get_sentiment_bertmulti_safe(segment_list, 'en', directory_out, filename_root):\n",
        "            print(f\"Failed to process BERTMulti for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            bertmulti_path = os.path.join(directory_out, f\"{filename_root}_bertmulti_partial.csv\")\n",
        "            bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "\n",
        "        # Process Ollama sentiments\n",
        "        if not get_sentiment_ollama_list(segment_list, 'en', directory_out, filename_root, ollama_model=\"mistral7bsenti\"):\n",
        "            print(f\"Failed to process Ollama for {key}\")\n",
        "            success = False\n",
        "        else:\n",
        "            ollama_path = os.path.join(directory_out, f\"{filename_root}_ollama_partial.csv\")\n",
        "            ollama_df = pd.read_csv(ollama_path)\n",
        "\n",
        "        if success:\n",
        "            # Combine results\n",
        "            final_df = vader_df\n",
        "            final_df['textblob'] = textblob_df['textblob']\n",
        "            final_df['bertmulti'] = bertmulti_df['bertmulti']\n",
        "            final_df['mistral'] = ollama_df['mistral']\n",
        "\n",
        "            clean_text_sentiments_dict[key] = final_df\n",
        "\n",
        "            # Save the final combined dataframe\n",
        "            final_output_path = os.path.join(directory_out, f\"{filename_root}_sentiments.csv\")\n",
        "            final_df.to_csv(final_output_path, index=False)\n",
        "        else:\n",
        "            print(f\"Skipping final combination for {key} due to previous failures.\")\n",
        "\n",
        "    return clean_text_sentiments_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "KSv_AlGGvTnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_sentiment_all(dictionary_of_lists, directory_out):\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in tqdm(dictionary_of_lists.items(), desc=\"Processing files\"):\n",
        "        filename_root, filename_ext = os.path.splitext(key)\n",
        "        final_output_path = os.path.join(directory_out, f\"{filename_root}_sentiments.csv\")\n",
        "\n",
        "        # Check if the final output file already exists\n",
        "        if os.path.exists(final_output_path):\n",
        "            print(f\"Output file for {key} already exists. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing: {key} with len(segment_list) = {len(segment_list)}\")\n",
        "\n",
        "        success = True\n",
        "\n",
        "        # Define paths for partial sentiment files\n",
        "        vader_path = os.path.join(directory_out, f\"{filename_root}_vader_partial.csv\")\n",
        "        textblob_path = os.path.join(directory_out, f\"{filename_root}_textblob_partial.csv\")\n",
        "        bertmulti_path = os.path.join(directory_out, f\"{filename_root}_bertmulti_partial.csv\")\n",
        "        ollama_path = os.path.join(directory_out, f\"{filename_root}_ollama_partial.csv\")\n",
        "\n",
        "        # Check for the existence of each partial sentiment file and read them if they exist\n",
        "        if os.path.exists(vader_path):\n",
        "            vader_df = pd.read_csv(vader_path)\n",
        "            print(f\"Loaded VADER results from {vader_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_vader_safe(segment_list, 'en', directory_out, filename_root):\n",
        "                print(f\"Failed to process VADER for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                vader_df = pd.read_csv(vader_path)\n",
        "\n",
        "        if os.path.exists(textblob_path):\n",
        "            textblob_df = pd.read_csv(textblob_path)\n",
        "            print(f\"Loaded TextBlob results from {textblob_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_textblob_safe(segment_list, 'en', directory_out, filename_root):\n",
        "                print(f\"Failed to process TextBlob for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                textblob_df = pd.read_csv(textblob_path)\n",
        "\n",
        "        if os.path.exists(bertmulti_path):\n",
        "            bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "            print(f\"Loaded BERTMulti results from {bertmulti_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_bertmulti_safe(segment_list, 'en', directory_out, filename_root):\n",
        "                print(f\"Failed to process BERTMulti for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "\n",
        "        # Adding random sleep time between 1 and 3 seconds\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "\n",
        "        if os.path.exists(ollama_path):\n",
        "            ollama_df = pd.read_csv(ollama_path)\n",
        "            print(f\"Loaded Ollama results from {ollama_path}\")\n",
        "        else:\n",
        "            try:\n",
        "                if not get_sentiment_ollama_list(segment_list, language='en', dir_out=directory_out, ollama_model=\"mistral7bsenti\"):\n",
        "                    print(f\"Failed to process Ollama for {key}\")\n",
        "                    success = False\n",
        "                else:\n",
        "                    ollama_df = pd.read_csv(ollama_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing Ollama for {key}: {e}\")\n",
        "                # Assign default value 99 to all Ollama sentiment values\n",
        "                ollama_df = pd.DataFrame({'text': segment_list, 'mistral': [99] * len(segment_list)})\n",
        "\n",
        "        if success:\n",
        "            # Combine results\n",
        "            final_df = vader_df\n",
        "            final_df['textblob'] = textblob_df['textblob']\n",
        "            final_df['bertmulti'] = bertmulti_df['bertmulti']\n",
        "            final_df['mistral'] = ollama_df['mistral']\n",
        "\n",
        "            clean_text_sentiments_dict[key] = final_df\n",
        "\n",
        "            # Save the final combined dataframe\n",
        "            final_df.to_csv(final_output_path, index=False)\n",
        "        else:\n",
        "            print(f\"Skipping final combination for {key} due to previous failures.\")\n",
        "\n",
        "    return clean_text_sentiments_dict\n",
        "\n",
        "# Ensure to define or import the ollama.generate function and its dependencies\n"
      ],
      "metadata": {
        "id": "_wjTQGNQ665x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP5pK6h-kZuE"
      },
      "outputs": [],
      "source": [
        "sentiments_dict = get_sentiment_all(clean_test_reformat_seg_filter_truncate_dict, 'sentiments')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save"
      ],
      "metadata": {
        "id": "29fwd8akK0el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dict_of_df(sentiments_dict, \"text_sentiments\")"
      ],
      "metadata": {
        "id": "1T6LDnNRLVB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a zip archive of these files\n",
        "subdir = 'text_sentiments'\n",
        "\n",
        "# Zip the subdirectory\n",
        "shutil.make_archive(subdir, 'zip', subdir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(subdir + '.zip')"
      ],
      "metadata": {
        "id": "UTh2KkVbLVCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## END"
      ],
      "metadata": {
        "id": "I8rbP5J-LTKL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUBATxYzkZuE"
      },
      "outputs": [],
      "source": [
        "sentiments_test_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVmyYjkLkZuE"
      },
      "outputs": [],
      "source": [
        "sentiments_test_dict['book_proust_fr_swans-way_proust_original_verified.txt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fgvYaiFkZuF"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gws9VU0xkZuF"
      },
      "outputs": [],
      "source": [
        "len(clean_text_reformat_seg_filter_dict['book_proust_fr_swans-way_proust_original_verified.txt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5A_pe4akZuF"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict['book_proust_fr_swans-way_proust_original_verified.txt'][:10]\n",
        "len(clean_text_reformat_seg_filter_dict['book_proust_fr_swans-way_proust_original_verified.txt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Results"
      ],
      "metadata": {
        "id": "ACmwhyT6y7Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_dict_of_df_to_files(directory_out, dict_of_df, segment_type='segments'):\n",
        "    \"\"\"\n",
        "    Saves each DataFrame from the dictionary to separate files in the specified directory.\n",
        "\n",
        "    Parameters:\n",
        "    directory_out (str): The directory where the files will be saved.\n",
        "    dict_of_df (dict): Dictionary where keys are filenames and values are pandas DataFrames.\n",
        "    segment_type (str): The suffix to be added to the output filenames.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with filenames as keys and their paths as values.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    file_paths = {}\n",
        "\n",
        "    for key in dict_of_df.keys():\n",
        "        # Create the output filename\n",
        "        filename_out = key.replace('_verified.txt', f'_{segment_type}.csv')\n",
        "        output_file_path = os.path.join(directory_out, filename_out)\n",
        "\n",
        "        # Debug: Print the current filename and output path\n",
        "        print(f\"Saving file: {output_file_path}\")\n",
        "\n",
        "        # Enhanced Debug: Print the shape of the DataFrame\n",
        "        print(f\"DataFrame shape for {key}: {dict_of_df[key].shape}\")\n",
        "\n",
        "        # Write the DataFrame to a CSV file\n",
        "        dict_of_df[key].to_csv(output_file_path, index=False)\n",
        "\n",
        "        # Store the filename and its path in the dictionary\n",
        "        file_paths[filename_out] = output_file_path\n",
        "\n",
        "    return file_paths"
      ],
      "metadata": {
        "id": "pJqAnJypy01s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileout_paths_dict = write_dict_of_df_to_files('test_sentiments', sentiments_test_dict, 'sentiments')"
      ],
      "metadata": {
        "id": "jn8dveE6zASu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrHraoLCzAPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b8nf4DlzI-s"
      },
      "outputs": [],
      "source": [
        "fileout_paths_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PluAT7pqzI-t"
      },
      "outputs": [],
      "source": [
        "sentiments_all_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMPbwpnEzI-t"
      },
      "outputs": [],
      "source": [
        "sentiments_all_dict['book_proust_fr_swans-way_proust_original_verified.txt'][:10]\n",
        "\n",
        "len(sentiments_all_dict['book_proust_fr_swans-way_proust_original_verified.txt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t-wrLLvzI-t"
      },
      "outputs": [],
      "source": [
        "fileout_paths_dict = save_dict_to_files('sentiments', sentiments_all_dict, 'sentiments')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vLUcJeIzANK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "98wzXbBJzAKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBDZ4Zaay0x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDbUAoJny0uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_vader_safe(segment_list, lang, directory_out, filename):\n",
        "    # Dummy implementation for illustration\n",
        "    try:\n",
        "        results = []  # Perform VADER sentiment analysis on segment_list\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(filename, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in VADER sentiment analysis: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_sentiment_textblob_safe(segment_list, lang, directory_out, filename):\n",
        "    # Dummy implementation for illustration\n",
        "    try:\n",
        "        results = []  # Perform TextBlob sentiment analysis on segment_list\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(filename, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in TextBlob sentiment analysis: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_sentiment_bertmulti_safe(segment_list, lang, directory_out, filename):\n",
        "    # Dummy implementation for illustration\n",
        "    try:\n",
        "        results = []  # Perform BERT multi-language sentiment analysis on segment_list\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(filename, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in BERTMulti sentiment analysis: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_sentiment_ollama_safe(segment_list, lang, directory_out, filename):\n",
        "    # Dummy implementation for illustration\n",
        "    try:\n",
        "        results = []  # Perform Ollama sentiment analysis on segment_list\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(filename, index=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Ollama sentiment analysis: {e}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "VY6pGYDRpge9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def get_sentiment_all(dictionary_of_lists, directory_out):\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in dictionary_of_lists.items():\n",
        "        print(f\"Processing: {key} with len(segment_list) = {len(segment_list)}\")\n",
        "\n",
        "        success = True\n",
        "        vader_df = textblob_df = bertmulti_df = ollama_df = None\n",
        "\n",
        "        # Extract the base name of the book\n",
        "        book_name = key.replace('_verified.txt', '')\n",
        "\n",
        "        # Define intermediate file paths\n",
        "        vader_path = os.path.join(directory_out, f'{book_name}_vader_partial.csv')\n",
        "        textblob_path = os.path.join(directory_out, f'{book_name}_textblob_partial.csv')\n",
        "        bertmulti_path = os.path.join(directory_out, f'{book_name}_bertmulti_partial.csv')\n",
        "        ollama_path = os.path.join(directory_out, f'{book_name}_ollama_partial.csv')\n",
        "\n",
        "        # Process VADER sentiments\n",
        "        if os.path.exists(vader_path):\n",
        "            vader_df = pd.read_csv(vader_path)\n",
        "            print(f\"Loaded VADER results from {vader_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_vader_safe(segment_list, 'en', directory_out, vader_path):\n",
        "                print(f\"Failed to process VADER for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                if os.path.exists(vader_path):\n",
        "                    vader_df = pd.read_csv(vader_path)\n",
        "                    print(f\"Saved VADER results to {vader_path}\")\n",
        "                    files.download(vader_path)  # Download the VADER results\n",
        "                else:\n",
        "                    print(f\"VADER results file not found for {key}\")\n",
        "                    success = False\n",
        "\n",
        "        # Process TextBlob sentiments\n",
        "        if os.path.exists(textblob_path):\n",
        "            textblob_df = pd.read_csv(textblob_path)\n",
        "            print(f\"Loaded TextBlob results from {textblob_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_textblob_safe(segment_list, 'en', directory_out, textblob_path):\n",
        "                print(f\"Failed to process TextBlob for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                if os.path.exists(textblob_path):\n",
        "                    textblob_df = pd.read_csv(textblob_path)\n",
        "                    print(f\"Saved TextBlob results to {textblob_path}\")\n",
        "                    files.download(textblob_path)  # Download the TextBlob results\n",
        "                else:\n",
        "                    print(f\"TextBlob results file not found for {key}\")\n",
        "                    success = False\n",
        "\n",
        "        # Process BERT multi-language sentiments\n",
        "        if os.path.exists(bertmulti_path):\n",
        "            bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "            print(f\"Loaded BERTMulti results from {bertmulti_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_bertmulti_safe(segment_list, 'en', directory_out, bertmulti_path):\n",
        "                print(f\"Failed to process BERTMulti for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                if os.path.exists(bertmulti_path):\n",
        "                    bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "                    print(f\"Saved BERTMulti results to {bertmulti_path}\")\n",
        "                    files.download(bertmulti_path)  # Download the BERTMulti results\n",
        "                else:\n",
        "                    print(f\"BERTMulti results file not found for {key}\")\n",
        "                    success = False\n",
        "\n",
        "        # Process Ollama sentiments\n",
        "        if os.path.exists(ollama_path):\n",
        "            ollama_df = pd.read_csv(ollama_path)\n",
        "            print(f\"Loaded Ollama results from {ollama_path}\")\n",
        "        else:\n",
        "            if not get_sentiment_ollama_safe(segment_list, 'en', directory_out, ollama_path):\n",
        "                print(f\"Failed to process Ollama for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                if os.path.exists(ollama_path):\n",
        "                    ollama_df = pd.read_csv(ollama_path)\n",
        "                    print(f\"Saved Ollama results to {ollama_path}\")\n",
        "                    files.download(ollama_path)  # Download the Ollama results\n",
        "                else:\n",
        "                    print(f\"Ollama results file not found for {key}\")\n",
        "                    success = False\n",
        "\n",
        "        if success:\n",
        "            # Combine results\n",
        "            final_df = vader_df\n",
        "            final_df['textblob'] = textblob_df['textblob']\n",
        "            final_df['bertmulti'] = bertmulti_df['bertmulti']\n",
        "            final_df['mistral'] = ollama_df['mistral']\n",
        "\n",
        "            clean_text_sentiments_dict[key] = final_df\n",
        "\n",
        "            # Save the final combined dataframe\n",
        "            final_output_path = os.path.join(directory_out, f'{book_name}_segments.csv')\n",
        "            final_df.to_csv(final_output_path, index=False)\n",
        "            print(f\"Saved combined results to {final_output_path}\")\n",
        "            files.download(final_output_path)  # Download the final combined results\n",
        "        else:\n",
        "            print(f\"Skipping final combination for {key} due to previous failures.\")\n",
        "\n",
        "    return clean_text_sentiments_dict\n"
      ],
      "metadata": {
        "id": "4deXg-dRpgbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPXqop4xpgVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def is_file_non_empty(filepath):\n",
        "    \"\"\"Check if the file is non-empty.\"\"\"\n",
        "    return os.path.exists(filepath) and os.stat(filepath).st_size > 0\n",
        "\n",
        "def get_sentiment_all(dictionary_of_lists, directory_out):\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    for key, segment_list in dictionary_of_lists.items():\n",
        "        print(f\"Processing: {key} with len(segment_list) = {len(segment_list)}\")\n",
        "\n",
        "        success = True\n",
        "        vader_df = textblob_df = bertmulti_df = ollama_df = None\n",
        "\n",
        "        # Extract the base name of the book\n",
        "        book_name = key.replace('_verified.txt', '')\n",
        "\n",
        "        # Define intermediate file paths\n",
        "        vader_path = os.path.join(directory_out, f'{book_name}_vader_partial.csv')\n",
        "        textblob_path = os.path.join(directory_out, f'{book_name}_textblob_partial.csv')\n",
        "        bertmulti_path = os.path.join(directory_out, f'{book_name}_bertmulti_partial.csv')\n",
        "        ollama_path = os.path.join(directory_out, f'{book_name}_ollama_partial.csv')\n",
        "\n",
        "        # Check if VADER results exist and are non-empty\n",
        "        if is_file_non_empty(vader_path):\n",
        "            print(f\"VADER results already processed for {key}\")\n",
        "        else:\n",
        "            if not get_sentiment_vader_safe(segment_list, 'en', directory_out, vader_path):\n",
        "                print(f\"Failed to process VADER for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                print(f\"Saved VADER results to {vader_path}\")\n",
        "                files.download(vader_path)  # Download the VADER results\n",
        "\n",
        "        # Check if TextBlob results exist and are non-empty\n",
        "        if is_file_non_empty(textblob_path):\n",
        "            print(f\"TextBlob results already processed for {key}\")\n",
        "        else:\n",
        "            if not get_sentiment_textblob_safe(segment_list, 'en', directory_out, textblob_path):\n",
        "                print(f\"Failed to process TextBlob for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                print(f\"Saved TextBlob results to {textblob_path}\")\n",
        "                files.download(textblob_path)  # Download the TextBlob results\n",
        "\n",
        "        # Check if BERTMulti results exist and are non-empty\n",
        "        if is_file_non_empty(bertmulti_path):\n",
        "            print(f\"BERTMulti results already processed for {key}\")\n",
        "        else:\n",
        "            if not get_sentiment_bertmulti_safe(segment_list, 'en', directory_out, bertmulti_path):\n",
        "                print(f\"Failed to process BERTMulti for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                print(f\"Saved BERTMulti results to {bertmulti_path}\")\n",
        "                files.download(bertmulti_path)  # Download the BERTMulti results\n",
        "\n",
        "        # Check if Ollama results exist and are non-empty\n",
        "        if is_file_non_empty(ollama_path):\n",
        "            print(f\"Ollama results already processed for {key}\")\n",
        "        else:\n",
        "            if not get_sentiment_ollama_safe(segment_list, 'en', directory_out, ollama_path):\n",
        "                print(f\"Failed to process Ollama for {key}\")\n",
        "                success = False\n",
        "            else:\n",
        "                print(f\"Saved Ollama results to {ollama_path}\")\n",
        "                files.download(ollama_path)  # Download the Ollama results\n",
        "\n",
        "        if success:\n",
        "            # Combine results if all models are successfully processed\n",
        "            if all([is_file_non_empty(vader_path), is_file_non_empty(textblob_path), is_file_non_empty(bertmulti_path), is_file_non_empty(ollama_path)]):\n",
        "                vader_df = pd.read_csv(vader_path)\n",
        "                textblob_df = pd.read_csv(textblob_path)\n",
        "                bertmulti_df = pd.read_csv(bertmulti_path)\n",
        "                ollama_df = pd.read_csv(ollama_path)\n",
        "\n",
        "                # Combine results\n",
        "                final_df = vader_df\n",
        "                final_df['textblob'] = textblob_df['textblob']\n",
        "                final_df['bertmulti'] = bertmulti_df['bertmulti']\n",
        "                final_df['mistral'] = ollama_df['mistral']\n",
        "\n",
        "                clean_text_sentiments_dict[key] = final_df\n",
        "\n",
        "                # Save the final combined dataframe\n",
        "                final_output_path = os.path.join(directory_out, f'{book_name}_segments.csv')\n",
        "                final_df.to_csv(final_output_path, index=False)\n",
        "                print(f\"Saved combined results to {final_output_path}\")\n",
        "                files.download(final_output_path)  # Download the final combined results\n",
        "            else:\n",
        "                print(f\"Skipping final combination for {key} due to incomplete sentiment analysis results.\")\n",
        "        else:\n",
        "            print(f\"Skipping final combination for {key} due to previous failures.\")\n",
        "\n",
        "    return clean_text_sentiments_dict\n"
      ],
      "metadata": {
        "id": "5u5FfbfDkD1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_ollama(prompt_str):\n",
        "    import ollama\n",
        "\n",
        "    response = ollama.chat(prompt_str)\n",
        "    return response.text\n",
        "\n",
        "res_str = test_ollama(\"Hello, how are you?\")\n",
        "print(res_str)"
      ],
      "metadata": {
        "id": "ST_BCLBks4tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr sentiments"
      ],
      "metadata": {
        "id": "THSwDraRodqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ./sentiments/*_partial.csv"
      ],
      "metadata": {
        "id": "UCeJHDBhp14l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyvYIuCLkZuF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 2h05m?\n",
        "\n",
        "sentiments_all_dict = get_sentiment_all(clean_text_reformat_seg_filter_dict, 'sentiments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3R6AoO8kZuF"
      },
      "outputs": [],
      "source": [
        "# sentiments_test_dict = get_sentiment_all(clean_test_reformat_seg_filter_test_dict, 'test_sentiments')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "dmUwIO54logQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "id": "aejHbZuZlqrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rmdir sentiments"
      ],
      "metadata": {
        "id": "hUh-bBAdme1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "3MQbd79Cmgfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat textblob_partial.csv | wc -l"
      ],
      "metadata": {
        "id": "coBvfgKal_nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *"
      ],
      "metadata": {
        "id": "wq0nqsKml_ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2nIYE-ikZuF"
      },
      "source": [
        "### Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z06uZaOYkZuF"
      },
      "outputs": [],
      "source": [
        "def write_dict_of_df_to_files(directory_out, dict_of_df, segment_type='segments'):\n",
        "    \"\"\"\n",
        "    Saves each DataFrame from the dictionary to separate files in the specified directory.\n",
        "\n",
        "    Parameters:\n",
        "    directory_out (str): The directory where the files will be saved.\n",
        "    dict_of_df (dict): Dictionary where keys are filenames and values are pandas DataFrames.\n",
        "    segment_type (str): The suffix to be added to the output filenames.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with filenames as keys and their paths as values.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(directory_out):\n",
        "        os.makedirs(directory_out)\n",
        "\n",
        "    file_paths = {}\n",
        "\n",
        "    for key in dict_of_df.keys():\n",
        "        # Create the output filename\n",
        "        filename_out = key.replace('_verified.txt', f'_{segment_type}.csv')\n",
        "        output_file_path = os.path.join(directory_out, filename_out)\n",
        "\n",
        "        # Debug: Print the current filename and output path\n",
        "        print(f\"Saving file: {output_file_path}\")\n",
        "\n",
        "        # Enhanced Debug: Print the shape of the DataFrame\n",
        "        print(f\"DataFrame shape for {key}: {dict_of_df[key].shape}\")\n",
        "\n",
        "        # Write the DataFrame to a CSV file\n",
        "        dict_of_df[key].to_csv(output_file_path, index=False)\n",
        "\n",
        "        # Store the filename and its path in the dictionary\n",
        "        file_paths[filename_out] = output_file_path\n",
        "\n",
        "    return file_paths\n",
        "\n",
        "\"\"\"\n",
        "# Example usage\n",
        "# Ensure the dictionary contains valid data\n",
        "example_data_1 = pd.DataFrame({\n",
        "    'Column1': ['A', 'B', 'C', 'D'],\n",
        "    'Column2': [1, 2, 3, 4]\n",
        "})\n",
        "example_data_2 = pd.DataFrame({\n",
        "    'Column1': ['W', 'X', 'Y', 'Z'],\n",
        "    'Column2': [10, 20, 30, 40]\n",
        "})\n",
        "clean_test_reformat_seg_filter_dict_df = {\n",
        "    'book_proust_fr_swans-way_proust_original_verified.txt': example_data_1,\n",
        "    'book_proust_en_swans-way_enright_original_verified.txt': example_data_2\n",
        "}\n",
        "\n",
        "file_paths_df = write_dict_of_df_to_files('test_df', clean_test_reformat_seg_filter_dict_df, 'test')\n",
        "print(file_paths_df)\n",
        "\n",
        "# Verify the content of the files by reading them back\n",
        "for filename, filepath in file_paths_df.items():\n",
        "    print(f\"Verifying content of {filename}:\")\n",
        "    df = pd.read_csv(filepath)\n",
        "    print(df.head())\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Qxj-X4kZuF"
      },
      "outputs": [],
      "source": [
        "sentiments_test_dict['book_proust_fr_swans-way_proust_original_verified.txt']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls test_sentiments/*_sentiments.csv"
      ],
      "metadata": {
        "id": "FQ92LgqFgxHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save test files\n",
        "\n",
        "for book_sentiments_all_file in os.listdir(os.path.join('.', 'test_sentiments')):\n",
        "  if book_sentiments_all_file.endswith('_sentiments.csv'):\n",
        "      print(book_sentiments_all_file)\n",
        "      files.download(os.path.join('.', 'test_sentiments', book_sentiments_all_file))\n",
        "    # print(f\"{book}: {df.shape}\")\n",
        "    # fileout_paths_dict = write_dict_of_df_to_files('test_sentiments', sentiments_test_dict, 'sentiments')"
      ],
      "metadata": {
        "id": "4xVOk5HigxEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMBu-jSDgwXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFPN7kZHkZuF"
      },
      "outputs": [],
      "source": [
        "fileout_paths_dict = write_dict_of_df_to_files('test_sentiments', sentiments_test_dict, 'sentiments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Didfc2kZuF"
      },
      "outputs": [],
      "source": [
        "fileout_paths_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfuv03InkZuF"
      },
      "outputs": [],
      "source": [
        "sentiments_all_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKCmAxldkZuF"
      },
      "outputs": [],
      "source": [
        "sentiments_all_dict['book_proust_fr_swans-way_proust_original_verified.txt'][:10]\n",
        "\n",
        "len(sentiments_all_dict['book_proust_fr_swans-way_proust_original_verified.txt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeaSW294kZuF"
      },
      "outputs": [],
      "source": [
        "fileout_paths_dict = save_dict_to_files('sentiments', sentiments_all_dict, 'sentiments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzGcFPiZkZuG"
      },
      "outputs": [],
      "source": [
        "fileout_paths_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGSp7y9mkZuG"
      },
      "outputs": [],
      "source": [
        "save_dict_to_files('./segments', sentiments_all_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMlHdcI8kZuG"
      },
      "outputs": [],
      "source": [
        "files.download('./segments/book_proust_fr_swans-way_proust_original_segments.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N4Uzh1GkZuG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADXIH34zkZuG"
      },
      "source": [
        "### Get Sentiments All At Once"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%whos\n"
      ],
      "metadata": {
        "id": "rkdbq3knjDqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PewX8TmdjDHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# 2h04m\n",
        "\n",
        "clean_text_sentiments_df = create_sentiment_dataframes(clean_text_reformat_seg_filter_dict)\n",
        "print(clean_text_sentiments_df.keys())"
      ],
      "metadata": {
        "id": "zlA_jfubzetn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def save_flat_dict_csv(dict_of_dataframes):\n",
        "    filenames = []\n",
        "    for book_title, dataframe in dict_of_dataframes.items():\n",
        "        # Create a safe filename\n",
        "        safe_filename = re.sub(r'[^a-zA-Z0-9_\\-]', '_', book_title) + '.csv'\n",
        "        filenames.append(safe_filename)\n",
        "\n",
        "        try:\n",
        "            # Write the dataframe to a CSV file\n",
        "            dataframe.to_csv(safe_filename, index=False)\n",
        "            print(f\"Successfully saved {safe_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving {safe_filename}: {e}\")\n",
        "\n",
        "    return filenames\n",
        "\n"
      ],
      "metadata": {
        "id": "kMtl8MQz0y0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = save_flat_dict_csv(clean_text_sentiments_df)\n",
        "\n",
        "# For Google Colab\n",
        "for filename in filenames:\n",
        "    files.download(filename)"
      ],
      "metadata": {
        "id": "YkuU7EFx0yxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yd6liu9s0yt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "mpbON92_zequ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-ZsRLKEzen7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nD96kiaszeky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTb9O0ZBkZuG"
      },
      "outputs": [],
      "source": [
        "def load_existing_sentiment_dataframe(filepath):\n",
        "    if os.path.exists(filepath):\n",
        "        return pd.read_csv(filepath)\n",
        "    return None\n",
        "\n",
        "def save_partial_sentiment_dataframe(filepath, df):\n",
        "    df.to_csv(filepath, index=False)\n",
        "\n",
        "def create_sentiment_dataframes(clean_text_reformat_seg_filter_dict_in, output_dir=\"sentiments\"):\n",
        "    clean_text_sentiments_dict = {}\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\" Directory: {output_dir} DNE, will create it\")\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for key, segment_list in clean_text_reformat_seg_filter_dict_in.items():\n",
        "        print(f\"Processing sentiments for: {key}\")\n",
        "        print(f\"PRocessing sentiment_list has {len(segment_list)} strings\")\n",
        "\n",
        "        # Create the output filenames\n",
        "        filename_out = key.replace('_verified.txt', '_segments.csv')\n",
        "        partial_vader_file = key.replace('_verified.txt', '_segments_vader_partial.csv')\n",
        "        partial_textblob_file = key.replace('_verified.txt', '_segments_textblob_partial.csv')\n",
        "        partial_bertmulti_file = key.replace('_verified.txt', '_segments_bertmulti_partial.csv')\n",
        "        partial_ollama_file = key.replace('_verified.txt', '_segments_ollama_partial.csv')\n",
        "\n",
        "        # Define the paths\n",
        "        full_output_path = os.path.join(\".\", output_dir, filename_out)\n",
        "        partial_vader_path = os.path.join(\".\", output_dir, partial_vader_file)\n",
        "        partial_textblob_path = os.path.join(\".\", output_dir, partial_textblob_file)\n",
        "        partial_bertmulti_path = os.path.join(\".\", output_dir, partial_bertmulti_file)\n",
        "        partial_ollama_path = os.path.join(\".\", output_dir, partial_ollama_file)\n",
        "\n",
        "        # Load existing dataframe if available\n",
        "        # df = load_existing_sentiment_dataframe(full_output_path)\n",
        "        # print(f\"df.info(): {df.info()}\")\n",
        "\n",
        "        # if df is None:\n",
        "        #     df = pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame()\n",
        "        print(f'{list(df.columns.values)}')\n",
        "\n",
        "        # Process VADER sentiments if not already done\n",
        "        if 'vader' not in df.columns:\n",
        "            print(\"PROCESSING Sentiment VADER\")\n",
        "            vader_sentiments = get_sentiment_vader(segment_list)\n",
        "            df['vader'] = vader_sentiments\n",
        "            print(f\"  Saving to partial_vader_path: {partial_vader_path}\")\n",
        "            save_partial_sentiment_dataframe(partial_vader_path, df)\n",
        "\n",
        "        # Process TextBlob sentiments if not already done\n",
        "        if 'textblob' not in df.columns:\n",
        "            print(\"PROCESSING Sentiment TextBlob\")\n",
        "            textblob_sentiments = get_sentiment_textblob(segment_list, language=\"en\")\n",
        "            df['textblob'] = textblob_sentiments\n",
        "            print(f\"  Saving to partial_textblob_path: {partial_textblob_path}\")\n",
        "            save_partial_sentiment_dataframe(partial_textblob_path, df)\n",
        "\n",
        "        # Process BERT multi-language sentiments if not already done\n",
        "        if 'bertmulti' not in df.columns:\n",
        "            print(\"PROCESSING Sentiment BERTMulti\")\n",
        "            bertmulti_sentiments = get_sentiment_bertmulti(segment_list, language=\"en\")\n",
        "            print(f\" bertmulti_sentiments has {len(bertmulti_sentiments)} strings\")\n",
        "            df['bertmulti'] = bertmulti_sentiments\n",
        "            print(f\"df['bertmulti']: {df['bertmulti']}\")\n",
        "            print(f\"  Saving to partial_xxx_path: {partial_bertmulti_path}\")\n",
        "            save_partial_sentiment_dataframe(partial_bertmulti_path, df)\n",
        "\n",
        "        # Process Ollama sentiments if not already done\n",
        "        if 'mistral' not in df.columns:\n",
        "            print(\"PROCESSING Sentiment Mistral\")\n",
        "            ollama_sentiments = get_sentiment_ollama(segment_list, language=\"en\", ollama_model=MODEL_OLLAMA)\n",
        "            df['mistral'] = ollama_sentiments\n",
        "            print(f\"  Saving to partial_xxx_path: {partial_ollama_path}\")\n",
        "            save_partial_sentiment_dataframe(partial_ollama_path, df)\n",
        "\n",
        "        # Save the complete dataframe\n",
        "        df.to_csv(full_output_path, index=False)\n",
        "        clean_text_sentiments_dict[key] = df\n",
        "\n",
        "    return clean_text_sentiments_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPZ1q3nBkZuG"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3svlBz3kZuG"
      },
      "outputs": [],
      "source": [
        "for book_now, lines_list in clean_text_reformat_seg_filter_dict.items():\n",
        "\n",
        "    print(f\"{book_now} : len={len(clean_text_reformat_seg_filter_dict[book_now])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziu_-BrJkZuG"
      },
      "outputs": [],
      "source": [
        "len(segments_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvWm2S4ekZuG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# test\n",
        "\n",
        "clean_test_sentiments_dict = create_sentiment_dataframes(clean_test_reformat_seg_filter_test_dict)\n",
        "print(clean_test_sentiments_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFnYNaKlkZuG"
      },
      "outputs": [],
      "source": [
        "clean_test_sentiments_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW2fil3akZuG"
      },
      "outputs": [],
      "source": [
        "clean_test_sentiments_dict['book_proust_fr_swans-way_proust_original_verified.txt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOFnd2NukZuG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUzq1GkAkZuG"
      },
      "outputs": [],
      "source": [
        "clean_test_reformat_seg_filter_test_dict\n",
        "\n",
        "clean_test_sentiments_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C8qIOvnkZuG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# 2h04m\n",
        "\n",
        "clean_text_sentiments_df = create_sentiment_dataframes(clean_text_reformat_seg_filter_dict)\n",
        "print(clean_text_sentiments_df.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYFf6Hd_kZuG"
      },
      "outputs": [],
      "source": [
        " clean_text_sentiments_dict['book_proust_en_swans-way_moncrieff_original_segments.txt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKUqNIeKkZuG"
      },
      "outputs": [],
      "source": [
        "clean_text_sentiments_dict['book_proust_en_swans-way_enright_original_segments.txt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVzt3VSxkZuG"
      },
      "outputs": [],
      "source": [
        "clean_text_sentiments_dict['book_proust_fr_swans-way_proust_original_segments.txt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D57jVDVDkZuH"
      },
      "outputs": [],
      "source": [
        "clean_text_sentiments_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOhlju0jkZuH"
      },
      "outputs": [],
      "source": [
        "clean_text_sentiments_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQJE3UWakZuH"
      },
      "outputs": [],
      "source": [
        "clean_text_reformat_seg_filter_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi_Zh9qXkZuH"
      },
      "outputs": [],
      "source": [
        "len(clean_text_reformat_seg_filter_dict['book_proust_en_swans-way_moncrieff_original_segments.txt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVwrepl1kZuH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "clean_text_sentiments_df = create_sentiment_dataframes(clean_text_reformat_seg_filter_dict, segments_list)\n",
        "print(clean_text_sentiments_df.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o8k83Orw9qW"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "sentence_test_both_list = sentence_test_en_list + sentence_test_fr_list\n",
        "clean_text_test_dict = {\n",
        "    'book_proust_en_swans-way_test_original_verified.txt': sentence_test_both_list\n",
        "    # Add other keys and segment lists as needed\n",
        "}\n",
        "\n",
        "clean_test_sentiments_dict = create_sentiment_dataframes(clean_text_test_dict)\n",
        "print(type(clean_test_sentiments_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96uiuKyeuYkd"
      },
      "outputs": [],
      "source": [
        "clean_test_sentiments_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S8EKzOduYhf"
      },
      "outputs": [],
      "source": [
        "\n",
        "len(clean_text_reformat_seg_filter_dict[\"book_proust_en_swans-way_moncrieff_original_verified.txt\"])\n",
        "\n",
        "clean_test_sentiments_dict['book_proust_en_swans-way_test_original_verified.txt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j_xNOvvitB2i",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# GET clean_text_sentiments_dict\n",
        "\n",
        "clean_text_sentiments_dict = create_sentiment_dataframes(clean_text_reformat_seg_filter_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0FsFCeGxyJp"
      },
      "outputs": [],
      "source": [
        "save_dict_to_files(clean_text_sentiments_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztod161xxyGD"
      },
      "outputs": [],
      "source": [
        "save_dict_to_files('./sentiments', clean_text_sentiments_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM2dAdsxxyfe"
      },
      "source": [
        "# [END]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkYsds6MCIJK"
      },
      "source": [
        "# II. Compute Sentiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksAI_QqeIkag"
      },
      "outputs": [],
      "source": [
        "# 20240525\n",
        "\n",
        "# Upload combo files:\n",
        "# Saving book_proust_en_swans-way_davis_sentence_sentiment_combined.csv to book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\n",
        "\n",
        "uploaded_sentiment = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxzrPitNNaBD"
      },
      "outputs": [],
      "source": [
        "# Get the filename from the uploaded files\n",
        "upload_filename = list(uploaded_sentiment.keys())[0]\n",
        "print(f\"upload_filename: {upload_filename}\")\n",
        "\n",
        "# Extract the book title from the filename\n",
        "book_title = \"_\".join(upload_filename.split(\".\")[0].split(\"_\")[1:5])\n",
        "print(f\"book_title: {book_title}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paArSrACIkag"
      },
      "outputs": [],
      "source": [
        "sentiment_combined_files_list = [\n",
        "    \"book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_enright_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_moncrieff_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_fr_swans-way_proust_sentence_sentiment_combined.csv\"\n",
        "]\n",
        "\n",
        "sentiment_combined_file = sentiment_combined_files_list[0]\n",
        "\n",
        "sentiment_df = pd.read_csv(upload_filename)\n",
        "\n",
        "sentiment_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_df.describe()\n"
      ],
      "metadata": {
        "id": "1Ahkq73NKrDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-TCX3gMIkah"
      },
      "outputs": [],
      "source": [
        "model_ls = sentiment_df.columns.tolist()\n",
        "model_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "virO-09kIkah"
      },
      "outputs": [],
      "source": [
        "\n",
        "# \"Swan's Way by Proust en_davis\"\n",
        "filename_subwords_list = sentiment_combined_file.split('_')\n",
        "novel_title = '_'.join([filename_subwords_list[1],filename_subwords_list[3],filename_subwords_list[2],filename_subwords_list[4]])\n",
        "print(novel_title)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fh8vQM1ZNzHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_combine_csv_to_df(list_file_str):\n",
        "    # Initialize an empty list to hold data\n",
        "    combined_data = []\n",
        "\n",
        "    # Iterate over each file in the list\n",
        "    for file in list_file_str:\n",
        "\n",
        "        # Read the CSV file into a dataframe\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        # Add a column for the text title\n",
        "        text_title = os.path.basename(file).split('_')[3]\n",
        "        df['title'] = text_title\n",
        "\n",
        "        # Add a column for the text translator\n",
        "        text_translator = os.path.basename(file).split('_')[4].split('.')[0]\n",
        "        df['translator'] = text_translator\n",
        "\n",
        "        # Add a column for the text language\n",
        "        text_language = os.path.basename(file).split('_')[2]\n",
        "        df['language'] = text_language\n",
        "\n",
        "        # Add a column for the segment number (assuming the CSV files are already in order)\n",
        "        df['segment_no'] = df.index\n",
        "\n",
        "        # Append the dataframe to the combined_data list\n",
        "        combined_data.append(df)\n",
        "\n",
        "    # Concatenate all dataframes in the list into a single dataframe\n",
        "    combined_df = pd.concat(combined_data, ignore_index=True)\n",
        "\n",
        "    # Reorder the columns to have title, translator, language, segment_no first\n",
        "    cols = ['title', 'translator', 'language', 'segment_no'] + [col for col in combined_df.columns if col not in ['title', 'translator', 'language', 'segment_no']]\n",
        "    combined_df = combined_df[cols]\n",
        "\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "UZMVZoJONy6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "hiHQiyk5N6mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "list_file_str = [\n",
        "    \"book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_enright_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_moncrieff_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_fr_swans-way_proust_sentence_sentiment_combined.csv\"\n",
        "]\n",
        "\n",
        "# Call the function to combine the CSV files\n",
        "combined_df = read_combine_csv_to_df(list_file_str)\n",
        "\n",
        "# Display the combined dataframe\n",
        "print(combined_df.head())"
      ],
      "metadata": {
        "id": "-nC6myU5Nyz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.to_csv('book_proust_all4translations_all4models_sentiments.csv')"
      ],
      "metadata": {
        "id": "JIES9hZwOsBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "b2SMtjPpNyw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('book_proust_all4translations_all4models_sentiments.csv')"
      ],
      "metadata": {
        "id": "7jKrG6RxL6YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df[combined_df['translator'] == translator_now]].describe()"
      ],
      "metadata": {
        "id": "0kSHWmHePldN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_summary_stats_by_author(df):\n",
        "    # Get the list of unique translators\n",
        "    translators = df['translator'].unique()\n",
        "\n",
        "    # Loop over each unique translator\n",
        "    for translator in translators:\n",
        "        # Create a temporary dataframe for the current translator\n",
        "        temp_by_translator_df = df[df['translator'] == translator]\n",
        "\n",
        "        # Generate descriptive statistics for the temporary dataframe\n",
        "        summary_stats = temp_by_translator_df.describe()\n",
        "\n",
        "        # Print the descriptive statistics to the screen\n",
        "        print(f\"\\n\\n\\nSummary statistics for translator: {translator}\")\n",
        "        print(summary_stats)\n",
        "\n",
        "        # Write the descriptive statistics to an external CSV file\n",
        "        summary_stats.to_csv(f\"proust_swans-way_{translator}_sumstats_sentiment.csv\")\n"
      ],
      "metadata": {
        "id": "Lfc5bD6iQXjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming combined_df has been generated using the previous function\n",
        "combined_df = read_combine_csv_to_df(list_file_str)\n",
        "\n",
        "# Call the function to generate and save the summary statistics\n",
        "sentiment_summary_stats_by_author(combined_df)"
      ],
      "metadata": {
        "id": "gqyNnXLfQXcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def plot_kde_by_translator(df):\n",
        "    # Filter the dataframe to include only the sentiment columns and the translator column\n",
        "    sentiment_columns = ['sentiment-bertmulti', 'sentiment-mistral7b', 'sentiment-textblob', 'sentiment-vader']\n",
        "    filtered_df = df[['translator'] + sentiment_columns]\n",
        "\n",
        "    # Get the list of unique translators\n",
        "    translators = filtered_df['translator'].unique()\n",
        "\n",
        "    # Set a seaborn style for the plots\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Loop over each unique translator to create individual KDE plots\n",
        "    for translator in translators:\n",
        "        plt.figure(figsize=(14, 7), dpi=300)\n",
        "        temp_by_translator_df = filtered_df[filtered_df['translator'] == translator]\n",
        "        for sentiment in sentiment_columns:\n",
        "            sns.kdeplot(temp_by_translator_df[sentiment], label=sentiment)\n",
        "        plt.title(f\"KDE Plot of Sentiment Scores for {translator.capitalize()}\", fontsize=18)\n",
        "        plt.xlabel(\"Sentiment Score\", fontsize=14)\n",
        "        plt.ylabel(\"Density\", fontsize=14)\n",
        "        plt.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"kde_sentiment_scores_{translator}.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    # Combined KDE plot for all translators (raw sentiments)\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "    for sentiment in sentiment_columns:\n",
        "        sns.kdeplot(filtered_df[sentiment], label=sentiment)\n",
        "    plt.title(\"Combined KDE Plot of Sentiment Scores for All Translators\", fontsize=18)\n",
        "    plt.xlabel(\"Sentiment Score\", fontsize=14)\n",
        "    plt.ylabel(\"Density\", fontsize=14)\n",
        "    plt.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"kde_sentiment_scores_all_translators.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Normalize the sentiment columns using Z-score normalization\n",
        "    normalized_df = filtered_df.copy()\n",
        "    normalized_df[sentiment_columns] = normalized_df[sentiment_columns].apply(zscore)\n",
        "\n",
        "    # Combined KDE plot for all translators (normalized sentiments)\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "    for sentiment in sentiment_columns:\n",
        "        sns.kdeplot(normalized_df[sentiment], label=sentiment)\n",
        "    plt.title(\"Combined KDE Plot of Normalized Sentiment Scores for All Translators\", fontsize=18)\n",
        "    plt.xlabel(\"Normalized Sentiment Score\", fontsize=14)\n",
        "    plt.ylabel(\"Density\", fontsize=14)\n",
        "    plt.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"kde_normalized_sentiment_scores_all_translators.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "list_file_str = [\n",
        "    \"book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_enright_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_moncrieff_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_fr_swans-way_proust_sentence_sentiment_combined.csv\"\n",
        "]\n",
        "\n",
        "# Assuming combined_df has been generated using the previous function\n",
        "combined_df = read_combine_csv_to_df(list_file_str)\n",
        "\n",
        "# Call the function to plot KDEs\n",
        "plot_kde_by_translator(combined_df)\n"
      ],
      "metadata": {
        "id": "KsoIH3G9QXYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_sumstats_by_translator(df):\n",
        "    # Filter the dataframe to include only the sentiment columns and the translator column\n",
        "    sentiment_columns = ['sentiment-bertmulti', 'sentiment-mistral7b', 'sentiment-textblob', 'sentiment-vader']\n",
        "    filtered_df = df[['translator'] + sentiment_columns]\n",
        "\n",
        "    # Get the list of unique translators\n",
        "    translators = filtered_df['translator'].unique()\n",
        "\n",
        "    # Initialize dictionaries to hold summary statistics\n",
        "    mean_stats = {}\n",
        "    std_stats = {}\n",
        "\n",
        "    # Loop over each unique translator to compute summary statistics\n",
        "    for translator in translators:\n",
        "        # Create a temporary dataframe for the current translator\n",
        "        temp_by_translator_df = filtered_df[filtered_df['translator'] == translator]\n",
        "\n",
        "        # Generate descriptive statistics for the temporary dataframe\n",
        "        summary_stats = temp_by_translator_df.describe()\n",
        "\n",
        "        # Store the mean and std statistics\n",
        "        mean_stats[translator] = summary_stats.loc['mean']\n",
        "        std_stats[translator] = summary_stats.loc['std']\n",
        "\n",
        "    # Convert the dictionaries to dataframes for easier plotting\n",
        "    mean_df = pd.DataFrame(mean_stats).transpose()[sentiment_columns]\n",
        "    std_df = pd.DataFrame(std_stats).transpose()[sentiment_columns]\n",
        "\n",
        "    # Set a seaborn style for the plots\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Plot mean statistics\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "    ax = mean_df.plot(kind='bar', figsize=(14, 7), colormap='viridis', edgecolor='black', linewidth=1.2)\n",
        "    ax.set_title(\"Mean Sentiment Scores by Translator\", fontsize=18)\n",
        "    ax.set_xlabel(\"Translator\", fontsize=14)\n",
        "    ax.set_ylabel(\"Mean Score\", fontsize=14)\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    # Move the legend outside the plot\n",
        "    ax.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot as a high-resolution image\n",
        "    plt.savefig(\"mean_sentiment_scores_by_translator.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot std deviation statistics\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "    ax = std_df.plot(kind='bar', figsize=(14, 7), colormap='viridis', edgecolor='black', linewidth=1.2)\n",
        "    ax.set_title(\"Standard Deviation of Sentiment Scores by Translator\", fontsize=18)\n",
        "    ax.set_xlabel(\"Translator\", fontsize=14)\n",
        "    ax.set_ylabel(\"Standard Deviation\", fontsize=14)\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    # Move the legend outside the plot\n",
        "    ax.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot as a high-resolution image\n",
        "    plt.savefig(\"std_sentiment_scores_by_translator.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "list_file_str = [\n",
        "    \"book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_enright_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_moncrieff_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_fr_swans-way_proust_sentence_sentiment_combined.csv\"\n",
        "]\n",
        "\n",
        "# Assuming combined_df has been generated using the previous function\n",
        "combined_df = read_combine_csv_to_df(list_file_str)\n",
        "\n",
        "# Call the function to plot the summary statistics\n",
        "plot_sumstats_by_translator(combined_df)\n"
      ],
      "metadata": {
        "id": "m_xzOa4IQXVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def plot_sumstats_by_translator(df, zscore_flag=False):\n",
        "    # Filter the dataframe to include only the sentiment columns and the translator column\n",
        "    sentiment_columns = ['sentiment-bertmulti', 'sentiment-mistral7b', 'sentiment-textblob', 'sentiment-vader']\n",
        "    filtered_df = df[['translator'] + sentiment_columns]\n",
        "\n",
        "    # Apply Z-score normalization if zscore_flag is True\n",
        "    if zscore_flag:\n",
        "        filtered_df[sentiment_columns] = filtered_df[sentiment_columns].apply(zscore)\n",
        "\n",
        "    # Get the list of unique translators\n",
        "    translators = filtered_df['translator'].unique()\n",
        "\n",
        "    # Initialize dictionaries to hold summary statistics\n",
        "    mean_stats = {}\n",
        "    std_stats = {}\n",
        "\n",
        "    # Loop over each unique translator to compute summary statistics\n",
        "    for translator in translators:\n",
        "        # Create a temporary dataframe for the current translator\n",
        "        temp_by_translator_df = filtered_df[filtered_df['translator'] == translator]\n",
        "\n",
        "        # Generate descriptive statistics for the temporary dataframe\n",
        "        summary_stats = temp_by_translator_df.describe()\n",
        "\n",
        "        # Store the mean and std statistics\n",
        "        mean_stats[translator] = summary_stats.loc['mean']\n",
        "        std_stats[translator] = summary_stats.loc['std']\n",
        "\n",
        "    # Convert the dictionaries to dataframes for easier plotting\n",
        "    mean_df = pd.DataFrame(mean_stats).transpose()[sentiment_columns]\n",
        "    std_df = pd.DataFrame(std_stats).transpose()[sentiment_columns]\n",
        "\n",
        "    # Set a seaborn style for the plots\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Plot mean statistics\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "    ax = mean_df.plot(kind='bar', figsize=(14, 7), colormap='viridis', edgecolor='black', linewidth=1.2)\n",
        "    ax.set_title(\"Mean Sentiment Scores by Translator\" + (\" (Z-score Normalized)\" if zscore_flag else \"\"), fontsize=18)\n",
        "    ax.set_xlabel(\"Translator\", fontsize=14)\n",
        "    ax.set_ylabel(\"Mean Score\", fontsize=14)\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    # Move the legend outside the plot\n",
        "    ax.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot as a high-resolution image\n",
        "    plt.savefig(\"mean_sentiment_scores_by_translator\" + (\"_zscore\" if zscore_flag else \"\") + \".png\", format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot std deviation statistics\n",
        "    plt.figure(figsize=(14, 7), dpi=300)\n",
        "    ax = std_df.plot(kind='bar', figsize=(14, 7), colormap='viridis', edgecolor='black', linewidth=1.2)\n",
        "    ax.set_title(\"Standard Deviation of Sentiment Scores by Translator\" + (\" (Z-score Normalized)\" if zscore_flag else \"\"), fontsize=18)\n",
        "    ax.set_xlabel(\"Translator\", fontsize=14)\n",
        "    ax.set_ylabel(\"Standard Deviation\", fontsize=14)\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    # Move the legend outside the plot\n",
        "    ax.legend(title=\"Sentiment Model\", fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot as a high-resolution image\n",
        "    plt.savefig(\"std_sentiment_scores_by_translator\" + (\"_zscore\" if zscore_flag else \"\") + \".png\", format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "list_file_str = [\n",
        "    \"book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_enright_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_moncrieff_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_fr_swans-way_proust_sentence_sentiment_combined.csv\"\n",
        "]\n",
        "\n",
        "# Assuming combined_df has been generated using the previous function\n",
        "combined_df = read_combine_csv_to_df(list_file_str)\n",
        "\n",
        "# Call the function to plot the summary statistics without Z-score normalization\n",
        "plot_sumstats_by_translator(combined_df, zscore_flag=False)\n",
        "\n",
        "# Call the function to plot the summary statistics with Z-score normalization\n",
        "plot_sumstats_by_translator(combined_df, zscore_flag=True)\n"
      ],
      "metadata": {
        "id": "t9klPx8nQXOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqENn2Q_MAXW"
      },
      "source": [
        "**[SKIP] to Section III: Get Sentiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2thPN2r_QJSz"
      },
      "source": [
        "# III. Load Sentiments (sentiments_all_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8BBt5kdUMcf"
      },
      "outputs": [],
      "source": [
        "# 20240525\n",
        "\n",
        "# Upload Combined Files: (both text and all raw model sentiment values)\n",
        "# \"book_proust_en_swans-way_moncrieff_original_segments.csv\"\n",
        "\n",
        "# Saving book_proust_en_swans-way_davis_original_segments.csv to book_proust_en_swans-way_davis_original_segments.csv\n",
        "# Saving book_proust_en_swans-way_enright_original_segments.csv to book_proust_en_swans-way_enright_original_segments.csv\n",
        "# Saving book_proust_fr_swans-way_proust_original_segments.csv to book_proust_fr_swans-way_proust_original_segments.csv\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Cloud RunPod.io"
      ],
      "metadata": {
        "id": "jEam4M9kl9Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls *_segments.csv"
      ],
      "metadata": {
        "id": "OhyhHko9l83B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBAL VAR: filename sentiment_all_list\n",
        "# list of all input filenames for computed sentiment values\n",
        "\n",
        "filename_sentiment_all_list = [file for file in glob.glob(\"*_segments.csv\")]\n",
        "print(filename_sentiment_all_list)"
      ],
      "metadata": {
        "id": "3DG28n9Qmz3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBAL VAR: sentiments_all_dict[filename_now]\n",
        "# 1-level dictionary[filename] = text/sentiment values]\n",
        "\n",
        "sentiments_all_dict = {}\n",
        "\n",
        "for filename_now in filename_sentiment_all_list:\n",
        "  print(f\"PROCESSING: {filename_now}\")\n",
        "  df = pd.read_csv(filename_now)\n",
        "  sentiments_all_dict[filename_now] = df\n",
        "  print(df.info())"
      ],
      "metadata": {
        "id": "6OM3w_9fmzvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK for dictionary keys/filenames\n",
        "\n",
        "sentiments_all_dict.keys()"
      ],
      "metadata": {
        "id": "yr2I0UiQoD1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK for complete and well-formed text, models, and values\n",
        "\n",
        "sentiments_all_dict['book_proust_fr_swans-way_proust_original_segments.csv'][:10]\n",
        "sentiments_all_dict['book_proust_fr_swans-way_proust_original_segments.csv'].info()"
      ],
      "metadata": {
        "id": "u346vLLGoDuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK lengths of each text\n",
        "\n",
        "for key, value in sentiments_all_dict.items():\n",
        "  print(f\"{key}\\n\\n\")\n",
        "\n",
        "for filename_now, sentiment_df in sentiments_all_dict.items():\n",
        "    print(f\"Processing: {filename_now} with len(sentiment_df) = {len(sentiment_df)}\")"
      ],
      "metadata": {
        "id": "wqmSJZ6Dmzsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[SKIP]**"
      ],
      "metadata": {
        "id": "jzN0HQ8w52yP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Local VSCode"
      ],
      "metadata": {
        "id": "2BDZkSYWl5f9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CngRePqaVagl"
      },
      "outputs": [],
      "source": [
        "sentiment_combined_files_list = [\n",
        "    \"book_proust_en_swans-way_davis_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_enright_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_en_swans-way_moncrieff_sentence_sentiment_combined.csv\",\n",
        "    \"book_proust_fr_swans-way_proust_sentence_sentiment_combined.csv\"\n",
        "]\n",
        "\n",
        "sentiment_combined_file = sentiment_combined_files_list[0]\n",
        "sentiment_df = pd.read_csv(sentiment_combined_file)\n",
        "\n",
        "sentiment_df.head()\n",
        "sentiment_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYem6jrp1896"
      },
      "outputs": [],
      "source": [
        "model_input_ls = sentiment_df.columns.tolist()\n",
        "model_input_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnyN9ZGNVaao"
      },
      "outputs": [],
      "source": [
        "\n",
        "# \"Swan's Way by Proust en_davis\"\n",
        "filename_subwords_list = sentiment_combined_file.split('_')\n",
        "novel_title = '_'.join([filename_subwords_list[1],filename_subwords_list[3],filename_subwords_list[2],filename_subwords_list[4]])\n",
        "print(novel_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLMS4igchaNH"
      },
      "source": [
        "# NOTES 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### START NEW CODE"
      ],
      "metadata": {
        "id": "LV8torHiaxxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments_all_equallen_dict.keys()"
      ],
      "metadata": {
        "id": "So5vrFQLdoB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Example dictionary of dataframes (using mock data for demonstration)\n",
        "sentiments_all_dict = {\n",
        "    \"book_proust_fr_swans-way_proust_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"Parfois, a peine ma bougie eteinte, mes yeux se fermaient immédiatement \" + str(i) for i in range(4514)],\n",
        "        'vader': np.random.randn(4514),\n",
        "        'textblob': np.random.randn(4514),\n",
        "        'bertmulti': np.random.randn(4514),\n",
        "        'mistral': np.random.randn(4514)\n",
        "    }),\n",
        "    \"book_proust_en_swans-way_moncrieff_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"Sometimes, when I had put out my candle, my eyes would close so quickly that I had not even time to say 'I'm going to sleep.'\" + str(i) for i in range(4287)],\n",
        "        'vader': np.random.randn(4287),\n",
        "        'textblob': np.random.randn(4287),\n",
        "        'bertmulti': np.random.randn(4287),\n",
        "        'mistral': np.random.randn(4287)\n",
        "    }),\n",
        "    \"book_proust_en_swans-way_davis_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"The Way by Swann's, for a long time I used to go to bed early.\" + str(i) for i in range(4321)],\n",
        "        'vader': np.random.randn(4321),\n",
        "        'textblob': np.random.randn(4321),\n",
        "        'bertmulti': np.random.randn(4321),\n",
        "        'mistral': np.random.randn(4321)\n",
        "    }),\n",
        "    \"book_proust_en_swans-way_enright_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"For a long time I would go to bed early, sometimes the candle barely out, my eyes would close so quickly that I had not even time to say I'm going to sleep.\" + str(i) for i in range(4449)],\n",
        "        'vader': np.random.randn(4449),\n",
        "        'textblob': np.random.randn(4449),\n",
        "        'bertmulti': np.random.randn(4449),\n",
        "        'mistral': np.random.randn(4449)\n",
        "    }),\n",
        "}\n",
        "\n",
        "WIN_PER = 10  # Percentage for SMA smoothing\n",
        "\n",
        "# 1. Dictionaries for clean output names\n",
        "output_map_titles_dict = {\n",
        "    \"book_proust_fr_swans-way_proust_original_segments.csv\": \"Swan's Way (original Proust in French)\",\n",
        "    \"book_proust_en_swans-way_moncrieff_original_segments.csv\": \"Swan's Way (trans. Moncrieff in English)\",\n",
        "    \"book_proust_en_swans-way_davis_original_segments.csv\": \"Swan's Way (trans. Davis in English)\",\n",
        "    \"book_proust_en_swans-way_enright_original_segments.csv\": \"Swan's Way (trans. Enright in English)\"\n",
        "}\n",
        "\n",
        "output_map_legend_dict = {\n",
        "    \"book_proust_fr_swans-way_proust_original_segments.csv\": \"Proust Original, French\",\n",
        "    \"book_proust_en_swans-way_moncrieff_original_segments.csv\": \"Moncrieff Translation, English\",\n",
        "    \"book_proust_en_swans-way_davis_original_segments.csv\": \"Davis Translation, English\",\n",
        "    \"book_proust_en_swans-way_enright_original_segments.csv\": \"Enright Translation, English\"\n",
        "}\n",
        "\n",
        "# 2. Aggregate the longer time series\n",
        "def aggregate_short_text(df, target_length):\n",
        "    while len(df) > target_length:\n",
        "        # Find the shortest text fragment\n",
        "        df['text_length'] = df['text'].apply(len)\n",
        "        shortest_index = df['text_length'].idxmin()\n",
        "\n",
        "        # Identify the shortest neighbor (previous or next)\n",
        "        if shortest_index == 0:\n",
        "            neighbor_index = shortest_index + 1\n",
        "        elif shortest_index == len(df) - 1:\n",
        "            neighbor_index = shortest_index - 1\n",
        "        else:\n",
        "            neighbor_index = shortest_index + 1 if df['text_length'][shortest_index + 1] < df['text_length'][shortest_index - 1] else shortest_index - 1\n",
        "\n",
        "        # Combine the shortest text fragment with its neighbor\n",
        "        df.at[neighbor_index, 'text'] = df.at[neighbor_index, 'text'] + \" \" + df.at[shortest_index, 'text']\n",
        "\n",
        "        # Average the sentiment values\n",
        "        for sentiment in ['vader', 'textblob', 'bertmulti', 'mistral']:\n",
        "            df.at[neighbor_index, sentiment] = (df.at[neighbor_index, sentiment] + df.at[shortest_index, sentiment]) / 2\n",
        "\n",
        "        # Drop the shortest text fragment row\n",
        "        df = df.drop(shortest_index).reset_index(drop=True)\n",
        "\n",
        "    # Drop the temporary 'text_length' column\n",
        "    df = df.drop(columns=['text_length'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Find the minimum length\n",
        "min_length = min(len(df) for df in sentiments_all_dict.values())\n",
        "\n",
        "# Create a new dictionary for equal length timeseries (using copies)\n",
        "sentiments_all_equallen_dict = {}\n",
        "for key, df in sentiments_all_dict.items():\n",
        "    df_copy = df.copy()\n",
        "    if len(df_copy) > min_length:\n",
        "        df_copy = aggregate_short_text(df_copy, min_length)\n",
        "    sentiments_all_equallen_dict[key] = df_copy\n",
        "\n",
        "# Z-score normalize the sentiment values\n",
        "for key, df in sentiments_all_equallen_dict.items():\n",
        "    sentiments_all_equallen_dict[key][['vader', 'textblob', 'bertmulti', 'mistral']] = df[['vader', 'textblob', 'bertmulti', 'mistral']].apply(zscore)\n",
        "\n",
        "# Apply SMA smoothing\n",
        "def apply_smoothing(df, window_percentage):\n",
        "    window_length = max(int(len(df) * window_percentage / 100), 1)\n",
        "    for sentiment in ['vader', 'textblob', 'bertmulti', 'mistral']:\n",
        "        df[sentiment] = df[sentiment].rolling(window=window_length, min_periods=1, center=True).mean()\n",
        "    return df\n",
        "\n",
        "if WIN_PER > 0:\n",
        "    for key in sentiments_all_equallen_dict.keys():\n",
        "        sentiments_all_equallen_dict[key] = apply_smoothing(sentiments_all_equallen_dict[key], WIN_PER)\n",
        "\n",
        "# Combine dataframes and prepare for plotting\n",
        "combined_df = pd.concat(sentiments_all_equallen_dict, axis=0)\n",
        "combined_df.reset_index(level=0, inplace=True)\n",
        "combined_df.rename(columns={'level_0': 'source'}, inplace=True)\n",
        "combined_df['sentence_no'] = combined_df.groupby('source').cumcount() + 1\n",
        "\n",
        "# Map the clean names to the combined dataframe\n",
        "combined_df['source_clean'] = combined_df['source'].map(output_map_legend_dict)\n",
        "\n",
        "# Create a column for shortened text for tooltips\n",
        "combined_df['short_text'] = combined_df['text'].apply(lambda x: x[:25] + '...')\n",
        "\n",
        "# Create columns for each text version\n",
        "combined_df['text_proust'] = combined_df[combined_df['source'] == 'book_proust_fr_swans-way_proust_original_segments.csv']['text']\n",
        "combined_df['text_moncrieff'] = combined_df[combined_df['source'] == 'book_proust_en_swans-way_moncrieff_original_segments.csv']['text']\n",
        "combined_df['text_davis'] = combined_df[combined_df['source'] == 'book_proust_en_swans-way_davis_original_segments.csv']['text']\n",
        "combined_df['text_enright'] = combined_df[combined_df['source'] == 'book_proust_en_swans-way_enright_original_segments.csv']['text']\n",
        "\n",
        "# Merge the text columns for hover data\n",
        "hover_data = combined_df[['source_clean', 'short_text', 'text_proust', 'text_moncrieff', 'text_davis', 'text_enright']].fillna('')\n",
        "hover_data['hover_text'] = hover_data.apply(lambda row: f\"Proust: {row['text_proust'][:25]}...<br>Moncrieff: {row['text_moncrieff'][:25]}...<br>Davis: {row['text_davis'][:25]}...<br>Enright: {row['text_enright'][:25]}...\", axis=1)\n",
        "\n",
        "# Create interactive Plotly plot focusing on the 'mistral' sentiment model\n",
        "fig = px.line(\n",
        "    combined_df,\n",
        "    x='sentence_no',\n",
        "    y='mistral',  # Ensure this is the Z-score normalized value\n",
        "    color='source_clean',\n",
        "    title=\"Swan's Way by Proust\\nSentiment vs Sentence No\\nMistral 7B LLM\\nNormalized (Z-Score) and Smoothed (SMA 10%)\",\n",
        "    labels={'sentence_no': 'Sentence Number', 'mistral': 'Z-score Normalized Sentiment'}\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Sentence Number',\n",
        "    yaxis_title='Z-score Normalized Sentiment',\n",
        "    legend_title='Source',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(x=0.01, y=0.01, xanchor='left', yanchor='bottom', bgcolor='rgba(255,255,255,0.5)')\n",
        ")\n",
        "\n",
        "# Add hover data for exact text from each translation\n",
        "fig.update_traces(\n",
        "    hovertemplate=\"<br>\".join([\n",
        "        \"Source: %{customdata[0]}\",\n",
        "        \"Sentence No: %{x}\",\n",
        "        \"Sentiment: %{y}\",\n",
        "        \"Text: %{customdata[1]}\"\n",
        "    ]),\n",
        "    customdata=hover_data[['source_clean', 'hover_text']].values\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# Create high-quality seaborn plots with normalized values\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(14, 7), dpi=300)\n",
        "\n",
        "# Plot mean sentiment scores with SMA smoothing and normalized values for the 'mistral' sentiment model\n",
        "for source, group_df in combined_df.groupby('source_clean'):\n",
        "    plt.plot(group_df['sentence_no'], group_df['mistral'], label=source)\n",
        "\n",
        "plt.title(\"Swan's Way by Proust\\nSentiment vs Sentence No\\nMistral 7B LLM\\nNormalized (Z-Score) and Smoothed (SMA 10%)\", fontsize=18)\n",
        "plt.xlabel(\"Sentence Number\", fontsize=14)\n",
        "plt.ylabel(\"Z-score Normalized Sentiment\", fontsize=14)\n",
        "plt.legend(title=\"Source\", bbox_to_anchor=(0.01, 0.01), loc='lower left')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"sentiment_timeseries_seaborn.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Create high-resolution plot using LOWESS smoothing\n",
        "combined_df['lowess_mistral'] = combined_df.groupby('source')['mistral'].transform(lambda x: lowess(x, np.arange(len(x)), frac=0.1)[:, 1])\n",
        "\n",
        "plt.figure(figsize=(14, 7), dpi=300)\n",
        "\n",
        "# Plot LOWESS smoothed sentiment scores for the 'mistral' sentiment model\n",
        "for source, group_df in combined_df.groupby('source_clean'):\n",
        "    plt.plot(group_df['sentence_no'], group_df['lowess_mistral'], label=source)\n",
        "\n",
        "plt.title(\"Swan's Way by Proust\\nSentiment vs Sentence No\\nMistral 7B LLM\\nNormalized (Z-Score) and Smoothed (LOWESS)\", fontsize=18)\n",
        "plt.xlabel(\"Sentence Number\", fontsize=14)\n",
        "plt.ylabel(\"Z-score Normalized Sentiment\", fontsize=14)\n",
        "plt.legend(title=\"Source\", bbox_to_anchor=(0.01, 0.01), loc='lower left')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"sentiment_timeseries_seaborn_lowess.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "zY9i_4vJmkax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Example dictionary of dataframes (using mock data for demonstration)\n",
        "sentiments_all_dict = {\n",
        "    \"book_proust_fr_swans-way_proust_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"Parfois, a peine ma bougie eteinte, mes yeux se fermaient immédiatement \" + str(i) for i in range(4514)],\n",
        "        'vader': np.random.randn(4514),\n",
        "        'textblob': np.random.randn(4514),\n",
        "        'bertmulti': np.random.randn(4514),\n",
        "        'mistral': np.random.randn(4514)\n",
        "    }),\n",
        "    \"book_proust_en_swans-way_moncrieff_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"Sometimes, when I had put out my candle, my eyes would close so quickly that I had not even time to say 'I'm going to sleep.'\" + str(i) for i in range(4287)],\n",
        "        'vader': np.random.randn(4287),\n",
        "        'textblob': np.random.randn(4287),\n",
        "        'bertmulti': np.random.randn(4287),\n",
        "        'mistral': np.random.randn(4287)\n",
        "    }),\n",
        "    \"book_proust_en_swans-way_davis_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"The Way by Swann's, for a long time I used to go to bed early.\" + str(i) for i in range(4321)],\n",
        "        'vader': np.random.randn(4321),\n",
        "        'textblob': np.random.randn(4321),\n",
        "        'bertmulti': np.random.randn(4321),\n",
        "        'mistral': np.random.randn(4321)\n",
        "    }),\n",
        "    \"book_proust_en_swans-way_enright_original_segments.csv\": pd.DataFrame({\n",
        "        'text': [\"For a long time I would go to bed early, sometimes the candle barely out, my eyes would close so quickly that I had not even time to say I'm going to sleep.\" + str(i) for i in range(4449)],\n",
        "        'vader': np.random.randn(4449),\n",
        "        'textblob': np.random.randn(4449),\n",
        "        'bertmulti': np.random.randn(4449),\n",
        "        'mistral': np.random.randn(4449)\n",
        "    }),\n",
        "}\n",
        "\n",
        "WIN_PER = 10  # Percentage for SMA smoothing\n",
        "\n",
        "# 1. Dictionaries for clean output names\n",
        "output_map_titles_dict = {\n",
        "    \"book_proust_fr_swans-way_proust_original_segments.csv\": \"Swan's Way (original Proust in French)\",\n",
        "    \"book_proust_en_swans-way_moncrieff_original_segments.csv\": \"Swan's Way (trans. Moncrieff in English)\",\n",
        "    \"book_proust_en_swans-way_davis_original_segments.csv\": \"Swan's Way (trans. Davis in English)\",\n",
        "    \"book_proust_en_swans-way_enright_original_segments.csv\": \"Swan's Way (trans. Enright in English)\"\n",
        "}\n",
        "\n",
        "output_map_legend_dict = {\n",
        "    \"book_proust_fr_swans-way_proust_original_segments.csv\": \"Proust Original, French\",\n",
        "    \"book_proust_en_swans-way_moncrieff_original_segments.csv\": \"Moncrieff Translation, English\",\n",
        "    \"book_proust_en_swans-way_davis_original_segments.csv\": \"Davis Translation, English\",\n",
        "    \"book_proust_en_swans-way_enright_original_segments.csv\": \"Enright Translation, English\"\n",
        "}\n",
        "\n",
        "# 2. Aggregate the longer time series\n",
        "def aggregate_short_text(df, target_length):\n",
        "    while len(df) > target_length:\n",
        "        # Find the shortest text fragment\n",
        "        df['text_length'] = df['text'].apply(len)\n",
        "        shortest_index = df['text_length'].idxmin()\n",
        "\n",
        "        # Identify the shortest neighbor (previous or next)\n",
        "        if shortest_index == 0:\n",
        "            neighbor_index = shortest_index + 1\n",
        "        elif shortest_index == len(df) - 1:\n",
        "            neighbor_index = shortest_index - 1\n",
        "        else:\n",
        "            neighbor_index = shortest_index + 1 if df['text_length'][shortest_index + 1] < df['text_length'][shortest_index - 1] else shortest_index - 1\n",
        "\n",
        "        # Combine the shortest text fragment with its neighbor\n",
        "        df.at[neighbor_index, 'text'] = df.at[neighbor_index, 'text'] + \" \" + df.at[shortest_index, 'text']\n",
        "\n",
        "        # Average the sentiment values\n",
        "        for sentiment in ['vader', 'textblob', 'bertmulti', 'mistral']:\n",
        "            df.at[neighbor_index, sentiment] = (df.at[neighbor_index, sentiment] + df.at[shortest_index, sentiment]) / 2\n",
        "\n",
        "        # Drop the shortest text fragment row\n",
        "        df = df.drop(shortest_index).reset_index(drop=True)\n",
        "\n",
        "    # Drop the temporary 'text_length' column\n",
        "    df = df.drop(columns=['text_length'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Find the minimum length\n",
        "min_length = min(len(df) for df in sentiments_all_dict.values())\n",
        "\n",
        "# Create a new dictionary for equal length timeseries (using copies)\n",
        "sentiments_all_equallen_dict = {}\n",
        "for key, df in sentiments_all_dict.items():\n",
        "    df_copy = df.copy()\n",
        "    if len(df_copy) > min_length:\n",
        "        df_copy = aggregate_short_text(df_copy, min_length)\n",
        "    sentiments_all_equallen_dict[key] = df_copy\n",
        "\n",
        "# Z-score normalize the sentiment values\n",
        "for key, df in sentiments_all_equallen_dict.items():\n",
        "    sentiments_all_equallen_dict[key][['vader', 'textblob', 'bertmulti', 'mistral']] = df[['vader', 'textblob', 'bertmulti', 'mistral']].apply(zscore)\n",
        "\n",
        "# Apply SMA smoothing\n",
        "def apply_smoothing(df, window_percentage):\n",
        "    window_length = max(int(len(df) * window_percentage / 100), 1)\n",
        "    for sentiment in ['vader', 'textblob', 'bertmulti', 'mistral']:\n",
        "        df[sentiment] = df[sentiment].rolling(window=window_length, min_periods=1, center=True).mean()\n",
        "    return df\n",
        "\n",
        "if WIN_PER > 0:\n",
        "    for key in sentiments_all_equallen_dict.keys():\n",
        "        sentiments_all_equallen_dict[key] = apply_smoothing(sentiments_all_equallen_dict[key], WIN_PER)\n",
        "\n",
        "# Combine dataframes and prepare for plotting\n",
        "combined_df = pd.concat(sentiments_all_equallen_dict, axis=0)\n",
        "combined_df.reset_index(level=0, inplace=True)\n",
        "combined_df.rename(columns={'level_0': 'source'}, inplace=True)\n",
        "combined_df['sentence_no'] = combined_df.groupby('source').cumcount() + 1\n",
        "\n",
        "# Map the clean names to the combined dataframe\n",
        "combined_df['source_clean'] = combined_df['source'].map(output_map_legend_dict)\n",
        "\n",
        "# Create a column for shortened text for tooltips\n",
        "combined_df['short_text'] = combined_df['text'].apply(lambda x: x[:25] + '...')\n",
        "\n",
        "# Create columns for each text version\n",
        "combined_df['text_proust'] = combined_df[combined_df['source'] == 'book_proust_fr_swans-way_proust_original_segments.csv']['text']\n",
        "combined_df['text_moncrieff'] = combined_df[combined_df['source'] == 'book_proust_en_swans-way_moncrieff_original_segments.csv']['text']\n",
        "combined_df['text_davis'] = combined_df[combined_df['source'] == 'book_proust_en_swans-way_davis_original_segments.csv']['text']\n",
        "combined_df['text_enright'] = combined_df[combined_df['source'] == 'book_proust_en_swans-way_enright_original_segments.csv']['text']\n",
        "\n",
        "# Merge the text columns for hover data\n",
        "hover_data = combined_df[['source_clean', 'short_text', 'text_proust', 'text_moncrieff', 'text_davis', 'text_enright']].fillna('')\n",
        "hover_data['hover_text'] = hover_data.apply(lambda row: f\"Proust: {row['text_proust'][:25]}...<br>Moncrieff: {row['text_moncrieff'][:25]}...<br>Davis: {row['text_davis'][:25]}...<br>Enright: {row['text_enright'][:25]}...\", axis=1)\n",
        "\n",
        "# Create interactive Plotly plot focusing on the 'mistral' sentiment model\n",
        "fig = px.line(\n",
        "    combined_df,\n",
        "    x='sentence_no',\n",
        "    y='mistral',  # Ensure this is the Z-score normalized value\n",
        "    color='source_clean',\n",
        "    title=\"Swan's Way by Proust\\nSentiment vs Sentence No\\nMistral 7B LLM\\nNormalized (Z-Score) and Smoothed (SMA 10%)\",\n",
        "    labels={'sentence_no': 'Sentence Number', 'mistral': 'Z-score Normalized Sentiment'}\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Sentence Number',\n",
        "    yaxis_title='Z-score Normalized Sentiment',\n",
        "    legend_title='Source',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(x=0.01, y=0.01, xanchor='left', yanchor='bottom', bgcolor='rgba(255,255,255,0.5)')\n",
        ")\n",
        "\n",
        "# Add hover data for exact text from each translation\n",
        "fig.update_traces(\n",
        "    hovertemplate=\"<br>\".join([\n",
        "        \"Source: %{customdata[0]}\",\n",
        "        \"Sentence No: %{x}\",\n",
        "        \"Sentiment: %{y}\",\n",
        "        \"Text: %{customdata[1]}\"\n",
        "    ]),\n",
        "    customdata=hover_data[['source_clean', 'hover_text']].values\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Create high-quality seaborn plots with normalized values\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(14, 7), dpi=300)\n",
        "\n",
        "# Plot mean sentiment scores with SMA smoothing and normalized values for the 'mistral' sentiment model\n",
        "for source, group_df in combined_df.groupby('source_clean'):\n",
        "    plt.plot(group_df['sentence_no'], group_df['mistral'], label=source)\n",
        "\n",
        "plt.title(\"Swan's Way by Proust\\nSentiment vs Sentence No\\nMistral 7B LLM\\nNormalized (Z-Score) and Smoothed (SMA 10%)\", fontsize=18)\n",
        "plt.xlabel(\"Sentence Number\", fontsize=14)\n",
        "plt.ylabel(\"Z-score Normalized Sentiment\", fontsize=14)\n",
        "plt.legend(title=\"Source\", bbox_to_anchor=(0.01, 0.01), loc='lower left')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"sentiment_timeseries_seaborn.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Create high-resolution plot using LOWESS smoothing\n",
        "combined_df['lowess_mistral'] = combined_df.groupby('source')['mistral'].transform(lambda x: lowess(x, np.arange(len(x)), frac=0.1)[:, 1])\n",
        "\n",
        "plt.figure(figsize=(14, 7), dpi=300)\n",
        "\n",
        "# Plot LOWESS smoothed sentiment scores for the 'mistral' sentiment model\n",
        "for source, group_df in combined_df.groupby('source_clean'):\n",
        "    plt.plot(group_df['sentence_no'], group_df['lowess_mistral'], label=source)\n",
        "\n",
        "plt.title(\"Swan's Way by Proust\\nSentiment vs Sentence No\\nMistral 7B LLM\\nNormalized (Z-Score) and Smoothed (LOWESS)\", fontsize=18)\n",
        "plt.xlabel(\"Sentence Number\", fontsize=14)\n",
        "plt.ylabel(\"Z-score Normalized Sentiment\", fontsize=14)\n",
        "plt.legend(title=\"Source\", bbox_to_anchor=(0.01, 0.01), loc='lower left')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"sentiment_timeseries_seaborn_lowess.png\", format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3Ke7EBiuqRNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04GN4fOvqRKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments_all_equallen_dict.keys()"
      ],
      "metadata": {
        "id": "bF9PThC-iwW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments_all_dict['book_proust_fr_swans-way_proust_original_segments.csv'][100:103]"
      ],
      "metadata": {
        "id": "vH1wvhHxiwTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### START OLD CODE"
      ],
      "metadata": {
        "id": "aSdKHtn_auzv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQcC0CDk149g"
      },
      "outputs": [],
      "source": [
        "model_input_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4keI9B5t7-DM"
      },
      "outputs": [],
      "source": [
        "##@title Enter the Sliding Window width as Percent of Novel length (default 10%, larger=smoother)\n",
        "\n",
        "Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "win_per = Window_Percent\n",
        "win_size = int(win_per/100 * sentiment_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbAyRC7av2TJ"
      },
      "outputs": [],
      "source": [
        "sentiment_df.head()\n",
        "sentiment_df.info()\n",
        "sentiment_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge and Plot Mutliple Translations"
      ],
      "metadata": {
        "id": "zKjDsqqGqQra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments_all_dict.keys()"
      ],
      "metadata": {
        "id": "ShsCZP6CqYbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_sma_zscores(dictionary_of_df, win_per=10):\n",
        "    \"\"\"\n",
        "    Plots the sentiment time series with SMA and Z-scores for each DataFrame in the dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    dictionary_of_df (dict): Dictionary where keys are filenames and values are pandas DataFrames.\n",
        "                             Each DataFrame contains a 'text' column and other columns for sentiment scores.\n",
        "    win_per (int): The window size percentage for the Simple Moving Average (SMA).\n",
        "    \"\"\"\n",
        "    for key, df in dictionary_of_df.items():\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Calculate the window size for SMA\n",
        "        window_size = max(1, int(len(df) * win_per / 100))\n",
        "\n",
        "        # Temporary DataFrame to store z-scores\n",
        "        temp_df = pd.DataFrame()\n",
        "\n",
        "        # Compute z-scores for each sentiment column\n",
        "        for sentiment_model in df.columns[1:]:  # Skip the first column 'text'\n",
        "            mean = df[sentiment_model].mean()\n",
        "            std = df[sentiment_model].std()\n",
        "            z_scores = (df[sentiment_model] - mean) / std\n",
        "            temp_df[sentiment_model] = z_scores\n",
        "\n",
        "        # Plot each sentiment column with SMA against the row number using z-scores\n",
        "        for sentiment_model in temp_df.columns:\n",
        "            smoothed_series = temp_df[sentiment_model].rolling(window=window_size, min_periods=1, center=True).mean()\n",
        "            smoothed_series = smoothed_series.interpolate(method='linear')\n",
        "            plt.plot(df.index, smoothed_series, label=sentiment_model)\n",
        "\n",
        "        plt.title(f'Sentiment Analysis (Z-Scores) for {key}')\n",
        "        plt.xlabel('Row Number')\n",
        "        plt.ylabel('Z-Scores of Sentiment Scores')\n",
        "        plt.legend()\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'dataframes_dict' is a dictionary of DataFrames\n",
        "# plot_sma_zscores(dataframes_dict, win_per=10)\n"
      ],
      "metadata": {
        "id": "oUNavTsiqQGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sma_zscores(sentiments_all_dict)"
      ],
      "metadata": {
        "id": "9AwuEUvqqQAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_sma_zscores(dictionary_of_df, win_per=10, plot_by_model=False):\n",
        "    \"\"\"\n",
        "    Plots the sentiment time series with SMA and Z-scores for each DataFrame in the dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    dictionary_of_df (dict): Dictionary where keys are filenames and values are pandas DataFrames.\n",
        "                             Each DataFrame contains a 'text' column and other columns for sentiment scores.\n",
        "    win_per (int): The window size percentage for the Simple Moving Average (SMA).\n",
        "    plot_by_model (bool): If True, reorganize and plot by sentiment model instead of by filename.\n",
        "    \"\"\"\n",
        "    if not plot_by_model:\n",
        "        # Plot by filename (book)\n",
        "        for key, df in dictionary_of_df.items():\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # Calculate the window size for SMA\n",
        "            window_size = max(1, int(len(df) * win_per / 100))\n",
        "\n",
        "            # Temporary DataFrame to store z-scores\n",
        "            temp_df = pd.DataFrame()\n",
        "\n",
        "            # Compute z-scores for each sentiment column\n",
        "            for sentiment_model in df.columns[1:]:  # Skip the first column 'text'\n",
        "                mean = df[sentiment_model].mean()\n",
        "                std = df[sentiment_model].std()\n",
        "                z_scores = (df[sentiment_model] - mean) / std\n",
        "                temp_df[sentiment_model] = z_scores\n",
        "\n",
        "            # Plot each sentiment column with SMA against the row number using z-scores\n",
        "            for sentiment_model in temp_df.columns:\n",
        "                smoothed_series = temp_df[sentiment_model].rolling(window=window_size, min_periods=1, center=True).mean()\n",
        "                smoothed_series = smoothed_series.interpolate(method='linear')\n",
        "                plt.plot(df.index, smoothed_series, label=sentiment_model)\n",
        "\n",
        "            plt.title(f'Sentiment Analysis (Z-Scores) for {key}')\n",
        "            plt.xlabel('Row Number')\n",
        "            plt.ylabel('Z-Scores of Sentiment Scores')\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "            plt.show()\n",
        "    else:\n",
        "        # Plot by sentiment model\n",
        "        models = dictionary_of_df[next(iter(dictionary_of_df))].columns[1:]  # Get list of sentiment models from the first DataFrame\n",
        "\n",
        "        for model in models:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # Temporary DataFrame to store concatenated z-scores for the model\n",
        "            temp_df = pd.DataFrame()\n",
        "\n",
        "            for key, df in dictionary_of_df.items():\n",
        "                mean = df[model].mean()\n",
        "                std = df[model].std()\n",
        "                z_scores = (df[model] - mean) / std\n",
        "                temp_df = pd.concat([temp_df, z_scores.reset_index(drop=True)], axis=0)\n",
        "\n",
        "            # Reset index to make it continuous\n",
        "            temp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "            # Calculate the window size for SMA\n",
        "            window_size = max(1, int(len(temp_df) * win_per / 100))\n",
        "\n",
        "            # Apply SMA and interpolation\n",
        "            smoothed_series = temp_df.rolling(window=window_size, min_periods=1, center=True).mean()\n",
        "            smoothed_series = smoothed_series.interpolate(method='linear')\n",
        "\n",
        "            plt.plot(smoothed_series, label=model)\n",
        "\n",
        "            plt.title(f'Sentiment Analysis (Z-Scores) for Model: {model}')\n",
        "            plt.xlabel('Row Number')\n",
        "            plt.ylabel('Z-Scores of Sentiment Scores')\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "            plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'dataframes_dict' is a dictionary of DataFrames\n",
        "# plot_sma_zscores(dataframes_dict, win_per=10, plot_by_model=False)\n",
        "# plot_sma_zscores(dataframes_dict, win_per=10, plot_by_model=True)\n"
      ],
      "metadata": {
        "id": "ul8f7CdbqP8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_sma_zscores(dictionary_of_df, win_per=10, plot_by_model=False):\n",
        "    \"\"\"\n",
        "    Plots the sentiment time series with SMA and Z-scores for each DataFrame in the dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    dictionary_of_df (dict): Dictionary where keys are filenames and values are pandas DataFrames.\n",
        "                             Each DataFrame contains a 'text' column and other columns for sentiment scores.\n",
        "    win_per (int): The window size percentage for the Simple Moving Average (SMA).\n",
        "    plot_by_model (bool): If True, reorganize and plot by sentiment model instead of by filename.\n",
        "    \"\"\"\n",
        "    if not plot_by_model:\n",
        "        # Plot by filename (book)\n",
        "        for key, df in dictionary_of_df.items():\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # Calculate the window size for SMA\n",
        "            window_size = max(1, int(len(df) * win_per / 100))\n",
        "\n",
        "            # Temporary DataFrame to store z-scores\n",
        "            temp_df = pd.DataFrame()\n",
        "\n",
        "            # Compute z-scores for each sentiment column\n",
        "            for sentiment_model in df.columns[1:]:  # Skip the first column 'text'\n",
        "                mean = df[sentiment_model].mean()\n",
        "                std = df[sentiment_model].std()\n",
        "                z_scores = (df[sentiment_model] - mean) / std\n",
        "                temp_df[sentiment_model] = z_scores\n",
        "\n",
        "            # Plot each sentiment column with SMA against the row number using z-scores\n",
        "            for sentiment_model in temp_df.columns:\n",
        "                smoothed_series = temp_df[sentiment_model].rolling(window=window_size, min_periods=1, center=True).mean()\n",
        "                smoothed_series = smoothed_series.interpolate(method='linear')\n",
        "                plt.plot(df.index, smoothed_series, label=sentiment_model)\n",
        "\n",
        "            plt.title(f'Sentiment Analysis (Z-Scores) for {key}')\n",
        "            plt.xlabel('Row Number')\n",
        "            plt.ylabel('Z-Scores of Sentiment Scores')\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "            plt.show()\n",
        "    else:\n",
        "        # Plot by sentiment model\n",
        "        models = dictionary_of_df[next(iter(dictionary_of_df))].columns[1:]  # Get list of sentiment models from the first DataFrame\n",
        "\n",
        "        for model in models:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            for key, df in dictionary_of_df.items():\n",
        "                # Temporary DataFrame to store z-scores\n",
        "                temp_df = pd.DataFrame()\n",
        "\n",
        "                mean = df[model].mean()\n",
        "                std = df[model].std()\n",
        "                z_scores = (df[model] - mean) / std\n",
        "                temp_df[model] = z_scores\n",
        "\n",
        "                # Calculate the window size for SMA\n",
        "                window_size = max(1, int(len(temp_df) * win_per / 100))\n",
        "\n",
        "                # Apply SMA and interpolation\n",
        "                smoothed_series = temp_df[model].rolling(window=window_size, min_periods=1, center=True).mean()\n",
        "                smoothed_series = smoothed_series.interpolate(method='linear')\n",
        "                plt.plot(df.index, smoothed_series, label=key)\n",
        "\n",
        "            plt.title(f'Sentiment Analysis (Z-Scores) for Model: {model}')\n",
        "            plt.xlabel('Row Number')\n",
        "            plt.ylabel('Z-Scores of Sentiment Scores')\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "            plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'dataframes_dict' is a dictionary of DataFrames\n",
        "# plot_sma_zscores(dataframes_dict, win_per=10, plot_by_model=False)\n",
        "# plot_sma_zscores(dataframes_dict, win_per=10, plot_by_model=True)\n"
      ],
      "metadata": {
        "id": "9_P-7GpKt-Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sma_zscores(sentiments_all_dict, win_per=10, plot_by_model=True)"
      ],
      "metadata": {
        "id": "5Fquf9vIqiMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3ObqCi0qiG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtJxKvQCqiCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQdVGmK_RY2G"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B1hbOF966Vr"
      },
      "source": [
        "### Plot Raw Timeseries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEuchgTWZlQb"
      },
      "source": [
        "### Ensure sentiment_df has no NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOYR2V1MZlHT"
      },
      "outputs": [],
      "source": [
        "sentiment_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oWnWx6wWA0j"
      },
      "outputs": [],
      "source": [
        "# fillna(0)\n",
        "\n",
        "model_ls = sentiment_df.columns.to_list()\n",
        "\n",
        "for col_name in model_input_ls:\n",
        "  sentiment_df[col_name] = sentiment_df[col_name].fillna(0)\n",
        "\n",
        "sentiment_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDrVJq3yLZwJ"
      },
      "source": [
        "### Define model columns in sentiment_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t7JfWiXQFVT"
      },
      "source": [
        "##### Raw Sentiment Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2-qU6UK7AA3"
      },
      "outputs": [],
      "source": [
        "# Plot Raw Timeseries\n",
        "\n",
        "win_per = 10\n",
        "win_size = int((win_per)/100 * sentiment_df.shape[0])\n",
        "ax = sentiment_df[model_ls].rolling(win_size, center=True).mean().plot(grid=True, lw=3, colormap='Dark2')\n",
        "ax.title.set_text(f'Sentiment Analysis \\n {novel_title} \\n Raw Sentiment Timeseries')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKgcrNd6gg2T"
      },
      "source": [
        "##### Seaborn Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnaeM76QUBF"
      },
      "source": [
        "#### Plotly Interactive Plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDgmcekl3QxG"
      },
      "outputs": [],
      "source": [
        "%whos list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SgT08SV3XSj"
      },
      "outputs": [],
      "source": [
        "novel_lines_ls[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leVa5Stf3j0u"
      },
      "outputs": [],
      "source": [
        "model_ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvEaCuV85vNO"
      },
      "outputs": [],
      "source": [
        "# Let crux point sentences\n",
        "\n",
        "win_lines = 10\n",
        "win_half = int(win_lines / 2)\n",
        "print(f\"win_half: {win_half}\")\n",
        "\n",
        "crux_sentence_no = 1795\n",
        "crux_range = f\"[{crux_sentence_no - win_half}:{crux_sentence_no + win_half}]\"\n",
        "print(f\"crux_range: {crux_range}\")\n",
        "\n",
        "index_start = crux_sentence_no - win_half\n",
        "index_end = crux_sentence_no + win_half\n",
        "\n",
        "# Assuming lines_list is defined somewhere in your code\n",
        "# Example: lines_list = [\"sentence 1\", \"sentence 2\", ..., \"sentence n\"]\n",
        "\n",
        "print(f\"Crux around Sentence #{crux_sentence_no}: \\n\")\n",
        "for line_now in lines_list[index_start:index_end]:\n",
        "  print(f\"  {line_now}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRttTUUr7jQq"
      },
      "outputs": [],
      "source": [
        "%whos dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7-C91Ig8ACI"
      },
      "source": [
        "**[END]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRq6gaKb79eH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfsmW-IN6-W_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Example sentiment_df and model_input_ls for testing\n",
        "sentiment_df = pd.DataFrame({\n",
        "    'sentence_num': [1, 2, 3, 4, 5],\n",
        "    'sentence_text': [\"The world is changed.\", \"I feel it in the water.\", \"I feel it in the earth.\", \"I smell it in the air.\", \"Much that once was is lost.\"],\n",
        "    'model_col_1': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "    'model_col_2': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "})\n",
        "model_input_ls = ['model_col_1', 'model_col_2']\n",
        "\n",
        "# Define the transform_zscore_norm function\n",
        "def transform_zscore_norm(original_df, model_list):\n",
        "    transformed_df = original_df.copy()\n",
        "    for col in model_list:\n",
        "        mean_val = transformed_df[col].mean()\n",
        "        std_val = transformed_df[col].std()\n",
        "        transformed_df[col] = (transformed_df[col] - mean_val) / std_val\n",
        "    return transformed_df\n",
        "\n",
        "# Transform the dataframe\n",
        "sentiment_zscore_df = transform_zscore_norm(sentiment_df, model_input_ls)\n",
        "\n",
        "# Create Plotly plot with rollover points showing sentence number and text\n",
        "def plot_with_rollover(dataframe, model_list, novel_title):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for column in model_list:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=dataframe['sentence_num'],\n",
        "            y=dataframe[column],\n",
        "            mode='lines+markers',\n",
        "            name=column,\n",
        "            hovertext=dataframe['sentence_num'].astype(str) + \": \" + dataframe['sentence_text'],\n",
        "            hoverinfo='text'\n",
        "        ))\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=f'Sentiment Analysis - {novel_title} - Raw Sentiment Timeseries',\n",
        "        xaxis_title=\"Sentence Number\",\n",
        "        yaxis_title=\"Standardized Value\",\n",
        "        autosize=False,\n",
        "        width=800,\n",
        "        height=500,\n",
        "        margin=dict(\n",
        "            l=50,\n",
        "            r=50,\n",
        "            b=100,\n",
        "            t=100,\n",
        "            pad=4\n",
        "        ),\n",
        "        paper_bgcolor=\"LightSteelBlue\",\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# Example usage\n",
        "novel_title = \"Example Novel\"\n",
        "plot_with_rollover(sentiment_zscore_df, model_input_ls, novel_title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkWUREnhbGHG"
      },
      "source": [
        "#### Get Most Incoherent Sentences in Novel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_-90GyePfjL"
      },
      "outputs": [],
      "source": [
        "sentiment_df.head()\n",
        "sentiment_df.info()\n",
        "sentiment_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrPd6dkm_kiZ"
      },
      "outputs": [],
      "source": [
        "model_input_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s71ES_m3ZId_"
      },
      "outputs": [],
      "source": [
        "model_input_ls = [\n",
        " 'sentiment-bertmulti',\n",
        " 'sentiment-mistral7b',\n",
        " 'sentiment-textblob',\n",
        " 'sentiment-vader',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A9143N2XRrf"
      },
      "outputs": [],
      "source": [
        "# Compute the coherence column\n",
        "sentiment_df['incoherence'] = sentiment_df[model_input_ls].apply(lambda x: x.max() - x.min(), axis=1)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "sentiment_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiRMFj6YXRhr"
      },
      "outputs": [],
      "source": [
        "# Calculate the maximum difference between 'sentiment-mistral7b' and all other model columns\n",
        "sentiment_df['max_mistral_diff'] = sentiment_df.apply(\n",
        "    lambda row: max(abs(row['sentiment-mistral7b'] - row[col]) for col in model_input_ls if col != 'sentiment-mistral7b'), axis=1\n",
        ")\n",
        "\n",
        "# Display the updated DataFrame\n",
        "sentiment_df.head()\n",
        "sentiment_df.info()\n",
        "sentiment_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p9XH5NngneO"
      },
      "outputs": [],
      "source": [
        "model_input_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-Cm06iFSwTA"
      },
      "outputs": [],
      "source": [
        "def transform_scale_center(original_df, model_list):\n",
        "    # Step 0: Create a new DataFrame to contain the transformed time series\n",
        "    transformed_df = original_df.copy()\n",
        "\n",
        "    # Step 1: Rescale all values between -1.0 and +1.0 for specified columns\n",
        "    for col in model_list:\n",
        "        min_val = transformed_df[col].min()\n",
        "        max_val = transformed_df[col].max()\n",
        "\n",
        "        # Rescale the values between -1.0 and +1.0\n",
        "        transformed_df[col] = (2 * (transformed_df[col] - min_val) / (max_val - min_val)) - 1\n",
        "\n",
        "    # Step 2: Adjust all means to 0 for specified columns\n",
        "    for col in model_list:\n",
        "        transformed_df[col] = transformed_df[col] - transformed_df[col].mean()\n",
        "\n",
        "    return transformed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELA7HSjqgyla"
      },
      "outputs": [],
      "source": [
        "model_input_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_9hUbS8aB-K"
      },
      "outputs": [],
      "source": [
        "def plot_only_models(dataframe_in, model_cols, win_per=10):\n",
        "    # Calculate the window size for the moving average (win_per% of the data length)\n",
        "    win_size = max(1, int((win_per / 100) * len(dataframe_in)))\n",
        "    if win_size % 2 == 0:\n",
        "        win_size += 1  # Ensure window size is odd for centering\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    for model in model_cols:\n",
        "        # Calculate the moving average with the specified window size\n",
        "        sma = dataframe_in[model].rolling(window=win_size, min_periods=1, center=True).mean()\n",
        "        plt.plot(dataframe_in.index, sma, label=f'{model} SMA {win_per}%')\n",
        "\n",
        "    plt.title(f'Smoothed Time Series Plot with SMA {win_per}%\\n{novel_title}\\nZ-Score Normed')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend(model_ls, fontsize=10, loc='upper right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show();\n",
        "\n",
        "plot_only_models(sentiment_zscore_df, model_input_ls, win_per=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqEKegxLfzBj"
      },
      "outputs": [],
      "source": [
        "def transform_zscore_norm(original_df, model_list):\n",
        "    # Step 0: Create a new DataFrame to contain the transformed time series\n",
        "    transformed_df = original_df.copy()\n",
        "\n",
        "    # Step 1: Standardize (z-score normalization) for specified columns\n",
        "    for col in model_list:\n",
        "        mean_val = transformed_df[col].mean()\n",
        "        std_val = transformed_df[col].std()\n",
        "\n",
        "        # Standardize the values to have mean 0 and standard deviation 1\n",
        "        transformed_df[col] = (transformed_df[col] - mean_val) / std_val\n",
        "\n",
        "    return transformed_df\n",
        "\n",
        "sentiment_zscore_df = transform_zscore_norm(sentiment_df, model_input_ls)\n",
        "\n",
        "# Display the transformed DataFrame\n",
        "# print(sentiment_zscore_df)\n",
        "plot_only_models(sentiment_zscore_df, model_input_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKgpDKFhUJFS"
      },
      "outputs": [],
      "source": [
        "model_input_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6mKP7iPS0EI"
      },
      "outputs": [],
      "source": [
        "# sentiment_transformed_zscore_df = sentiment_zscore_df(sentiment_df, model_input_ls)\n",
        "sentiment_zscore_df.head()\n",
        "sentiment_zscore_df.info()\n",
        "sentiment_zscore_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS1GypXpbW_w"
      },
      "outputs": [],
      "source": [
        "def plot_models_plus(dataframe_in, model_cols, win_per=10):\n",
        "    # Calculate the window size for the moving average (win_per% of the data length)\n",
        "    win_size = max(1, int((win_per / 100) * len(dataframe_in)))\n",
        "    if win_size % 2 == 0:\n",
        "        win_size += 1  # Ensure window size is odd for centering\n",
        "\n",
        "    # Identify columns not in model_cols\n",
        "    additional_cols = [col for col in dataframe_in.columns if col not in model_cols]\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axs = plt.subplots(1 + len(additional_cols), 1, figsize=(15, 8 + 3 * len(additional_cols)), gridspec_kw={'height_ratios': [3] + [1] * len(additional_cols)})\n",
        "\n",
        "    # Plot the specified time series and their SMA in the main plot\n",
        "    for model in model_cols:\n",
        "        # Calculate the moving average with the specified window size\n",
        "        sma = dataframe_in[model].rolling(window=win_size, min_periods=1, center=True).mean()\n",
        "        axs[0].plot(dataframe_in.index, sma, label=f'{model} SMA {win_per}%')\n",
        "\n",
        "    axs[0].set_title(f'Smoothed Time Series Plot with SMA\\n{novel_title}\\nZ-Score Normed')\n",
        "    axs[0].set_xlabel('Index')\n",
        "    axs[0].set_ylabel('Value')\n",
        "    axs[0].legend(model_ls, fontsize=10, loc='upper right')\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    # Plot each additional column in its own subplot with SMA smoothing\n",
        "    for i, col in enumerate(additional_cols):\n",
        "        # Calculate the moving average for the additional columns\n",
        "        sma = dataframe_in[col].rolling(window=win_size, min_periods=1, center=True).mean()\n",
        "        axs[i + 1].plot(dataframe_in.index, sma, label=f'{col} SMA {win_per}%', color='orange')\n",
        "        axs[i + 1].set_title(col)\n",
        "        axs[i + 1].set_xlabel('Index')\n",
        "        axs[i + 1].set_ylabel(col)\n",
        "        axs[i + 1].legend(model_ls, fontsize=10, loc='upper right')\n",
        "        axs[i + 1].grid(True)\n",
        "\n",
        "    # Adjust the layout\n",
        "    plt.tight_layout()\n",
        "    plt.show();\n",
        "\n",
        "plot_models_plus(sentiment_zscore_df, model_input_ls, win_per=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5EeJCG4FOUQ"
      },
      "outputs": [],
      "source": [
        "sentiment_df['sentiment-bertmulti'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGoUdgO0eBwQ"
      },
      "outputs": [],
      "source": [
        "pd.Series(sentiment_df['incoherence'] == sentiment_df['max_mistral_diff']).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgkUAbZ4b4fW"
      },
      "outputs": [],
      "source": [
        "pd.Series(sentiment_zscore_df['incoherence'] == sentiment_zscore_df['max_mistral_diff']).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMNdXmzi98Pn"
      },
      "source": [
        "#### Sentiment Distribution by Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESjoJp7iPIb_"
      },
      "outputs": [],
      "source": [
        "model_ls\n",
        "len(model_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15oAUQE8Q7Fj"
      },
      "outputs": [],
      "source": [
        "# Ensure color_ls is long enough by cycling through the colors if needed\n",
        "base_colors = ['red', 'blue', 'green', 'purple', 'orange', 'gray', 'cyan', 'magenta', 'olive', 'black', 'pink', 'brown']\n",
        "color_ls = [color for _, color in zip(range(len(model_ls)), cycle(base_colors))]\n",
        "len(color_ls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoykNIbL5jio"
      },
      "source": [
        "##### KDE ALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNFufTLoRVze"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define your model list\n",
        "# model_ls = ['sentiment-bertmulti', 'sentiment-mistral7b', 'sentiment-textblob', 'sentiment-vader']  # example\n",
        "\n",
        "# Ensure color_ls is long enough by cycling through the colors if needed\n",
        "base_colors = ['red', 'blue', 'green', 'purple', 'orange', 'gray', 'cyan', 'magenta', 'olive', 'black', 'pink', 'brown']\n",
        "color_ls = [color for _, color in zip(range(len(model_ls)), cycle(base_colors))]\n",
        "\n",
        "# Increase font sizes\n",
        "plt.rcParams.update({\n",
        "    'axes.titlesize': 30,\n",
        "    'axes.labelsize': 27,\n",
        "    'xtick.labelsize': 24,\n",
        "    'ytick.labelsize': 24,\n",
        "    'legend.fontsize': 27,\n",
        "    'figure.titlesize': 33\n",
        "})\n",
        "\n",
        "for i, col in enumerate(model_ls):\n",
        "    print(f\"Processing {col}\")\n",
        "    sns.kdeplot(data=sentiment_zscore_df[col], color=color_ls[i], alpha=0.2, linewidth=2, fill=True)\n",
        "\n",
        "# Add vertical dashed red lines with labels\n",
        "plt.axvline(x=-1.0, color='red', linestyle='--', linewidth=4, alpha=0.3)\n",
        "plt.axvline(x=1.0, color='red', linestyle='--', linewidth=4, alpha=0.3)\n",
        "plt.text(-1.0, plt.ylim()[1] * 0.5, '-1.0 Min Sentiment Value', color='red', fontsize=18, rotation=90, ha='left')\n",
        "plt.text(1.0, plt.ylim()[1] * 0.5, '+1.0 Max Sentiment Value', color='red', fontsize=18, rotation=90, ha='left')\n",
        "\n",
        "# Add title and subtitle to the plot\n",
        "plt.title(f\"KDE Sentiment Value Distributions by Model\\nfor All Sentiment Sentence Values\\n{novel_title}\\nZ-Score Normed\", fontsize=26)\n",
        "\n",
        "# Add key to the plot\n",
        "plt.legend(model_ls, fontsize=10, loc='upper right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5H5cPpK5aPc"
      },
      "source": [
        "**[SKIP]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2ifBkkP5pJh"
      },
      "source": [
        "##### KDE Top 10% Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYy1PWbJysfJ"
      },
      "outputs": [],
      "source": [
        "# create KDE smooth distributions\n",
        "\n",
        "ten_percent = int(0.1*sentiment_df.shape[0])\n",
        "\n",
        "\"\"\"\n",
        "if NOVEL_CUR == 'b_tm':\n",
        "  # upto 13 models (eg Beloved by Toni Morrison)\n",
        "  color_ls = ['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink', 'brown', 'gray', 'black', 'cyan', 'magenta', 'olive']\n",
        "elif NOVEL_CUR == 'ttl_vf':\n",
        "  # upto 6 models (eg To The Lighthouse by Virgina Woolf)\n",
        "  color_ls = ['red', 'blue', 'green', 'purple', 'orange', 'gray']\n",
        "else:\n",
        "  print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "\"\"\";\n",
        "\n",
        "color_ls = ['red', 'blue', 'green']\n",
        "\n",
        "for i, col in enumerate(model_ls):\n",
        "    sns.kdeplot(data=sentiment_df.iloc[:ten_percent][col], color=color_ls[i], alpha=0.2, linewidth=2, fill=True)\n",
        "\n",
        "# add vertical dashed red lines with labels\n",
        "plt.axvline(x=-1.0, color='red', linestyle='--', linewidth=4, label='-1.0 Min Sentiment Value')\n",
        "plt.axvline(x=1.0, color='red', linestyle='--', linewidth=4, label='+1.0 Max Sentiment Value')\n",
        "# plt.text(-1.0, 0.1, '-1.0 Min Sentiment Value', color='red', fontsize=12, rotation=90)\n",
        "# plt.text(1.0, 0.1, '+1.0 Max Sentiment Value', color='red', fontsize=12, rotation=90)\n",
        "plt.text(-0.9, 2.5, '-1.0 Min Sentiment Value', color='red', fontsize=12, rotation=90, ha='center')\n",
        "plt.text(1.1, 2.5, '+1.0 Max Sentiment Value', color='red', fontsize=12, rotation=90, ha='center')\n",
        "\n",
        "\n",
        "# add title and subtitle to the plot\n",
        "# plt.suptitle('KDE Sentiment Value Distributions by Model', fontsize=16)\n",
        "plt.title('KDE Sentiment Value Distributions by Model\\nfor Top 10% Incoherent Sentiment Sentence Values\\nTo The Lighthouse by Virginia Woolf', fontsize=16)\n",
        "\n",
        "# add key to the plot\n",
        "plt.legend(model_ls)\n",
        "\n",
        "# show the plot\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOxBzvZD1ora"
      },
      "outputs": [],
      "source": [
        "model_ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UhMoOxr6Acy"
      },
      "source": [
        "##### KDE Top 10% Incoherent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDRPT3Z1tj61"
      },
      "outputs": [],
      "source": [
        "# create KDE smooth distributions\n",
        "\n",
        "\n",
        "if NOVEL_CUR == 'b_tm':\n",
        "  # upto 13 models (eg Beloved by Toni Morrison)\n",
        "  color_ls = ['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink', 'brown', 'gray', 'black', 'cyan', 'magenta', 'olive']\n",
        "elif NOVEL_CUR == 'ttl_vf':\n",
        "  # upto 6 models (eg To The Lighthouse by Virgina Woolf)\n",
        "  color_ls = ['red', 'blue', 'green', 'purple', 'orange', 'gray']\n",
        "else:\n",
        "  print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "for i, col in enumerate(model_ls):\n",
        "    sns.kdeplot(data=thresh_minmax_diff_df[col], color=color_ls[i], alpha=0.2, linewidth=2, fill=True)\n",
        "\n",
        "# add vertical dashed red lines with labels\n",
        "plt.axvline(x=-1.0, color='red', linestyle='--', linewidth=4, label='-1.0 Min Sentiment Value')\n",
        "plt.axvline(x=1.0, color='red', linestyle='--', linewidth=4, label='+1.0 Max Sentiment Value')\n",
        "# plt.text(-1.0, 0.1, '-1.0 Min Sentiment Value', color='red', fontsize=12, rotation=90)\n",
        "# plt.text(1.0, 0.1, '+1.0 Max Sentiment Value', color='red', fontsize=12, rotation=90)\n",
        "plt.text(-0.9, 1.7, '-1.0 Min Sentiment Value', color='red', fontsize=12, rotation=90, ha='center')\n",
        "plt.text(1.1, 1.7, '+1.0 Max Sentiment Value', color='red', fontsize=12, rotation=90, ha='center')\n",
        "\n",
        "\n",
        "# add title and subtitle to the plot\n",
        "# plt.suptitle('KDE Sentiment Value Distributions by Model', fontsize=16)\n",
        "plt.title(f\"KDE Sentiment Value Distributions by Model\\nfor Maximally Incoherent Sentiment Sentence Values\\n{Novel_Title}\", fontsize=16)\n",
        "\n",
        "# add key to the plot\n",
        "plt.legend(model_ls)\n",
        "\n",
        "# show the plot\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF3EJBpN3sxB"
      },
      "outputs": [],
      "source": [
        "sentiment_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQtroBP73_rf"
      },
      "outputs": [],
      "source": [
        "# Convert model sentiment columns to numeric and handle missing values (if any)\n",
        "for model in model_ls:\n",
        "    sentiment_df[model] = pd.to_numeric(sentiment_df[model], errors='coerce')\n",
        "    sentiment_df[model].fillna(0, inplace=True)  # replacing missing values with 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6stbQyHV4kPR"
      },
      "outputs": [],
      "source": [
        "# Convert model sentiment columns to float and handle missing values (if any)\n",
        "for model in model_ls:\n",
        "    sentiment_df[model] = sentiment_df[model].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll-eSGtDhxP5"
      },
      "outputs": [],
      "source": [
        "model_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpYwAllC7V6z"
      },
      "outputs": [],
      "source": [
        "# Sentiment Value Distributions by Model\n",
        "\n",
        "MODEL_CORE_FL = True\n",
        "\n",
        "if MODEL_CORE_FL:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['nlptown', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  elif NOVEL_CUR == 'ttl_vf':\n",
        "    model_subset_ls = ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "else:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['ada_v1p_score','ada_v2p_score','ada_v3p_score','ada_v4p_score','ada_v5p_score','ada_v6p_score','gpt35','gpt4','nlptown','roberta15lg','textblob','vader']\n",
        "  elif NOVEL_CUR == 'ttl_vf':\n",
        "    model_subset_ls = ['nlptown','distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "# Melt the DataFrame to have models and their sentiment scores in two columns\n",
        "# melted_df = pd.melt(sentiment_df, id_vars=['line_no'], value_vars=model_ls,\n",
        "melted_df = pd.melt(sentiment_df, id_vars=['line_no'], value_vars=model_subset_ls,\n",
        "                    var_name='model', value_name='sentiment_score')\n",
        "\n",
        "# Create a grid of histograms\n",
        "g = sns.FacetGrid(melted_df, col=\"model\", col_wrap=3, sharex=True, sharey=True)\n",
        "g.map(plt.hist, 'sentiment_score', bins=10)\n",
        "\n",
        "plt.subplots_adjust(top=0.85)  # Adjust the top to provide space for the title\n",
        "g.fig.suptitle(f'Sentiment Value Distributions by Model\\n{Novel_Title}', fontsize=14)\n",
        "\n",
        "\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C6Lp-pK90_3"
      },
      "source": [
        "#### Culumative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSG-q2OctRQf"
      },
      "outputs": [],
      "source": [
        "# DATA show a Pandas DataFrame where each row is a line_no\n",
        "#   where sentiment values between -1.0-1.0 are recorded for 6 models in ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "#   and difference is the max difference between any two of the 6 models.\n",
        "\n",
        "# Create a beautiful seaborn line chart with 6 lines for each model with x-axis running from line_no in range(0,3700)\n",
        "# and the y-axis showing a cumulative amount of times each model was either the min or max sentiment value in it's row.\n",
        "# Add a key, gridlines alpha=0.3, and a title=\"Cumulative count of extreme sentiment values\\nTo the Lighthouse by Virginia Woolf\"\n",
        "\n",
        "# Initialize DataFrame to hold cumulative counts\n",
        "cumulative_df = pd.DataFrame(columns=model_ls)\n",
        "\n",
        "# Initialize counters for each model\n",
        "counters = dict.fromkeys(model_ls, 0)\n",
        "\n",
        "# Iterate over DataFrame rows\n",
        "# for i, row in sentiment_df.iterrows():\n",
        "for i, row in tqdm(sentiment_df.iterrows(), total=len(sentiment_df)):\n",
        "    # TypeError: reduction operation 'argmin' not allowed for this dtype\n",
        "    # min_model = row[model_ls].idxmin()\n",
        "    # max_model = row[model_ls].idxmax()\n",
        "\n",
        "    min_model = model_ls[np.argmin(row[model_ls].values)]\n",
        "    max_model = model_ls[np.argmax(row[model_ls].values)]\n",
        "\n",
        "    counters[min_model] += 1\n",
        "    counters[max_model] += 1\n",
        "\n",
        "    # Add current counters to cumulative DataFrame\n",
        "    cumulative_df = cumulative_df.append(counters, ignore_index=True)\n",
        "\n",
        "# Set line_no as index for cumulative_df\n",
        "cumulative_df.index = sentiment_df['line_no']\n",
        "\n",
        "# Plot cumulative counts\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.lineplot(data=cumulative_df)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.title(\"Cumulative count of extreme sentiment values\\nTo the Lighthouse by Virginia Woolf\")\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aULPuQmF64IR"
      },
      "outputs": [],
      "source": [
        "# Models for which sentiment values are recorded\n",
        "model_subset_ls = model_ls # ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "\n",
        "# Create an empty DataFrame with columns for each model. This DataFrame will be used to hold the cumulative counts.\n",
        "cumulative_df = pd.DataFrame(columns=model_subset_ls)\n",
        "\n",
        "# Initialize a counter for each model to zero. This counter will be used to track the number of times\n",
        "# each model's sentiment value is the minimum or maximum in a row.\n",
        "counters = dict.fromkeys(model_subset_ls, 0)\n",
        "\n",
        "# Iterate over the rows of the sentiment DataFrame\n",
        "for i, row in tqdm(sentiment_df.iterrows(), total=len(sentiment_df)):\n",
        "    # Identify the model with the minimum and maximum sentiment value for the current row\n",
        "    min_model = model_subset_ls[np.argmin(row[model_subset_ls].values)]\n",
        "    max_model = model_subset_ls[np.argmax(row[model_subset_ls].values)]\n",
        "\n",
        "    # Increment the counter for the models with the minimum and maximum sentiment values\n",
        "    counters[min_model] += 1\n",
        "    counters[max_model] += 1\n",
        "\n",
        "    # Add the current values of the counters to the cumulative DataFrame\n",
        "    cumulative_df = cumulative_df.append(counters, ignore_index=True)\n",
        "\n",
        "# Set the line_no from the sentiment DataFrame as the index for the cumulative DataFrame\n",
        "cumulative_df.index = sentiment_df['line_no']\n",
        "\n",
        "# Plot the cumulative counts of the extreme sentiment values as a line chart.\n",
        "# Each line in the chart represents one of the models.\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.lineplot(data=cumulative_df)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.title(\"Cumulative count of extreme sentiment values\\nTo the Lighthouse by Virginia Woolf\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21B5hpn39yNm"
      },
      "source": [
        "#### Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URwPbkrtrG0c"
      },
      "outputs": [],
      "source": [
        "model_a = 'gpt35'\n",
        "model_b = 'gpt4'\n",
        "diff_threshold_min = 1.99\n",
        "\n",
        "gpt_ct = 0\n",
        "for idx, row in thresh_minmax_diff_df.iterrows():\n",
        "    if row['difference'] >= diff_threshold_min:  # Adjusted condition\n",
        "        print(f\"Example #{gpt_ct}: {row['text_raw']}\")\n",
        "        print(f\"     {model_a}: {row[model_a]}\")\n",
        "        print(f\"     {model_b}:  {row[model_b]}\")\n",
        "        gpt_ct += 1\n",
        "\n",
        "print(f\"TOTAL {gpt_ct} examples where the difference column is greater or equal to {diff_threshold_min} out of {len(thresh_minmax_diff_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxy7O60YmmjB"
      },
      "outputs": [],
      "source": [
        "model_a = 'gpt35'\n",
        "model_b = 'gpt4'\n",
        "diff_threshold_min = 1.99\n",
        "\n",
        "gpt_ct = 0\n",
        "for idx, row in thresh_minmax_diff_df.iterrows():\n",
        "    print(f\"row: {row}\")\n",
        "    if np.abs(row[model_a] - row[model_b]) >= diff_threshold_min:\n",
        "        print(f\"Example #{gpt_ct}: {row['text_raw']}\")\n",
        "        print(f\"     {model_a}: {row[model_a]}\")\n",
        "        print(f\"     {model_b}:  {row[model_b]}\\n\")\n",
        "        gpt_ct += 1\n",
        "\n",
        "print(f\"TOTAL {gpt_ct} examples where {model_a} and {model_b} disagreed out of {len(thresh_minmax_diff_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uydhq3cPjCXk"
      },
      "outputs": [],
      "source": [
        "%whos DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0svay5XkLOD"
      },
      "outputs": [],
      "source": [
        "# TODO: Bug in Beloved (many cols) vs TTL\n",
        "\n",
        "model_minmax_diff_df    .head()\n",
        "model_minmax_diff_df    .info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5EJapLUk1Be"
      },
      "outputs": [],
      "source": [
        "np.abs(model_minmax_diff_df.iloc[10]['gpt35'] - model_minmax_diff_df.iloc[10]['vader'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy4yOrTxlD-C"
      },
      "outputs": [],
      "source": [
        "model_minmax_diff_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTFoGLzllasc"
      },
      "outputs": [],
      "source": [
        "thresh_minmax_diff_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd9_QC7NmHZN"
      },
      "outputs": [],
      "source": [
        "text_minmax_diff_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhKXdwEDemJi"
      },
      "outputs": [],
      "source": [
        "# Find the sentences where model_a and model_b differ >= diff_threshold_min\n",
        "\n",
        "model_a = 'gpt35'\n",
        "model_b = 'gpt4'\n",
        "diff_threshold_min = 1.7\n",
        "\n",
        "gpt_ct = 0\n",
        "# for idx, aline_no in enumerate(thresh_minmax_diff_df):\n",
        "for idx, aline_no in enumerate(text_minmax_diff_df['difference']):\n",
        "  print(type(aline_no))\n",
        "  # print(f\"{sentiment_df.iloc[aline_no]['text_raw']}\\n\")\n",
        "  if np.abs(model_minmax_diff_df.iloc[aline_no][model_a] - model_minmax_diff_df.iloc[aline_no][model_b]) >= diff_threshold_min:\n",
        "    print(f\"Example #{gpt_ct}: {model_minmax_diff_df.iloc[aline_no]['text_raw']}\")\n",
        "    print(f\"     {model_a}: {model_minmax_diff_df.iloc[aline_no][model_a]}\")\n",
        "    print(f\"     {model_b}:  {model_minmax_diff_df.iloc[aline_no][model_b]}\")\n",
        "    gpt_ct += 1\n",
        "\n",
        "print(f\"TOTAL {gpt_ct} examples where {model_a} and {model_b} disagreed beyond threshold={diff_threshold} out of {len(model_minmax_diff_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Yx7Tu9Sk_OJ"
      },
      "outputs": [],
      "source": [
        "%whos DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5W2UrQ9fYHZ"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def compute_model_diffs(df, model_ls):\n",
        "    # Create all combinations of models\n",
        "    comb = combinations(model_ls, 2)\n",
        "\n",
        "    # For each combination of models, compute the absolute difference\n",
        "    for pair in list(comb):\n",
        "        model_a, model_b = pair\n",
        "        df[f'diff_{model_a}_{model_b}'] = np.abs(df[model_a] - df[model_b])\n",
        "\n",
        "    return df\n",
        "\n",
        "# model_ls = ['nlptown', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "model_diff_df = compute_model_diffs(model_minmax_diff_df, model_ls)\n",
        "\n",
        "model_diff_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN_KqiwulNnT"
      },
      "outputs": [],
      "source": [
        "%whos DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lirGmkBn-W11"
      },
      "outputs": [],
      "source": [
        "model_minmax_diff_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVWY3ytD_bvV"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCVD6qwaUKT0"
      },
      "outputs": [],
      "source": [
        "# UPDATE 20240526 Heatmap\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = sentiment_df[model_ls].corr()\n",
        "\n",
        "# Set font size for all text elements\n",
        "font_size = 12\n",
        "\n",
        "# Plot the heatmap of the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', xticklabels=model_ls, yticklabels=model_ls,\n",
        "            annot_kws={\"size\": font_size}, cbar_kws={\"ticks\": np.linspace(-1, 1, 11), \"label\": \"Correlation\"})\n",
        "plt.title(f\"Correlation Between Sentiment Scores by Model\\n{novel_title}\", fontsize=font_size)\n",
        "plt.xlabel(\"Models\", fontsize=font_size)\n",
        "plt.ylabel(\"Models\", fontsize=font_size)\n",
        "plt.xticks(fontsize=font_size)\n",
        "plt.yticks(fontsize=font_size)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cgarP8LmbeL"
      },
      "outputs": [],
      "source": [
        "model_subset_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ccgze1o_bqC"
      },
      "outputs": [],
      "source": [
        "# Heatmap of min/max extreme model combination\n",
        "\n",
        "MODEL_CORE_FL = True\n",
        "\n",
        "if MODEL_CORE_FL:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['nlptown', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  elif NOVEL_CUR == 'ttl_vwoolf ':\n",
        "    model_subset_ls = ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "else:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['ada_v1p_score','ada_v2p_score','ada_v3p_score','ada_v4p_score','ada_v5p_score','ada_v6p_score','gpt35','gpt4','nlptown','roberta15lg','textblob','vader']\n",
        "  elif NOVEL_CUR == 'ttl_vwoolf ':\n",
        "    model_subset_ls = ['nlptown','distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "\n",
        "\n",
        "# Initialize a square DataFrame with 0s to store the counts for each pair of models\n",
        "# heatmap_df = pd.DataFrame(np.zeros((6, 6)), index=model_ls, columns=model_ls)\n",
        "heatmap_df = pd.DataFrame(np.zeros((6, 6)), index=model_subset_ls, columns=model_subset_ls)\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for i, row in sentiment_df.iterrows():\n",
        "    # Get the model with the minimum and maximum sentiment score\n",
        "    # min_values = row[model_ls][row[model_ls] == row[model_ls].min()]\n",
        "    # max_values = row[model_ls][row[model_ls] == row[model_ls].max()]\n",
        "    min_values = row[model_subset_ls][row[model_subset_ls] == row[model_subset_ls].min()]\n",
        "    max_values = row[model_subset_ls][row[model_subset_ls] == row[model_subset_ls].max()]\n",
        "\n",
        "    # If there are ties, randomly choose one model\n",
        "    min_model = random.choice(min_values.index)\n",
        "    max_model = random.choice(max_values.index)\n",
        "\n",
        "    # Update the count for the pair of models\n",
        "    heatmap_df.loc[min_model, max_model] += 1\n",
        "    heatmap_df.loc[max_model, min_model] += 1\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(heatmap_df, annot=True, fmt=\".0f\", cmap='YlGnBu')\n",
        "plt.title(f\"Model Pairs with Extreme Sentiment Scores\\n{novel_title}\")\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJtncnCLFSau"
      },
      "outputs": [],
      "source": [
        "sentiment_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKkhZM12Ujb4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Heatmap of min/max extreme model combination\n",
        "\n",
        "MODEL_CORE_FL = True\n",
        "\n",
        "if MODEL_CORE_FL:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['nlptown', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  elif NOVEL_CUR == 'ttl_vwoolf ':\n",
        "    model_subset_ls = ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "else:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['ada_v1p_score','ada_v2p_score','ada_v3p_score','ada_v4p_score','ada_v5p_score','ada_v6p_score','gpt35','gpt4','nlptown','roberta15lg','textblob','vader']\n",
        "  elif NOVEL_CUR == 'ttl_vwoolf ':\n",
        "    model_subset_ls = ['nlptown','distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "# Initialize a square DataFrame with 0s to store the counts for each pair of models\n",
        "heatmap_df = pd.DataFrame(np.zeros((6, 6)), index=model_subset_ls, columns=model_subset_ls)\n",
        "# heatmap_df = pd.DataFrame(np.zeros((6, 6)), index=model_subset_ls, columns=model_subset_ls)\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for i, row in sentiment_df.iterrows():\n",
        "    # Get the model with the minimum and maximum sentiment score\n",
        "    # min_values = row[model_ls][row[model_ls] == row[model_ls].min()]\n",
        "    # max_values = row[model_ls][row[model_ls] == row[model_ls].max()]\n",
        "    min_values = row[model_subset_ls][row[model_subset_ls] == row[model_subset_ls].min()]\n",
        "    max_values = row[model_subset_ls][row[model_subset_ls] == row[model_subset_ls].max()]\n",
        "\n",
        "    # If there are ties, randomly choose one model\n",
        "    min_model = random.choice(min_values.index)\n",
        "    max_model = random.choice(max_values.index)\n",
        "\n",
        "    # Update the count for the pair of models\n",
        "    heatmap_df.loc[min_model, max_model] += 1\n",
        "    heatmap_df.loc[max_model, min_model] += 1\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(heatmap_df, annot=True, fmt=\".0f\", cmap='YlGnBu')\n",
        "plt.title(f\"Model Pairs with Extreme Sentiment Scores\\n{Novel_Title}\")\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He_OmrO8BGIb"
      },
      "outputs": [],
      "source": [
        "# create six KDE smooth distributions\n",
        "\n",
        "if NOVEL_CUR == 'b_tm':\n",
        "  # upto 13 models (eg Beloved by Toni Morrison)\n",
        "  color_ls = ['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink', 'brown', 'gray', 'black', 'cyan', 'magenta', 'olive']\n",
        "elif NOVEL_CUR == 'ttl_vf':\n",
        "  # upto 6 models (eg To The Lighthouse by Virgina Woolf)\n",
        "  color_ls = ['red', 'blue', 'green', 'purple', 'orange', 'gray']\n",
        "else:\n",
        "  print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "MODEL_CORE_FL = True\n",
        "\n",
        "if MODEL_CORE_FL:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['nlptown', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  elif NOVEL_CUR == 'ttl_vf':\n",
        "    model_subset_ls = ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "else:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['ada_v1p_score','ada_v2p_score','ada_v3p_score','ada_v4p_score','ada_v5p_score','ada_v6p_score','gpt35','gpt4','nlptown','roberta15lg','textblob','vader']\n",
        "  elif NOVEL_CUR == 'ttl_vf':\n",
        "    model_subset_ls = ['nlptown','distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "\n",
        "\n",
        "ten_percent = int(0.1*model_minmax_diff_df.shape[0])\n",
        "\n",
        "for i, col in enumerate(model_subset_ls):\n",
        "    sns.kdeplot(data=model_minmax_diff_df.iloc[:ten_percent][col], color=color_ls[i], alpha=0.2, linewidth=2, fill=True)\n",
        "\n",
        "# add vertical dashed red lines with labels\n",
        "plt.axvline(x=-1.0, color='red', linestyle='--', linewidth=4, label='-1.0 Min Sentiment Value')\n",
        "plt.axvline(x=1.0, color='red', linestyle='--', linewidth=4, label='+1.0 Max Sentiment Value')\n",
        "# plt.text(-1.0, 0.1, '-1.0 Min Sentiment Value', color='red', fontsize=12, rotation=90)\n",
        "# plt.text(1.0, 0.1, '+1.0 Max Sentiment Value', color='red', fontsize=12, rotation=90)\n",
        "plt.text(-0.95, 1.5, '-1.0 Min Sentiment Value', color='red', fontsize=12, rotation=90, ha='center')\n",
        "plt.text(1.05, 1.5, '+1.0 Max Sentiment Value', color='red', fontsize=12, rotation=90, ha='center')\n",
        "\n",
        "\n",
        "# add title and subtitle to the plot\n",
        "# plt.suptitle('KDE Sentiment Value Distributions by Model', fontsize=16)\n",
        "plt.title('KDE Sentiment Value Distributions by Model\\nfor Top 10% Incoherent Sentiment Sentence Values\\nTo The Lighthouse by Virginia Woolf', fontsize=16)\n",
        "\n",
        "# add key to the plot\n",
        "plt.legend(model_subset_ls)\n",
        "\n",
        "# show the plot\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95b3jxDVAvgk"
      },
      "outputs": [],
      "source": [
        "# Heatmap of min/max extreme model combination\n",
        "\n",
        "MODEL_CORE_FL = True\n",
        "\n",
        "if MODEL_CORE_FL:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['nlptown', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  elif NOVEL_CUR == 'ttl_vf':\n",
        "    model_subset_ls = ['distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "else:\n",
        "  if NOVEL_CUR == 'b_tm':\n",
        "    model_subset_ls = ['ada_v1p_score','ada_v2p_score','ada_v3p_score','ada_v4p_score','ada_v5p_score','ada_v6p_score','gpt35','gpt4','nlptown','roberta15lg','textblob','vader']\n",
        "  elif NOVEL_CUR == 'ttl_vf':\n",
        "    model_subset_ls = ['nlptown','distilbert', 'gpt35', 'gpt4', 'roberta15lg', 'textblob', 'vader']\n",
        "  else:\n",
        "    print(f\"ERROR: NOVEL_CUR={NOVEL_CUR} does not have a color_ls assigned.\")\n",
        "\n",
        "cutoff_per = 10\n",
        "cutoff_idx = int((cutoff_per/100)*model_minmax_diff_df.shape[0])\n",
        "cutoff_df = model_minmax_diff_df.iloc[:cutoff_idx]\n",
        "\n",
        "# Initialize a square DataFrame with 0s to store the counts for each pair of models\n",
        "# heatmap_df = pd.DataFrame(np.zeros((6, 6)), index=model_ls, columns=model_ls)\n",
        "heatmap_df = pd.DataFrame(np.zeros((6, 6)), index=model_subset_ls, columns=model_subset_ls)\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for i, row in cutoff_df.iterrows():\n",
        "    # Get the model with the minimum and maximum sentiment score\n",
        "    # min_values = row[model_ls][row[model_ls] == row[model_ls].min()]\n",
        "    # max_values = row[model_ls][row[model_ls] == row[model_ls].max()]\n",
        "    min_values = row[model_subset_ls][row[model_subset_ls] == row[model_subset_ls].min()]\n",
        "    max_values = row[model_subset_ls][row[model_subset_ls] == row[model_subset_ls].max()]\n",
        "\n",
        "    # If there are ties, randomly choose one model\n",
        "    min_model = random.choice(min_values.index)\n",
        "    max_model = random.choice(max_values.index)\n",
        "\n",
        "    # Update the count for the pair of models\n",
        "    heatmap_df.loc[min_model, max_model] += 1\n",
        "    heatmap_df.loc[max_model, min_model] += 1\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(heatmap_df, annot=True, fmt=\".0f\", cmap='YlGnBu')\n",
        "plt.title(f\"Model Pairs with Extreme {cutoff_per}% Divergent Sentiment Scores\\n{Novel_Title}\")\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6DrbjrN68Dg"
      },
      "source": [
        "### Plot StandardScaler Normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiyhwXLlQkVY"
      },
      "outputs": [],
      "source": [
        "# Compute the mean of each raw Sentiment Timeseries and adjust to [-1.0, 1.0] Range\n",
        "\n",
        "model_samelen_adj_mean_dt = {}\n",
        "\n",
        "for amodel in model_ls:\n",
        "  amodel_min = sentiment_df[amodel].min()\n",
        "  amodel_max = sentiment_df[amodel].max()\n",
        "  amodel_range = amodel_max - amodel_min\n",
        "  amodel_raw_mean = sentiment_df[amodel].mean()\n",
        "\n",
        "  if amodel_range > 2.0:\n",
        "    model_samelen_adj_mean_dt[amodel] = (amodel_raw_mean + amodel_min)/(amodel_max - amodel_min)*2 + -1.0\n",
        "  elif amodel_range < 1.1:\n",
        "    model_samelen_adj_mean_dt[amodel] = (amodel_raw_mean + amodel_min)/(amodel_max - amodel_min)*2 + -1.0\n",
        "  else:\n",
        "    model_samelen_adj_mean_dt[amodel] = amodel_raw_mean\n",
        "\n",
        "  print(f'Model: {amodel}\\n  Raw Mean: {amodel_raw_mean}\\n  Adj Mean: {model_samelen_adj_mean_dt[amodel]}\\n  Min: {amodel_min}\\n  Max: {amodel_max}\\n  Range: {amodel_range}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpzGoUFAren8"
      },
      "outputs": [],
      "source": [
        "sentiment_all_norm_df.head()\n",
        "sentiment_all_norm_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsWdlG9Do9rY"
      },
      "outputs": [],
      "source": [
        "# Normalize Timeseries with StandardScaler (u=0, sd=+/- 1)\n",
        "model_all_ls = model_ls + ['distilbert']\n",
        "\n",
        "# sentiment_all_norm_df = pd.DataFrame()\n",
        "sentiment_all_norm_df = sentiment_df[['line_no','text_raw','text_clean']].copy(deep=True)\n",
        "sentiment_all_norm_df[model_all_ls] = StandardScaler().fit_transform(sentiment_df[model_all_ls])\n",
        "sentiment_all_norm_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvdjGjWHCGqE"
      },
      "outputs": [],
      "source": [
        "# UPDATE 20240526\n",
        "# _ = sentiment_df[model_ls].rolling(win_size, min_periods=1, center=True).mean().plot(grid=True)\n",
        "\n",
        "# Parameters\n",
        "win_per = 10  # Window size percent\n",
        "win_size = int((win_per / 100) * sentiment_df.shape[0])  # Calculate window size\n",
        "if win_size % 2 == 0:\n",
        "    win_size += 1  # Ensure win_size is odd as required by S-G Algo\n",
        "\n",
        "# Compute the rolling mean and center around mean=0\n",
        "rolling_mean_centered = sentiment_df[model_ls].rolling(win_size, min_periods=1, center=True).mean()\n",
        "rolling_mean_centered = rolling_mean_centered - rolling_mean_centered.mean()\n",
        "\n",
        "# Plot the centered rolling means\n",
        "font_size = 12  # Uniform font size for all elements\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "rolling_mean_centered.plot(grid=True, ax=plt.gca())\n",
        "plt.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.title(f\"Centered Rolling Mean of Sentiment Scores\\n{novel_title}\", fontsize=font_size)\n",
        "plt.xlabel(\"Index\", fontsize=font_size)\n",
        "plt.ylabel(\"Sentiment\", fontsize=font_size)\n",
        "plt.xticks(fontsize=font_size)\n",
        "plt.yticks(fontsize=font_size)\n",
        "plt.legend(fontsize=font_size)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGnpxJIVoMVO"
      },
      "outputs": [],
      "source": [
        "# Plot Normalized Time Series to same mean\n",
        "\n",
        "# ax = sentiment_all_norm_df[model_all_ls].rolling(win_size, center=True).mean().plot(grid=True, colormap='Dark2', lw=2)\n",
        "ax = sentiment_all_norm_df[model_ls].rolling(win_size, center=True).mean().plot(grid=True, colormap='Dark2', lw=2)\n",
        "\n",
        "ax.title.set_text(f'Sentiment Analysis \\n {novel_title} \\n Normalization: Standard Scaler')\n",
        "\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7x7RUc8m5xT"
      },
      "outputs": [],
      "source": [
        "NOVEL_LS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lapYe3gVc_M"
      },
      "outputs": [],
      "source": [
        "if NOVEL_CUR == 'b_tm':\n",
        "  model_gpt_ls = ['gpt35','gpt4','ada_v1p_score','ada_v2p_score','ada_v3p_score','ada_v4p_score','ada_v5p_score','ada_v6p_score']\n",
        "\n",
        "  # Plot subset of Normalized Timeseries to same mean\n",
        "\n",
        "  ax = sentiment_all_norm_df[model_gpt_ls].rolling(win_size, center=True).mean().plot(grid=True, colormap='Dark2', lw=3)\n",
        "  ax.title.set_text(f'Sentiment Analysis \\n {Novel_Title} \\n Normalization: Standard Scaler')\n",
        "\n",
        "  plt.show();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEpUbhMnWFph"
      },
      "outputs": [],
      "source": [
        "model_main_ls = ['vader', 'textblob', 'nlptown', 'roberta15lg', 'gpt35', 'gpt4'] # , 'distilbert']\n",
        "model_main_ls = model_subset_ls\n",
        "\n",
        "# Plot subset of Normalized Timeseries to same mean\n",
        "\n",
        "ax = sentiment_all_norm_df[model_main_ls].rolling(win_size, center=True).mean().plot(grid=True, colormap='Dark2', lw=2)\n",
        "ax.title.set_text(f'Sentiment Analysis \\n {novel_title} \\n Normalization: Standard Scaler')\n",
        "\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mDNUJeIqW1k"
      },
      "source": [
        "### Secondary SG-Smoothing\n",
        "\n",
        "Savitzky-Golay filtering. Savitzky-Golay filtering is a smoothing method that can effectively preserve important features, such as peaks and valleys, while reducing noise.\n",
        "\n",
        "Savitzky-Golay filtering fits a polynomial to small subsets of data points within a sliding window and uses the polynomial coefficients to estimate the smoothed values. This technique can provide better preservation of local features compared to simple moving average smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAkpZoH_qoAr"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import savgol_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jpm8LfO0q1Rj"
      },
      "outputs": [],
      "source": [
        "%whos DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQQYsW_wrw6Y"
      },
      "outputs": [],
      "source": [
        "sentiment_zscore_df.head()\n",
        "sentiment_zscore_df.info()\n",
        "sentiment_zscore_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCNsufkNko-C"
      },
      "outputs": [],
      "source": [
        "def plot_sma_sv(dataframe_in, model_cols, win_per=10, polynomial_order=3):\n",
        "    # Create an empty DataFrame to store the smoothed values\n",
        "    sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "    # Calculate the window size for the moving average (win_per% of the data length)\n",
        "    win_size = max(1, int((win_per / 100) * dataframe_in.shape[0]))\n",
        "    if win_size % 2 == 0:\n",
        "        win_size += 1  # Ensure window size is odd for centering\n",
        "\n",
        "    # Apply SMA and Savitzky-Golay filtering to each model in model_cols\n",
        "    for amodel in model_cols:\n",
        "        print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "        # Apply savgol_filter to the rolling mean of the normalized sentiment scores\n",
        "        rolling_mean = dataframe_in[amodel].rolling(window=win_size, min_periods=1, center=True).mean()\n",
        "        smoothed_values = savgol_filter(rolling_mean, win_size, polynomial_order)\n",
        "        sentiment_sg_df[amodel] = smoothed_values\n",
        "\n",
        "        # Plot the smoothed sentiment scores with a key\n",
        "        sentiment_sg_df[amodel].plot(label=amodel)\n",
        "\n",
        "    # Set the title of the plot\n",
        "    plt.title(f\"Sentiment Analysis\\n{novel_title}\\nZ-Score > 10% SMA > SG 10%\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(\"Smoothed Values\")\n",
        "    plt.legend(model_ls, fontsize=10, loc='upper right')  # Add a legend to the plot\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show();\n",
        "\n",
        "plot_sma_sv(sentiment_zscore_df, model_input_ls, win_per=10, polynomial_order=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNDzOhWquCDm"
      },
      "outputs": [],
      "source": [
        "#Apply sequentially SMA 10% then Savitzky-Golay filtering\n",
        "\n",
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "# Assuming your time series is stored in the variable 'data'\n",
        "win_per = 10 # Window size percent\n",
        "win_size = int((win_per/100)*sentiment_zscore_df.shape[0])  # Adjust the window size as needed\n",
        "# Ensure win_size is odd as required by S-G Algo\n",
        "if win_size % 2 == 0:\n",
        "  # If not, add 1\n",
        "  win_size += 1\n",
        "\n",
        "polynomial_order = 3  # Adjust the polynomial order as needed\n",
        "\n",
        "for amodel in model_subset_ls:\n",
        "  print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "  # Apply savgol_filter to the rolling mean of the normalized sentiment scores\n",
        "  sentiment_sg_df[amodel] = savgol_filter(sentiment_zscore_df[amodel].rolling(win_size, min_periods=1, center=True).mean(), win_size, polynomial_order)\n",
        "\n",
        "  # Set the title of the plot\n",
        "  title = f\"Sentiment Analysis: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{novel_title}\"\n",
        "\n",
        "  # Plot the smoothed sentiment scores with a key\n",
        "  _ = sentiment_sg_df[amodel].plot(title=title, label=amodel)\n",
        "  plt.legend(); # Add a legend to the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmtjzbuVnE8s"
      },
      "source": [
        "### Pearson Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqmyI3ZVnHvl"
      },
      "outputs": [],
      "source": [
        "def make_pearson_heat(dataframe_in, model_cols, novel_title):\n",
        "    # Calculate the Pearson correlation matrix\n",
        "    correlation_matrix = dataframe_in[model_cols].corr(method='pearson')\n",
        "\n",
        "    # Plot the heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
        "    plt.title(f\"Pearson Correlation Heatmap\\n{novel_title}\\nZ-Score Norm > 10% SMA > 10% S-G Smoothed\")\n",
        "    plt.show()\n",
        "\n",
        "make_pearson_heat(sentiment_zscore_df, model_input_ls, novel_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8RNF9tQnxhL"
      },
      "source": [
        "**[SKIP]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL5ArfT9nHrA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNbpJF1Zwlpl"
      },
      "outputs": [],
      "source": [
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "win_per = 10  # Window size percent\n",
        "win_size = int((win_per / 100) * sentiment_all_norm_df.shape[0])  # Adjust the window size as needed\n",
        "# Ensure win_size is odd as required by S-G Algo\n",
        "if win_size % 2 == 0:\n",
        "    # If not, add 1\n",
        "    win_size += 1\n",
        "\n",
        "polynomial_order = 3  # Adjust the polynomial order as needed\n",
        "\n",
        "for amodel in model_subset_ls:\n",
        "    print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "    # Apply savgol_filter to the rolling mean of the normalized sentiment scores\n",
        "    sentiment_sg_df[amodel] = savgol_filter(\n",
        "        sentiment_all_norm_df[amodel].rolling(win_size, min_periods=1, center=True).mean(),\n",
        "        win_size,\n",
        "        polynomial_order\n",
        "    )\n",
        "\n",
        "# Set the title of the plot\n",
        "title = f\"Euclidean Distance Between Sentiment Time Series: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{Novel_Title}\"\n",
        "\n",
        "# Heatmap of Euclidean Distance of Norm/SMA/SG smoothed model time series\n",
        "\n",
        "# Calculate the pairwise Euclidean distance matrix using the smoothed data\n",
        "euclidean_distance_matrix = np.linalg.norm(\n",
        "    sentiment_sg_df.values[:, :, np.newaxis] - sentiment_sg_df.values[:, np.newaxis, :],\n",
        "    axis=0\n",
        ")\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "sns.heatmap(euclidean_distance_matrix, cmap='YlGnBu', xticklabels=sentiment_sg_df.columns,\n",
        "            yticklabels=sentiment_sg_df.columns)\n",
        "plt.title(title)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNgHFZUkxwN2"
      },
      "source": [
        "**[SKIP] To next Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C82VfmgwwjWA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "win_per = 10  # Window size percent\n",
        "win_size = int((win_per / 100) * sentiment_all_norm_df.shape[0])  # Adjust the window size as needed\n",
        "# Ensure win_size is odd as required by S-G Algo\n",
        "if win_size % 2 == 0:\n",
        "    # If not, add 1\n",
        "    win_size += 1\n",
        "\n",
        "polynomial_order = 3  # Adjust the polynomial order as needed\n",
        "\n",
        "for amodel in model_subset_ls:\n",
        "    print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "    # Apply savgol_filter to the rolling mean of the normalized sentiment scores\n",
        "    sentiment_sg_df[amodel] = savgol_filter(\n",
        "        sentiment_all_norm_df[amodel].rolling(win_size, min_periods=1, center=True).mean(),\n",
        "        win_size,\n",
        "        polynomial_order\n",
        "    )\n",
        "\n",
        "    # Set the title of the plot\n",
        "    title = f\"Sentiment Analysis: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{Novel_Title}\"\n",
        "\n",
        "    # Plot the smoothed sentiment scores with a key\n",
        "    sentiment_sg_df[amodel].plot(title=title, label=amodel)\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Heatmap of Euclidean Distance of Norm/SMA/SG smoothed model time series\n",
        "\n",
        "# Calculate the pairwise Euclidean distance matrix using the smoothed data\n",
        "euclidean_distance_matrix = np.linalg.norm(\n",
        "    sentiment_sg_df.values[:, :, np.newaxis] - sentiment_sg_df.values[:, np.newaxis, :],\n",
        "    axis=0\n",
        ")\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "sns.heatmap(euclidean_distance_matrix, xticklabels=sentiment_sg_df.columns, yticklabels=sentiment_sg_df.columns)\n",
        "plt.title(\"Euclidean distance between all time series in sentiment_sg_df\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVNUbTFjwDmf"
      },
      "outputs": [],
      "source": [
        "# Heatmap of Euclidean Distance of Norm/SMA/SG smoothed model time series\n",
        "\n",
        "# Calculate the pairwise Euclidean distance matrix using the smoothed data\n",
        "euclidean_distance_matrix = np.linalg.norm(sentiment_sg_df[:, np.newaxis] - smoothed_data, axis=2)\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "sns.heatmap(euclidean_distance_matrix, xticklabels=sentiment_dg_df.columns, yticklabels=sentiment_dg_df.columns)\n",
        "plt.title(\"Euclidean distance between all time series in sentiment_dg_df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjBA6ysmEZDM"
      },
      "outputs": [],
      "source": [
        "# UPDATE 20240526 Efficient S-G\n",
        "\n",
        "# Parameters\n",
        "win_per = 10  # Window size percent\n",
        "win_size = int((win_per / 100) * sentiment_df.shape[0])  # Calculate window size\n",
        "if win_size % 2 == 0:\n",
        "    win_size += 1  # Ensure win_size is odd as required by S-G Algo\n",
        "polynomial_order = 3  # Polynomial order for S-G filter\n",
        "\n",
        "# Initialize DataFrame for smoothed data\n",
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "# Apply filters\n",
        "for amodel in model_ls:\n",
        "    print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "    # Apply rolling mean\n",
        "    rolling_mean = sentiment_df[amodel].rolling(win_size, min_periods=1, center=True).mean()\n",
        "\n",
        "    # Apply Savitzky-Golay filter\n",
        "    smoothed = savgol_filter(rolling_mean, win_size, polynomial_order)\n",
        "\n",
        "    # Center the smoothed data around mean = 0\n",
        "    smoothed_centered = smoothed - np.mean(smoothed)\n",
        "\n",
        "    sentiment_sg_df[amodel] = smoothed_centered\n",
        "\n",
        "# Check the DataFrame after processing\n",
        "print(\"Smoothed and Centered DataFrame Head:\")\n",
        "print(sentiment_sg_df.head())\n",
        "\n",
        "# Plot the smoothed and centered sentiment scores\n",
        "plt.figure(figsize=(12, 8))\n",
        "title = f\"Sentiment Analysis: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{novel_title}\"\n",
        "plt.title(title, fontsize=12)\n",
        "for amodel in model_ls:\n",
        "    plt.plot(sentiment_sg_df[amodel], label=amodel)\n",
        "plt.legend(fontsize=8)\n",
        "plt.xlabel(\"Index\", fontsize=7)\n",
        "plt.ylabel(\"Sentiment\", fontsize=7)\n",
        "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.show();\n",
        "\n",
        "\"\"\"\n",
        "# Calculate the pairwise Euclidean distance matrix\n",
        "# Optimize by using efficient NumPy operations\n",
        "sentiment_sg_values = sentiment_sg_df.values\n",
        "euclidean_distance_matrix = np.sqrt(((sentiment_sg_values[:, np.newaxis, :] - sentiment_sg_values[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
        "\n",
        "# Check the distance matrix dimensions and a sample\n",
        "print(\"Euclidean Distance Matrix Shape:\", euclidean_distance_matrix.shape)\n",
        "print(\"Euclidean Distance Matrix Sample:\")\n",
        "print(euclidean_distance_matrix[:5, :5])\n",
        "\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(euclidean_distance_matrix, xticklabels=model_ls, yticklabels=model_ls, cmap='viridis', annot=True, fmt=\".2f\", annot_kws={\"size\": 8})\n",
        "plt.title(\"Euclidean Distance Between All Time Series in Sentiment SG DF\", fontsize=12)\n",
        "plt.xlabel(\"Models\", fontsize=10)\n",
        "plt.ylabel(\"Models\", fontsize=10)\n",
        "plt.xticks(fontsize=8)\n",
        "plt.yticks(fontsize=8)\n",
        "plt.show()\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8UqeKAyC2z_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Parameters\n",
        "win_per = 10  # Window size percent\n",
        "win_size = int((win_per / 100) * sentiment_df.shape[0])  # Calculate window size\n",
        "if win_size % 2 == 0:\n",
        "    win_size += 1  # Ensure win_size is odd as required by S-G Algo\n",
        "polynomial_order = 3  # Polynomial order for S-G filter\n",
        "\n",
        "# Initialize DataFrame for smoothed data\n",
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "# Apply filters\n",
        "for amodel in model_ls:\n",
        "    print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "    # Apply rolling mean\n",
        "    rolling_mean = sentiment_df[amodel].rolling(win_size, min_periods=1, center=True).mean()\n",
        "\n",
        "    # Apply Savitzky-Golay filter\n",
        "    smoothed = savgol_filter(rolling_mean, win_size, polynomial_order)\n",
        "\n",
        "    # Center the smoothed data around mean = 0\n",
        "    smoothed_centered = smoothed - np.mean(smoothed)\n",
        "\n",
        "    sentiment_sg_df[amodel] = smoothed_centered\n",
        "\n",
        "# Plot the smoothed and centered sentiment scores\n",
        "plt.figure(figsize=(12, 8))\n",
        "title = f\"Sentiment Analysis: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{novel_title}\"\n",
        "plt.title(title, fontsize=12)\n",
        "for amodel in model_ls:\n",
        "    plt.plot(sentiment_sg_df[amodel], label=amodel)\n",
        "plt.legend(fontsize=8)\n",
        "plt.xlabel(\"Index\", fontsize=7)\n",
        "plt.ylabel(\"Sentiment\", fontsize=7)\n",
        "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.show();\n",
        "\n",
        "\"\"\"\n",
        "# Calculate the pairwise Euclidean distance matrix\n",
        "euclidean_distance_matrix = np.linalg.norm(sentiment_sg_df.values[:, np.newaxis] - sentiment_sg_df.values, axis=2)\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(euclidean_distance_matrix, xticklabels=model_ls, yticklabels=model_ls, cmap='viridis', annot=True, fmt=\".2f\", annot_kws={\"size\": 8})\n",
        "plt.title(\"Euclidean Distance Between All Time Series in Sentiment SG DF\", fontsize=12)\n",
        "plt.xlabel(\"Models\", fontsize=10)\n",
        "plt.ylabel(\"Models\", fontsize=10)\n",
        "plt.xticks(fontsize=8)\n",
        "plt.yticks(fontsize=8)\n",
        "plt.show();\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D5IZ9THv9PQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#Apply sequentially SMA 10% then Savitzky-Golay filtering\n",
        "\n",
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "# Assuming your time series is stored in the variable 'data'\n",
        "win_per = 10 # Window size percent\n",
        "win_size = int((win_per/100)*sentiment_all_norm_df.shape[0])  # Adjust the window size as needed\n",
        "# Ensure win_size is odd as required by S-G Algo\n",
        "if win_size % 2 == 0:\n",
        "  # If not, add 1\n",
        "  win_size += 1\n",
        "\n",
        "polynomial_order = 3  # Adjust the polynomial order as needed\n",
        "\n",
        "for amodel in model_subset_ls:\n",
        "  print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "  # Apply savgol_filter to the rolling mean of the normalized sentiment scores\n",
        "  sentiment_sg_df[amodel] = savgol_filter(sentiment_all_norm_df[amodel].rolling(win_size, min_periods=1, center=True).mean(), win_size, polynomial_order)\n",
        "\n",
        "  # Set the title of the plot\n",
        "  title = f\"Sentiment Analysis: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{Novel_Title}\"\n",
        "\n",
        "  # Plot the smoothed sentiment scores with a key\n",
        "  _ = sentiment_sg_df[amodel].plot(title=title, label=amodel)\n",
        "  plt.legend(); # Add a legend to the plot\n",
        "\n",
        "# Heatmap of Euclidean Distance of Norm/SMA/SG smoothed model time series\n",
        "\n",
        "# Calculate the pairwise Euclidean distance matrix using the smoothed data\n",
        "euclidean_distance_matrix = np.linalg.norm(sentiment_sg_df[:, np.newaxis] - smoothed_data, axis=2)\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "sns.heatmap(euclidean_distance_matrix, xticklabels=sentiment_dg_df.columns, yticklabels=sentiment_dg_df.columns)\n",
        "plt.title(\"Euclidean distance between all time series in sentiment_dg_df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO4tVVB2vXS6"
      },
      "outputs": [],
      "source": [
        "for amodel in model_subset_ls:\n",
        "  print(f\"Processing Model: {amodel}\")\n",
        "\n",
        "  # Apply savgol_filter to the rolling mean of the normalized sentiment scores\n",
        "  sentiment_sg_df[amodel] = savgol_filter(sentiment_all_norm_df[amodel].rolling(win_size, min_periods=1, center=True).mean(), win_size, polynomial_order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjl-3mU1vFXO"
      },
      "outputs": [],
      "source": [
        "# Heatmap of Euclidean Distance of Norm/SMA/SG smoothed model time series\n",
        "\n",
        "# Calculate the pairwise Euclidean distance matrix using the smoothed data\n",
        "euclidean_distance_matrix = np.linalg.norm(sentiment_sg_df[:, np.newaxis] - smoothed_data, axis=2)\n",
        "\n",
        "# Plot the heatmap of the distance matrix\n",
        "sns.heatmap(euclidean_distance_matrix, xticklabels=sentiment_dg_df.columns, yticklabels=sentiment_dg_df.columns)\n",
        "plt.title(\"Euclidean distance between all time series in sentiment_dg_df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYIuZRxqvFTd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfxKjjPea_eY"
      },
      "outputs": [],
      "source": [
        "#Apply sequentially SMA 10% then Savitzky-Golay filtering\n",
        "\n",
        "sentiment_sg_df = pd.DataFrame()\n",
        "\n",
        "# Assuming your time series is stored in the variable 'data'\n",
        "win_per = 10 # Window size percent\n",
        "win_size = int((win_per/100)*sentiment_all_norm_df.shape[0])  # Adjust the window size as needed\n",
        "# Ensure win_size is odd as required by S-G Algo\n",
        "if win_size % 2 == 0:\n",
        "  # If not, add 1\n",
        "  win_size += 1\n",
        "\n",
        "polynomial_order = 3  # Adjust the polynomial order as needed\n",
        "\n",
        "for amodel in model_subset_ls:\n",
        "  print(f\"Processing Model: {amodel}\")\n",
        "  # Apply Savitzky-Golay filtering\n",
        "  # ax = sentiment_all_norm_df[model_gpt_ls].rolling(win_size, center=True).mean().plot(grid=True, colormap='Dark2', lw=3)\n",
        "  # ax.title.set_text(f'Sentiment Analysis \\n {Novel_Title} \\n Normalization: Standard Scaler')\n",
        "  ax = sentiment_sg_df[amodel] = savgol_filter(sentiment_all_norm_df[amodel].rolling(win_size, min_periods=1, center=True).mean(), win_size, polynomial_order)\n",
        "  ax.title.set_text(f\"Sentiment Analysis: Normed & Double Smoothed\\n (Standard Scaler + SMA 10% + SG 10%)\\n{novel_title}\")\n",
        "  sentiment_sg_df[amodel].plot()\n",
        "  # Calculate Euclidean distance using the smoothed data\n",
        "  # euclidean_distance = np.linalg.norm(smoothed_data - other_time_series)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36JDj3qdqbA6"
      },
      "source": [
        "### TS Euclidian Distance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTIM6mfxqajH"
      },
      "outputs": [],
      "source": [
        "# Normalize Timeseries with StandardScaler (u=0, sd=+/- 1)\n",
        "model_all_ls = model_ls + ['distilbert']\n",
        "\n",
        "# sentiment_all_norm_df = pd.DataFrame()\n",
        "sentiment_all_norm_df = sentiment_df[['line_no','text_raw','text_clean']].copy(deep=True)\n",
        "sentiment_all_norm_df[model_all_ls] = StandardScaler().fit_transform(sentiment_df[model_all_ls])\n",
        "sentiment_all_norm_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc1cWOGAqTY9"
      },
      "source": [
        "### In/coherence Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi_5zEEKZEuZ"
      },
      "outputs": [],
      "source": [
        "# ORIGINAL FULL Ensemble\n",
        "\n",
        "# TODO: Here and everywhere, replace model_mail_ls with model_subset_ls\n",
        "# model_main_ls = model_ls\n",
        "# model_main_ls = model_subset_ls\n",
        "model_main_ls = model_ls\n",
        "\n",
        "# Compute rolling mean dataframe\n",
        "rolling_mean_df = sentiment_df.rolling(win_size, min_periods=1, center=True).mean()\n",
        "\n",
        "# Compute range dataframe\n",
        "# incoherence_df = rolling_mean_df[model_ls].apply(lambda x: np.abs(x.max() - x.min()), axis=1)\n",
        "\n",
        "# Create subplot with 2 rows, 1 column\n",
        "fig, ax = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [4, 1]})\n",
        "\n",
        "# Plot main sentiment series\n",
        "rolling_mean_df.plot(ax=ax[0], grid=True, colormap='Dark2', lw=2)\n",
        "ax[0].title.set_text(f'Sentiment Analysis \\n {novel_title} \\n Normalization: Standard Scaler')\n",
        "\n",
        "# Plot range series\n",
        "# incoherence_df.plot(ax=ax[1], grid=True, color='red')\n",
        "\n",
        "# Invert Y-axis and add labels\n",
        "# ax[1].invert_yaxis()\n",
        "ax[1].set_title('Ensemble Incoherence')\n",
        "# ax[1].set_ylabel('incoherence')\n",
        "\n",
        "# Show the plot\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pd-qe7lbSEO"
      },
      "outputs": [],
      "source": [
        "# REMOVE: outlier model(s)\n",
        "\n",
        "model_remove_ls = ['distilbert'] # ['nlptown']\n",
        "model_main_ls = model_ls\n",
        "\n",
        "# Remove the strings from the large list\n",
        "for amodel in model_remove_ls:\n",
        "    try:\n",
        "        model_main_ls.remove(amodel)\n",
        "    except ValueError:\n",
        "        print(\"The string {} does not exist in the large list.\".format(string))\n",
        "\n",
        "model_main_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtD-v85TdcUK"
      },
      "outputs": [],
      "source": [
        "sentiment_all_norm_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su0Yd-d02Nq6"
      },
      "outputs": [],
      "source": [
        "incoherence_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyRorUgkBnpV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDCllbXdZskq"
      },
      "outputs": [],
      "source": [
        "# Plot Emsemble centered around 0 mean\n",
        "\n",
        "# Increase font sizes\n",
        "plt.rcParams.update({\n",
        "    'axes.titlesize': 30,\n",
        "    'axes.labelsize': 27,\n",
        "    'xtick.labelsize': 24,\n",
        "    'ytick.labelsize': 24,\n",
        "    'legend.fontsize': 27,\n",
        "    'figure.titlesize': 33\n",
        "})\n",
        "\n",
        "# Compute the rolling mean dataframe\n",
        "rolling_mean_df = sentiment_df[model_ls].rolling(win_size, min_periods=1, center=True).mean()\n",
        "\n",
        "# Center each rolling mean time series around 0 baseline\n",
        "for col in model_ls:\n",
        "    rolling_mean_df[col] = rolling_mean_df[col] - rolling_mean_df[col].mean()\n",
        "\n",
        "#\n",
        "# Compute range dataframe\n",
        "incoherence_df = rolling_mean_df.apply(lambda x: np.abs(x.max() - x.min()), axis=1)\n",
        "coherence_df = incoherence_df * -1.0\n",
        "\n",
        "# Create subplot with 2 rows, 1 column\n",
        "fig, ax = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [4, 1]})\n",
        "\n",
        "# Plot main sentiment series\n",
        "rolling_mean_df.plot(ax=ax[0], grid=True, colormap='Dark2', lw=2)\n",
        "ax[0].title.set_text(f'Sentiment Analysis \\n {novel_title} \\n Normalization: Standard Scaler')\n",
        "\n",
        "# Plot incoherence_df series\n",
        "coherence_df.plot(ax=ax[1], grid=True, color='red')\n",
        "\n",
        "# Invert Y-axis and add labels\n",
        "# ax[1].invert_yaxis()\n",
        "ax[1].set_title('Ensemble Incoherence')\n",
        "ax[1].set_ylabel('coherence')\n",
        "\n",
        "# Show the plot\n",
        "plt.show();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiqAduT5RFSH"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lVKek_uU7NG_",
        "lf3GmUq1yTKT",
        "z49LEOStkmt8",
        "IlElbp_ZJEe-",
        "AURLiQGny5I1",
        "yUV7HgvLk_E1",
        "wXiMSEvIlHmp",
        "vzaE7PuejExE",
        "dzp6OrUUGtb1",
        "QmS7W3PfkfXp",
        "kb7T0OCmlABK",
        "kncXmKaJP3X5"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}